model_polarity = Transformer(
    NORBERT=NORBERT,
    tokenizer=train_dataset.tokenizer,
    num_labels=3,
    IGNORE_ID=train_dataset.IGNORE_ID,
    device="cpu", # "cuda" if torch.cuda.is_available() else "cpu",
    epochs=20,  # best is 9 or 13
    lr_scheduler=False,
    factor=0.1,
    lrs_patience=2,
    loss_funct='cross-entropy',
    random_state=1,
    verbose=True,
    lr=0.00001,
    momentum=0.9,
    epoch_patience=1,
    label_indexer=None,
    optmizer='AdamW'
)

model_polarity.fit(
    train_loader=train_loader,
    verbose=True,
    dev_loader=dev_loader,
    need_pipeline=torch.load("exam/transformer_bio.pt")
)

~/Documents/IN5550$ python3 exam/test_bert_polarity.py
Some weights of the model checkpoint at exam/saga/216 were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at exam/saga/216 and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|                                                    | 0/20 [00:00<?, ?it/s]Batch: 0  |  Train Loss: 1.178472638130188  |
Batch: 1  |  Train Loss: 1.0017915964126587  |
Batch: 2  |  Train Loss: 0.8953767418861389  |
Batch: 3  |  Train Loss: 0.7381447553634644  |
Batch: 4  |  Train Loss: 0.6831239461898804  |
Batch: 5  |  Train Loss: 0.5554893612861633  |
Batch: 6  |  Train Loss: 0.4903692901134491  |
Batch: 7  |  Train Loss: 0.4772849380970001  |
Batch: 8  |  Train Loss: 0.4465610980987549  |
Batch: 9  |  Train Loss: 0.4082006514072418  |
Batch: 10  |  Train Loss: 0.40006932616233826  |
Batch: 11  |  Train Loss: 0.40224528312683105  |
Batch: 12  |  Train Loss: 0.35828933119773865  |
Batch: 13  |  Train Loss: 0.3191940188407898  |
Batch: 14  |  Train Loss: 0.270701140165329  |
Batch: 15  |  Train Loss: 0.2522682249546051  |
Batch: 16  |  Train Loss: 0.29009005427360535  |
Batch: 17  |  Train Loss: 0.2368013560771942  |
Batch: 18  |  Train Loss: 0.26728060841560364  |
Batch: 19  |  Train Loss: 0.2863807678222656  |
Batch: 20  |  Train Loss: 0.3610684871673584  |
Batch: 21  |  Train Loss: 0.3320350646972656  |
Batch: 22  |  Train Loss: 0.3400154411792755  |
Batch: 23  |  Train Loss: 0.2661701738834381  |
Batch: 24  |  Train Loss: 0.2706754207611084  |
Batch: 25  |  Train Loss: 0.31241485476493835  |
Batch: 26  |  Train Loss: 0.228313148021698  |
Batch: 27  |  Train Loss: 0.36167216300964355  |
Batch: 28  |  Train Loss: 0.2712431252002716  |
Batch: 29  |  Train Loss: 0.27283838391304016  |
Batch: 30  |  Train Loss: 0.344044029712677  |
Batch: 31  |  Train Loss: 0.28385114669799805  |
Batch: 32  |  Train Loss: 0.2639424502849579  |
Batch: 33  |  Train Loss: 0.21187083423137665  |
Batch: 34  |  Train Loss: 0.2723940312862396  |
Batch: 35  |  Train Loss: 0.2351207733154297  |
Batch: 36  |  Train Loss: 0.2853826582431793  |
Batch: 37  |  Train Loss: 0.26776450872421265  |
Batch: 38  |  Train Loss: 0.38504141569137573  |
Batch: 39  |  Train Loss: 0.21522846817970276  |
Batch: 40  |  Train Loss: 0.17597702145576477  |
Batch: 41  |  Train Loss: 0.336365669965744  |
Batch: 42  |  Train Loss: 0.2798416018486023  |
Batch: 43  |  Train Loss: 0.24283559620380402  |
Batch: 44  |  Train Loss: 0.2145230621099472  |
Batch: 45  |  Train Loss: 0.29320773482322693  |
Batch: 46  |  Train Loss: 0.3995131850242615  |
Batch: 47  |  Train Loss: 0.32751041650772095  |
Batch: 48  |  Train Loss: 0.19208647310733795  |
Batch: 49  |  Train Loss: 0.26493409276008606  |
Batch: 50  |  Train Loss: 0.2925987243652344  |
Batch: 51  |  Train Loss: 0.3517288863658905  |
Batch: 52  |  Train Loss: 0.3064328134059906  |
Batch: 53  |  Train Loss: 0.260488361120224  |
Batch: 54  |  Train Loss: 0.41568729281425476  |
Batch: 55  |  Train Loss: 0.26153069734573364  |
Batch: 56  |  Train Loss: 0.27210795879364014  |
Batch: 57  |  Train Loss: 0.24894045293331146  |
Batch: 58  |  Train Loss: 0.2935418486595154  |
Batch: 59  |  Train Loss: 0.2809005081653595  |
Batch: 60  |  Train Loss: 0.17154726386070251  |
Batch: 61  |  Train Loss: 0.39258235692977905  |
Batch: 62  |  Train Loss: 0.23134271800518036  |
Batch: 63  |  Train Loss: 0.2881815433502197  |
Batch: 64  |  Train Loss: 0.1861031949520111  |
Batch: 65  |  Train Loss: 0.41973677277565  |
Batch: 66  |  Train Loss: 0.28342971205711365  |
Batch: 67  |  Train Loss: 0.27539655566215515  |
Batch: 68  |  Train Loss: 0.39998066425323486  |
Batch: 69  |  Train Loss: 0.27593740820884705  |
Batch: 70  |  Train Loss: 0.21533803641796112  |
Batch: 71  |  Train Loss: 0.2930287718772888  |
Batch: 72  |  Train Loss: 0.2388765811920166  |
Batch: 73  |  Train Loss: 0.2717429995536804  |
Batch: 74  |  Train Loss: 0.22306720912456512  |
Batch: 75  |  Train Loss: 0.2616584599018097  |
Batch: 76  |  Train Loss: 0.20230069756507874  |
Batch: 77  |  Train Loss: 0.25191885232925415  |
Batch: 78  |  Train Loss: 0.1939801275730133  |
Batch: 79  |  Train Loss: 0.2298012375831604  |
Batch: 80  |  Train Loss: 0.19181470572948456  |
Batch: 81  |  Train Loss: 0.2541694641113281  |
Batch: 82  |  Train Loss: 0.23940643668174744  |
Batch: 83  |  Train Loss: 0.22944098711013794  |
Batch: 84  |  Train Loss: 0.17226473987102509  |
Batch: 85  |  Train Loss: 0.20325353741645813  |
Batch: 86  |  Train Loss: 0.13554508984088898  |
Batch: 87  |  Train Loss: 0.17680221796035767  |
Batch: 88  |  Train Loss: 0.31267106533050537  |
Batch: 89  |  Train Loss: 0.32489198446273804  |
Batch: 90  |  Train Loss: 0.1583767980337143  |
Batch: 91  |  Train Loss: 0.16026882827281952  |
Batch: 92  |  Train Loss: 0.29536235332489014  |
Batch: 93  |  Train Loss: 0.31466493010520935  |
Batch: 94  |  Train Loss: 0.3362348973751068  |
Batch: 95  |  Train Loss: 0.2155507504940033  |
Batch: 96  |  Train Loss: 0.2597818672657013  |
Batch: 97  |  Train Loss: 0.2241370975971222  |
Batch: 98  |  Train Loss: 0.22382594645023346  |
Batch: 99  |  Train Loss: 0.2649184465408325  |
Batch: 100  |  Train Loss: 0.17173941433429718  |
Batch: 101  |  Train Loss: 0.26939916610717773  |
Batch: 102  |  Train Loss: 0.3321550488471985  |
Batch: 103  |  Train Loss: 0.19866903126239777  |
Batch: 104  |  Train Loss: 0.19427882134914398  |
Batch: 105  |  Train Loss: 0.3099097013473511  |
Batch: 106  |  Train Loss: 0.3157038390636444  |
Batch: 107  |  Train Loss: 0.2917347848415375  |
Batch: 108  |  Train Loss: 0.21425576508045197  |
Batch: 109  |  Train Loss: 0.2092149257659912  |
Batch: 110  |  Train Loss: 0.24806497991085052  |
Batch: 111  |  Train Loss: 0.22639575600624084  |
Batch: 112  |  Train Loss: 0.19793961942195892  |
Batch: 113  |  Train Loss: 0.3200695514678955  |
Batch: 114  |  Train Loss: 0.2096509039402008  |
Batch: 115  |  Train Loss: 0.2072770744562149  |
Batch: 116  |  Train Loss: 0.17314991354942322  |
Batch: 117  |  Train Loss: 0.25808602571487427  |
Batch: 118  |  Train Loss: 0.31913501024246216  |
Batch: 119  |  Train Loss: 0.17543980479240417  |
Batch: 120  |  Train Loss: 0.3514995872974396  |
Batch: 121  |  Train Loss: 0.22024378180503845  |
Batch: 122  |  Train Loss: 0.42071568965911865  |
Batch: 123  |  Train Loss: 0.23831836879253387  |
Batch: 124  |  Train Loss: 0.2379472702741623  |
Batch: 125  |  Train Loss: 0.3004375994205475  |
Batch: 126  |  Train Loss: 0.32009270787239075  |
Batch: 127  |  Train Loss: 0.2469516098499298  |
Batch: 128  |  Train Loss: 0.25799331068992615  |
Batch: 129  |  Train Loss: 0.2667044699192047  |
Batch: 130  |  Train Loss: 0.4230262041091919  |
Batch: 131  |  Train Loss: 0.19733667373657227  |
Batch: 132  |  Train Loss: 0.20364762842655182  |
Batch: 133  |  Train Loss: 0.19691483676433563  |
Batch: 134  |  Train Loss: 0.19849315285682678  |
Batch: 135  |  Train Loss: 0.19398196041584015  |
Batch: 136  |  Train Loss: 0.2994273900985718  |
Batch: 137  |  Train Loss: 0.16981355845928192  |
Batch: 138  |  Train Loss: 0.17867662012577057  |
Batch: 139  |  Train Loss: 0.24194519221782684  |
Batch: 140  |  Train Loss: 0.2723800539970398  |
Batch: 141  |  Train Loss: 0.3828440308570862  |
Batch: 142  |  Train Loss: 0.35802221298217773  |
Batch: 143  |  Train Loss: 0.26074162125587463  |
Batch: 144  |  Train Loss: 0.2008405178785324  |
Batch: 145  |  Train Loss: 0.26801279187202454  |
Batch: 146  |  Train Loss: 0.29742667078971863  |
Batch: 147  |  Train Loss: 0.24694836139678955  |
Batch: 148  |  Train Loss: 0.25414809584617615  |
Batch: 149  |  Train Loss: 0.2943000793457031  |
Batch: 150  |  Train Loss: 0.27497079968452454  |
Batch: 151  |  Train Loss: 0.16184678673744202  |
Batch: 152  |  Train Loss: 0.15578201413154602  |
Batch: 153  |  Train Loss: 0.24476173520088196  |
Batch: 154  |  Train Loss: 0.3797847032546997  |
Batch: 155  |  Train Loss: 0.18777163326740265  |
Batch: 156  |  Train Loss: 0.235890731215477  |
Batch: 157  |  Train Loss: 0.4378666281700134  |
Batch: 158  |  Train Loss: 0.15299741923809052  |
Batch: 159  |  Train Loss: 0.37071385979652405  |
Batch: 160  |  Train Loss: 0.1347467601299286  |
Batch: 161  |  Train Loss: 0.17523761093616486  |
Batch: 162  |  Train Loss: 0.22157436609268188  |
Batch: 163  |  Train Loss: 0.18110200762748718  |
Batch: 164  |  Train Loss: 0.4178973436355591  |
Batch: 165  |  Train Loss: 0.1953311413526535  |
Batch: 166  |  Train Loss: 0.1849244385957718  |
Batch: 167  |  Train Loss: 0.18832778930664062  |
Batch: 168  |  Train Loss: 0.2618347406387329  |
Batch: 169  |  Train Loss: 0.16248610615730286  |
Batch: 170  |  Train Loss: 0.14829006791114807  |
Batch: 171  |  Train Loss: 0.24459633231163025  |
Batch: 172  |  Train Loss: 0.1901547759771347  |
Batch: 173  |  Train Loss: 0.13410484790802002  |
Batch: 174  |  Train Loss: 0.1906825453042984  |
Batch: 175  |  Train Loss: 0.13197600841522217  |
Batch: 176  |  Train Loss: 0.1981252282857895  |
Batch: 177  |  Train Loss: 0.16304455697536469  |
Batch: 178  |  Train Loss: 0.27971139550209045  |
Batch: 179  |  Train Loss: 0.3178442418575287  |
Batch: 180  |  Train Loss: 0.19702741503715515  |
Batch: 181  |  Train Loss: 0.24304258823394775  |
Batch: 182  |  Train Loss: 0.26347893476486206  |
Batch: 183  |  Train Loss: 0.17599506676197052  |
Batch: 184  |  Train Loss: 0.1840822547674179  |
Epoch: 0  |  Train Loss: 0.28151034310057355
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.88it/s]
Binary results:████████████████████████████▉| 1150/1151 [00:50<00:00, 23.93it/s]
################################################################################

Target prec: 0.658
Target recall: 0.344
Target F1: 0.452

Proportional results:
################################################################################

Target prec: 0.476
Target recall: 0.194
Target F1: 0.275

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.83it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.86it/s]
Binary results:█████████████████████████████| 1151/1151 [00:50<00:00, 22.07it/s]
################################################################################

Target prec: 0.733
Target recall: 0.328
Target F1: 0.454

Proportional results:
################################################################################

Target prec: 0.493
Target recall: 0.170
Target F1: 0.253

################# END OF PIPELINE's RESULTS #################
  5%|██                                      | 1/20 [17:37<5:34:51, 1057.46s/it]Batch: 0  |  Train Loss: 0.17464028298854828  |
Batch: 1  |  Train Loss: 0.24489933252334595  |
Batch: 2  |  Train Loss: 0.11655422300100327  |
Batch: 3  |  Train Loss: 0.4606028199195862  |
Batch: 4  |  Train Loss: 0.16940107941627502  |
Batch: 5  |  Train Loss: 0.22376488149166107  |
Batch: 6  |  Train Loss: 0.1649729609489441  |
Batch: 7  |  Train Loss: 0.24475568532943726  |
Batch: 8  |  Train Loss: 0.15761014819145203  |
Batch: 9  |  Train Loss: 0.1797155886888504  |
Batch: 10  |  Train Loss: 0.10492371767759323  |
Batch: 11  |  Train Loss: 0.2737595736980438  |
Batch: 12  |  Train Loss: 0.230702206492424  |
Batch: 13  |  Train Loss: 0.2730684280395508  |
Batch: 14  |  Train Loss: 0.16354921460151672  |
Batch: 15  |  Train Loss: 0.10972359776496887  |
Batch: 16  |  Train Loss: 0.13181619346141815  |
Batch: 17  |  Train Loss: 0.22017642855644226  |
Batch: 18  |  Train Loss: 0.16202177107334137  |
Batch: 19  |  Train Loss: 0.1913754791021347  |
Batch: 20  |  Train Loss: 0.2899158000946045  |
Batch: 21  |  Train Loss: 0.26913291215896606  |
Batch: 22  |  Train Loss: 0.23029273748397827  |
Batch: 23  |  Train Loss: 0.15677018463611603  |
Batch: 24  |  Train Loss: 0.1899612843990326  |
Batch: 25  |  Train Loss: 0.20928801596164703  |
Batch: 26  |  Train Loss: 0.21921272575855255  |
Batch: 27  |  Train Loss: 0.13856783509254456  |
Batch: 28  |  Train Loss: 0.27740782499313354  |
Batch: 29  |  Train Loss: 0.14347484707832336  |
Batch: 30  |  Train Loss: 0.3338439464569092  |
Batch: 31  |  Train Loss: 0.4622284471988678  |
Batch: 32  |  Train Loss: 0.19224698841571808  |
Batch: 33  |  Train Loss: 0.319172203540802  |
Batch: 34  |  Train Loss: 0.2481299340724945  |
Batch: 35  |  Train Loss: 0.14912652969360352  |
Batch: 36  |  Train Loss: 0.19551025331020355  |
Batch: 37  |  Train Loss: 0.18552757799625397  |
Batch: 38  |  Train Loss: 0.16583387553691864  |
Batch: 39  |  Train Loss: 0.16246439516544342  |
Batch: 40  |  Train Loss: 0.09293317794799805  |
Batch: 41  |  Train Loss: 0.31265339255332947  |
Batch: 42  |  Train Loss: 0.16764503717422485  |
Batch: 43  |  Train Loss: 0.3150166869163513  |
Batch: 44  |  Train Loss: 0.22980186343193054  |
Batch: 45  |  Train Loss: 0.11883675307035446  |
Batch: 46  |  Train Loss: 0.23410263657569885  |
Batch: 47  |  Train Loss: 0.1748289316892624  |
Batch: 48  |  Train Loss: 0.16918876767158508  |
Batch: 49  |  Train Loss: 0.25387686491012573  |
Batch: 50  |  Train Loss: 0.208173930644989  |
Batch: 51  |  Train Loss: 0.2890733778476715  |
Batch: 52  |  Train Loss: 0.15244203805923462  |
Batch: 53  |  Train Loss: 0.12023220956325531  |
Batch: 54  |  Train Loss: 0.3054736256599426  |
Batch: 55  |  Train Loss: 0.19265614449977875  |
Batch: 56  |  Train Loss: 0.17961657047271729  |
Batch: 57  |  Train Loss: 0.2503332495689392  |
Batch: 58  |  Train Loss: 0.18083995580673218  |
Batch: 59  |  Train Loss: 0.20124730467796326  |
Batch: 60  |  Train Loss: 0.20527523756027222  |
Batch: 61  |  Train Loss: 0.2539617121219635  |
Batch: 62  |  Train Loss: 0.1909627765417099  |
Batch: 63  |  Train Loss: 0.16726721823215485  |
Batch: 64  |  Train Loss: 0.19183799624443054  |
Batch: 65  |  Train Loss: 0.294344961643219  |
Batch: 66  |  Train Loss: 0.31049931049346924  |
Batch: 67  |  Train Loss: 0.18301180005073547  |
Batch: 68  |  Train Loss: 0.20151260495185852  |
Batch: 69  |  Train Loss: 0.14124424755573273  |
Batch: 70  |  Train Loss: 0.1488383412361145  |
Batch: 71  |  Train Loss: 0.322770357131958  |
Batch: 72  |  Train Loss: 0.15728846192359924  |
Batch: 73  |  Train Loss: 0.13538877665996552  |
Batch: 74  |  Train Loss: 0.36459654569625854  |
Batch: 75  |  Train Loss: 0.13162805140018463  |
Batch: 76  |  Train Loss: 0.19530805945396423  |
Batch: 77  |  Train Loss: 0.15667860209941864  |
Batch: 78  |  Train Loss: 0.20599883794784546  |
Batch: 79  |  Train Loss: 0.26213786005973816  |
Batch: 80  |  Train Loss: 0.21280308067798615  |
Batch: 81  |  Train Loss: 0.18403296172618866  |
Batch: 82  |  Train Loss: 0.1956760734319687  |
Batch: 83  |  Train Loss: 0.163435161113739  |
Batch: 84  |  Train Loss: 0.2839597165584564  |
Batch: 85  |  Train Loss: 0.11730325222015381  |
Batch: 86  |  Train Loss: 0.2376343011856079  |
Batch: 87  |  Train Loss: 0.17675235867500305  |
Batch: 88  |  Train Loss: 0.16543184220790863  |
Batch: 89  |  Train Loss: 0.13526855409145355  |
Batch: 90  |  Train Loss: 0.09281513839960098  |
Batch: 91  |  Train Loss: 0.1430744230747223  |
Batch: 92  |  Train Loss: 0.2099345177412033  |
Batch: 93  |  Train Loss: 0.049677956849336624  |
Batch: 94  |  Train Loss: 0.11486799269914627  |
Batch: 95  |  Train Loss: 0.1648377925157547  |
Batch: 96  |  Train Loss: 0.2562171518802643  |
Batch: 97  |  Train Loss: 0.1383003443479538  |
Batch: 98  |  Train Loss: 0.2342345416545868  |
Batch: 99  |  Train Loss: 0.27893921732902527  |
Batch: 100  |  Train Loss: 0.18530523777008057  |
Batch: 101  |  Train Loss: 0.20824770629405975  |
Batch: 102  |  Train Loss: 0.1791727989912033  |
Batch: 103  |  Train Loss: 0.2950192987918854  |
Batch: 104  |  Train Loss: 0.20582546293735504  |
Batch: 105  |  Train Loss: 0.14881402254104614  |
Batch: 106  |  Train Loss: 0.1929984837770462  |
Batch: 107  |  Train Loss: 0.18940207362174988  |
Batch: 108  |  Train Loss: 0.15983939170837402  |
Batch: 109  |  Train Loss: 0.21473954617977142  |
Batch: 110  |  Train Loss: 0.09417153894901276  |
Batch: 111  |  Train Loss: 0.25427308678627014  |
Batch: 112  |  Train Loss: 0.24406006932258606  |
Batch: 113  |  Train Loss: 0.16739711165428162  |
Batch: 114  |  Train Loss: 0.2595115005970001  |
Batch: 115  |  Train Loss: 0.24917149543762207  |
Batch: 116  |  Train Loss: 0.21021036803722382  |
Batch: 117  |  Train Loss: 0.14340364933013916  |
Batch: 118  |  Train Loss: 0.23012728989124298  |
Batch: 119  |  Train Loss: 0.24879178404808044  |
Batch: 120  |  Train Loss: 0.2638455629348755  |
Batch: 121  |  Train Loss: 0.18744653463363647  |
Batch: 122  |  Train Loss: 0.19044983386993408  |
Batch: 123  |  Train Loss: 0.21001866459846497  |
Batch: 124  |  Train Loss: 0.20413173735141754  |
Batch: 125  |  Train Loss: 0.1826079785823822  |
Batch: 126  |  Train Loss: 0.22961996495723724  |
Batch: 127  |  Train Loss: 0.18509715795516968  |
Batch: 128  |  Train Loss: 0.12463884800672531  |
Batch: 129  |  Train Loss: 0.21586161851882935  |
Batch: 130  |  Train Loss: 0.17421594262123108  |
Batch: 131  |  Train Loss: 0.18009328842163086  |
Batch: 132  |  Train Loss: 0.19405338168144226  |
Batch: 133  |  Train Loss: 0.2160002887248993  |
Batch: 134  |  Train Loss: 0.17508937418460846  |
Batch: 135  |  Train Loss: 0.3354608118534088  |
Batch: 136  |  Train Loss: 0.1435956507921219  |
Batch: 137  |  Train Loss: 0.1720733344554901  |
Batch: 138  |  Train Loss: 0.12499643117189407  |
Batch: 139  |  Train Loss: 0.1947406381368637  |
Batch: 140  |  Train Loss: 0.17491501569747925  |
Batch: 141  |  Train Loss: 0.1638626903295517  |
Batch: 142  |  Train Loss: 0.2047785222530365  |
Batch: 143  |  Train Loss: 0.2505871653556824  |
Batch: 144  |  Train Loss: 0.15364280343055725  |
Batch: 145  |  Train Loss: 0.13656970858573914  |
Batch: 146  |  Train Loss: 0.12549656629562378  |
Batch: 147  |  Train Loss: 0.20280757546424866  |
Batch: 148  |  Train Loss: 0.1624765247106552  |
Batch: 149  |  Train Loss: 0.22743532061576843  |
Batch: 150  |  Train Loss: 0.11578591912984848  |
Batch: 151  |  Train Loss: 0.11271698027849197  |
Batch: 152  |  Train Loss: 0.23619689047336578  |
Batch: 153  |  Train Loss: 0.2526319921016693  |
Batch: 154  |  Train Loss: 0.1893722265958786  |
Batch: 155  |  Train Loss: 0.22644850611686707  |
Batch: 156  |  Train Loss: 0.29552119970321655  |
Batch: 157  |  Train Loss: 0.17808662354946136  |
Batch: 158  |  Train Loss: 0.2187807261943817  |
Batch: 159  |  Train Loss: 0.13583579659461975  |
Batch: 160  |  Train Loss: 0.1854790598154068  |
Batch: 161  |  Train Loss: 0.2440958172082901  |
Batch: 162  |  Train Loss: 0.170754536986351  |
Batch: 163  |  Train Loss: 0.298402339220047  |
Batch: 164  |  Train Loss: 0.19226132333278656  |
Batch: 165  |  Train Loss: 0.11406195163726807  |
Batch: 166  |  Train Loss: 0.1689043790102005  |
Batch: 167  |  Train Loss: 0.10608870536088943  |
Batch: 168  |  Train Loss: 0.24104075133800507  |
Batch: 169  |  Train Loss: 0.12979020178318024  |
Batch: 170  |  Train Loss: 0.17846551537513733  |
Batch: 171  |  Train Loss: 0.11447171866893768  |
Batch: 172  |  Train Loss: 0.12812070548534393  |
Batch: 173  |  Train Loss: 0.13245421648025513  |
Batch: 174  |  Train Loss: 0.16281691193580627  |
Batch: 175  |  Train Loss: 0.25757482647895813  |
Batch: 176  |  Train Loss: 0.1273801326751709  |
Batch: 177  |  Train Loss: 0.2764110863208771  |
Batch: 178  |  Train Loss: 0.25524652004241943  |
Batch: 179  |  Train Loss: 0.16717004776000977  |
Batch: 180  |  Train Loss: 0.3477228581905365  |
Batch: 181  |  Train Loss: 0.2029670774936676  |
Batch: 182  |  Train Loss: 0.1584276556968689  |
Batch: 183  |  Train Loss: 0.1366049349308014  |
Batch: 184  |  Train Loss: 0.22726239264011383  |
Epoch: 1  |  Train Loss: 0.1996394917167522
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.89it/s]
Binary results:█████████████████████████████| 1151/1151 [00:50<00:00, 21.67it/s]
################################################################################

Target prec: 0.602
Target recall: 0.609
Target F1: 0.606

Proportional results:
################################################################################

Target prec: 0.456
Target recall: 0.381
Target F1: 0.415

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.87it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.80it/s]
Binary results:█████████████████████████████| 1151/1151 [00:50<00:00, 24.56it/s]
################################################################################

Target prec: 0.675
Target recall: 0.559
Target F1: 0.612

Proportional results:
################################################################################

Target prec: 0.472
Target recall: 0.307
Target F1: 0.372

################# END OF PIPELINE's RESULTS #################
 10%|████                                    | 2/20 [35:09<5:16:20, 1054.46s/it]Batch: 0  |  Train Loss: 0.18697799742221832  |
Batch: 1  |  Train Loss: 0.09742006659507751  |
Batch: 2  |  Train Loss: 0.13668213784694672  |
Batch: 3  |  Train Loss: 0.1772615611553192  |
Batch: 4  |  Train Loss: 0.13723330199718475  |
Batch: 5  |  Train Loss: 0.19353051483631134  |
Batch: 6  |  Train Loss: 0.08880302309989929  |
Batch: 7  |  Train Loss: 0.21423661708831787  |
Batch: 8  |  Train Loss: 0.17698222398757935  |
Batch: 9  |  Train Loss: 0.16940553486347198  |
Batch: 10  |  Train Loss: 0.13269644975662231  |
Batch: 11  |  Train Loss: 0.17297108471393585  |
Batch: 12  |  Train Loss: 0.2249569445848465  |
Batch: 13  |  Train Loss: 0.17220662534236908  |
Batch: 14  |  Train Loss: 0.19609476625919342  |
Batch: 15  |  Train Loss: 0.13838103413581848  |
Batch: 16  |  Train Loss: 0.16410408914089203  |
Batch: 17  |  Train Loss: 0.15531305968761444  |
Batch: 18  |  Train Loss: 0.19479160010814667  |
Batch: 19  |  Train Loss: 0.2559862434864044  |
Batch: 20  |  Train Loss: 0.26609498262405396  |
Batch: 21  |  Train Loss: 0.15971286594867706  |
Batch: 22  |  Train Loss: 0.197074756026268  |
Batch: 23  |  Train Loss: 0.14491187036037445  |
Batch: 24  |  Train Loss: 0.24736064672470093  |
Batch: 25  |  Train Loss: 0.20249846577644348  |
Batch: 26  |  Train Loss: 0.20088952779769897  |
Batch: 27  |  Train Loss: 0.2139396220445633  |
Batch: 28  |  Train Loss: 0.15885543823242188  |
Batch: 29  |  Train Loss: 0.09439608454704285  |
Batch: 30  |  Train Loss: 0.10453701764345169  |
Batch: 31  |  Train Loss: 0.1377730816602707  |
Batch: 32  |  Train Loss: 0.11979620903730392  |
Batch: 33  |  Train Loss: 0.07931236922740936  |
Batch: 34  |  Train Loss: 0.21341295540332794  |
Batch: 35  |  Train Loss: 0.20467448234558105  |
Batch: 36  |  Train Loss: 0.25752297043800354  |
Batch: 37  |  Train Loss: 0.14797385036945343  |
Batch: 38  |  Train Loss: 0.10826006531715393  |
Batch: 39  |  Train Loss: 0.2925072908401489  |
Batch: 40  |  Train Loss: 0.21911440789699554  |
Batch: 41  |  Train Loss: 0.18482840061187744  |
Batch: 42  |  Train Loss: 0.12217233330011368  |
Batch: 43  |  Train Loss: 0.13174200057983398  |
Batch: 44  |  Train Loss: 0.17757725715637207  |
Batch: 45  |  Train Loss: 0.1705833226442337  |
Batch: 46  |  Train Loss: 0.11069882661104202  |
Batch: 47  |  Train Loss: 0.08726616948843002  |
Batch: 48  |  Train Loss: 0.19030825793743134  |
Batch: 49  |  Train Loss: 0.17321237921714783  |
Batch: 50  |  Train Loss: 0.1579340547323227  |
Batch: 51  |  Train Loss: 0.20163097977638245  |
Batch: 52  |  Train Loss: 0.1777528077363968  |
Batch: 53  |  Train Loss: 0.10453204810619354  |
Batch: 54  |  Train Loss: 0.1331847757101059  |
Batch: 55  |  Train Loss: 0.22318336367607117  |
Batch: 56  |  Train Loss: 0.24090248346328735  |
Batch: 57  |  Train Loss: 0.13824106752872467  |
Batch: 58  |  Train Loss: 0.13065403699874878  |
Batch: 59  |  Train Loss: 0.2186964601278305  |
Batch: 60  |  Train Loss: 0.2620149552822113  |
Batch: 61  |  Train Loss: 0.11360600590705872  |
Batch: 62  |  Train Loss: 0.19087184965610504  |
Batch: 63  |  Train Loss: 0.16906379163265228  |
Batch: 64  |  Train Loss: 0.19623693823814392  |
Batch: 65  |  Train Loss: 0.15313071012496948  |
Batch: 66  |  Train Loss: 0.1124628484249115  |
Batch: 67  |  Train Loss: 0.12878358364105225  |
Batch: 68  |  Train Loss: 0.17784367501735687  |
Batch: 69  |  Train Loss: 0.1899057775735855  |
Batch: 70  |  Train Loss: 0.16980689764022827  |
Batch: 71  |  Train Loss: 0.21041519939899445  |
Batch: 72  |  Train Loss: 0.11722306907176971  |
Batch: 73  |  Train Loss: 0.10339854657649994  |
Batch: 74  |  Train Loss: 0.17917528748512268  |
Batch: 75  |  Train Loss: 0.20312733948230743  |
Batch: 76  |  Train Loss: 0.11626723408699036  |
Batch: 77  |  Train Loss: 0.09143871814012527  |
Batch: 78  |  Train Loss: 0.17020578682422638  |
Batch: 79  |  Train Loss: 0.15063372254371643  |
Batch: 80  |  Train Loss: 0.11804364621639252  |
Batch: 81  |  Train Loss: 0.4659475088119507  |
Batch: 82  |  Train Loss: 0.08074162155389786  |
Batch: 83  |  Train Loss: 0.18931585550308228  |
Batch: 84  |  Train Loss: 0.14277932047843933  |
Batch: 85  |  Train Loss: 0.16616928577423096  |
Batch: 86  |  Train Loss: 0.11715149134397507  |
Batch: 87  |  Train Loss: 0.12709076702594757  |
Batch: 88  |  Train Loss: 0.17621742188930511  |
Batch: 89  |  Train Loss: 0.16739849746227264  |
Batch: 90  |  Train Loss: 0.2672371566295624  |
Batch: 91  |  Train Loss: 0.2093118280172348  |
Batch: 92  |  Train Loss: 0.18638332188129425  |
Batch: 93  |  Train Loss: 0.17678266763687134  |
Batch: 94  |  Train Loss: 0.11003179848194122  |
Batch: 95  |  Train Loss: 0.10066825896501541  |
Batch: 96  |  Train Loss: 0.18748947978019714  |
Batch: 97  |  Train Loss: 0.17863303422927856  |
Batch: 98  |  Train Loss: 0.1157970204949379  |
Batch: 99  |  Train Loss: 0.12607410550117493  |
Batch: 100  |  Train Loss: 0.17947328090667725  |
Batch: 101  |  Train Loss: 0.1261015683412552  |
Batch: 102  |  Train Loss: 0.1420799344778061  |
Batch: 103  |  Train Loss: 0.23917101323604584  |
Batch: 104  |  Train Loss: 0.14212603867053986  |
Batch: 105  |  Train Loss: 0.15128079056739807  |
Batch: 106  |  Train Loss: 0.20814090967178345  |
Batch: 107  |  Train Loss: 0.2718331217765808  |
Batch: 108  |  Train Loss: 0.26166775822639465  |
Batch: 109  |  Train Loss: 0.10575775057077408  |
Batch: 110  |  Train Loss: 0.16745829582214355  |
Batch: 111  |  Train Loss: 0.26454317569732666  |
Batch: 112  |  Train Loss: 0.19054870307445526  |
Batch: 113  |  Train Loss: 0.29237163066864014  |
Batch: 114  |  Train Loss: 0.1499515324831009  |
Batch: 115  |  Train Loss: 0.16066023707389832  |
Batch: 116  |  Train Loss: 0.15839384496212006  |
Batch: 117  |  Train Loss: 0.17081379890441895  |
Batch: 118  |  Train Loss: 0.14908704161643982  |
Batch: 119  |  Train Loss: 0.08312728255987167  |
Batch: 120  |  Train Loss: 0.16452926397323608  |
Batch: 121  |  Train Loss: 0.2037716954946518  |
Batch: 122  |  Train Loss: 0.11884690821170807  |
Batch: 123  |  Train Loss: 0.25558599829673767  |
Batch: 124  |  Train Loss: 0.11195072531700134  |
Batch: 125  |  Train Loss: 0.17053556442260742  |
Batch: 126  |  Train Loss: 0.16688492894172668  |
Batch: 127  |  Train Loss: 0.18030408024787903  |
Batch: 128  |  Train Loss: 0.1718587428331375  |
Batch: 129  |  Train Loss: 0.11003205925226212  |
Batch: 130  |  Train Loss: 0.2497626543045044  |
Batch: 131  |  Train Loss: 0.16744203865528107  |
Batch: 132  |  Train Loss: 0.27315807342529297  |
Batch: 133  |  Train Loss: 0.21478596329689026  |
Batch: 134  |  Train Loss: 0.2529410123825073  |
Batch: 135  |  Train Loss: 0.16784699261188507  |
Batch: 136  |  Train Loss: 0.11779724061489105  |
Batch: 137  |  Train Loss: 0.08169271796941757  |
Batch: 138  |  Train Loss: 0.2419557273387909  |
Batch: 139  |  Train Loss: 0.08712317794561386  |
Batch: 140  |  Train Loss: 0.27396950125694275  |
Batch: 141  |  Train Loss: 0.2250688225030899  |
Batch: 142  |  Train Loss: 0.1495789736509323  |
Batch: 143  |  Train Loss: 0.08655770123004913  |
Batch: 144  |  Train Loss: 0.1448216736316681  |
Batch: 145  |  Train Loss: 0.18113131821155548  |
Batch: 146  |  Train Loss: 0.17123235762119293  |
Batch: 147  |  Train Loss: 0.26066964864730835  |
Batch: 148  |  Train Loss: 0.17749977111816406  |
Batch: 149  |  Train Loss: 0.11679045855998993  |
Batch: 150  |  Train Loss: 0.11991617828607559  |
Batch: 151  |  Train Loss: 0.2396565079689026  |
Batch: 152  |  Train Loss: 0.1755037009716034  |
Batch: 153  |  Train Loss: 0.29536646604537964  |
Batch: 154  |  Train Loss: 0.19163282215595245  |
Batch: 155  |  Train Loss: 0.15030689537525177  |
Batch: 156  |  Train Loss: 0.13981370627880096  |
Batch: 157  |  Train Loss: 0.19784870743751526  |
Batch: 158  |  Train Loss: 0.1286366581916809  |
Batch: 159  |  Train Loss: 0.16789506375789642  |
Batch: 160  |  Train Loss: 0.1272406429052353  |
Batch: 161  |  Train Loss: 0.156815305352211  |
Batch: 162  |  Train Loss: 0.12072735279798508  |
Batch: 163  |  Train Loss: 0.18962544202804565  |
Batch: 164  |  Train Loss: 0.15360452234745026  |
Batch: 165  |  Train Loss: 0.1984752118587494  |
Batch: 166  |  Train Loss: 0.13834251463413239  |
Batch: 167  |  Train Loss: 0.10650024563074112  |
Batch: 168  |  Train Loss: 0.08716275542974472  |
Batch: 169  |  Train Loss: 0.16511642932891846  |
Batch: 170  |  Train Loss: 0.1153722032904625  |
Batch: 171  |  Train Loss: 0.10677700489759445  |
Batch: 172  |  Train Loss: 0.18638975918293  |
Batch: 173  |  Train Loss: 0.15432608127593994  |
Batch: 174  |  Train Loss: 0.22161895036697388  |
Batch: 175  |  Train Loss: 0.11023920029401779  |
Batch: 176  |  Train Loss: 0.12969017028808594  |
Batch: 177  |  Train Loss: 0.1792464405298233  |
Batch: 178  |  Train Loss: 0.1847909539937973  |
Batch: 179  |  Train Loss: 0.1478123664855957  |
Batch: 180  |  Train Loss: 0.12464914470911026  |
Batch: 181  |  Train Loss: 0.11468080431222916  |
Batch: 182  |  Train Loss: 0.19450606405735016  |
Batch: 183  |  Train Loss: 0.16569900512695312  |
Batch: 184  |  Train Loss: 0.09012039005756378  |
Epoch: 2  |  Train Loss: 0.16882945975741825
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.88it/s]
Binary results:████████████████████████████▉| 1149/1151 [00:50<00:00, 24.17it/s]
################################################################################

Target prec: 0.728
Target recall: 0.437
Target F1: 0.546

Proportional results:
################################################################################

Target prec: 0.604
Target recall: 0.293
Target F1: 0.394

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.95it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.89it/s]
Binary results:████████████████████████████▉| 1149/1151 [00:50<00:00, 25.04it/s]
################################################################################

Target prec: 0.773
Target recall: 0.419
Target F1: 0.544

Proportional results:
################################################################################

Target prec: 0.585
Target recall: 0.256
Target F1: 0.356

################# END OF PIPELINE's RESULTS #################
 15%|██████                                  | 3/20 [52:43<4:58:38, 1054.04s/it]Batch: 0  |  Train Loss: 0.13919922709465027  |
Batch: 1  |  Train Loss: 0.26889991760253906  |
Batch: 2  |  Train Loss: 0.13235437870025635  |
Batch: 3  |  Train Loss: 0.11349324136972427  |
Batch: 4  |  Train Loss: 0.07927608489990234  |
Batch: 5  |  Train Loss: 0.19494204223155975  |
Batch: 6  |  Train Loss: 0.14849823713302612  |
Batch: 7  |  Train Loss: 0.14899992942810059  |
Batch: 8  |  Train Loss: 0.16837045550346375  |
Batch: 9  |  Train Loss: 0.12687255442142487  |
Batch: 10  |  Train Loss: 0.1747853010892868  |
Batch: 11  |  Train Loss: 0.11861303448677063  |
Batch: 12  |  Train Loss: 0.19165457785129547  |
Batch: 13  |  Train Loss: 0.10764385014772415  |
Batch: 14  |  Train Loss: 0.42217013239860535  |
Batch: 15  |  Train Loss: 0.14870451390743256  |
Batch: 16  |  Train Loss: 0.10867460817098618  |
Batch: 17  |  Train Loss: 0.14636307954788208  |
Batch: 18  |  Train Loss: 0.12408731132745743  |
Batch: 19  |  Train Loss: 0.14419607818126678  |
Batch: 20  |  Train Loss: 0.13239158689975739  |
Batch: 21  |  Train Loss: 0.0795394778251648  |
Batch: 22  |  Train Loss: 0.15995587408542633  |
Batch: 23  |  Train Loss: 0.19432717561721802  |
Batch: 24  |  Train Loss: 0.11160130053758621  |
Batch: 25  |  Train Loss: 0.1908961832523346  |
Batch: 26  |  Train Loss: 0.11547791957855225  |
Batch: 27  |  Train Loss: 0.10978168994188309  |
Batch: 28  |  Train Loss: 0.16711483895778656  |
Batch: 29  |  Train Loss: 0.14403121173381805  |
Batch: 30  |  Train Loss: 0.12164538353681564  |
Batch: 31  |  Train Loss: 0.22451145946979523  |
Batch: 32  |  Train Loss: 0.2623610198497772  |
Batch: 33  |  Train Loss: 0.18358241021633148  |
Batch: 34  |  Train Loss: 0.27223411202430725  |
Batch: 35  |  Train Loss: 0.11656401306390762  |
Batch: 36  |  Train Loss: 0.16320979595184326  |
Batch: 37  |  Train Loss: 0.14638656377792358  |
Batch: 38  |  Train Loss: 0.1794646680355072  |
Batch: 39  |  Train Loss: 0.10872677713632584  |
Batch: 40  |  Train Loss: 0.1047525629401207  |
Batch: 41  |  Train Loss: 0.10977903008460999  |
Batch: 42  |  Train Loss: 0.16476020216941833  |
Batch: 43  |  Train Loss: 0.16088321805000305  |
Batch: 44  |  Train Loss: 0.14629845321178436  |
Batch: 45  |  Train Loss: 0.16268031299114227  |
Batch: 46  |  Train Loss: 0.15506520867347717  |
Batch: 47  |  Train Loss: 0.07813704758882523  |
Batch: 48  |  Train Loss: 0.21179106831550598  |
Batch: 49  |  Train Loss: 0.1690296232700348  |
Batch: 50  |  Train Loss: 0.08705074340105057  |
Batch: 51  |  Train Loss: 0.11912919580936432  |
Batch: 52  |  Train Loss: 0.0963289812207222  |
Batch: 53  |  Train Loss: 0.07730676978826523  |
Batch: 54  |  Train Loss: 0.10087376832962036  |
Batch: 55  |  Train Loss: 0.17272089421749115  |
Batch: 56  |  Train Loss: 0.14982251822948456  |
Batch: 57  |  Train Loss: 0.09432661533355713  |
Batch: 58  |  Train Loss: 0.1301424354314804  |
Batch: 59  |  Train Loss: 0.18688294291496277  |
Batch: 60  |  Train Loss: 0.08379048109054565  |
Batch: 61  |  Train Loss: 0.16282425820827484  |
Batch: 62  |  Train Loss: 0.13377192616462708  |
Batch: 63  |  Train Loss: 0.10494951158761978  |
Batch: 64  |  Train Loss: 0.10145623236894608  |
Batch: 65  |  Train Loss: 0.10068275034427643  |
Batch: 66  |  Train Loss: 0.12192366272211075  |
Batch: 67  |  Train Loss: 0.0875743106007576  |
Batch: 68  |  Train Loss: 0.187982976436615  |
Batch: 69  |  Train Loss: 0.11893805861473083  |
Batch: 70  |  Train Loss: 0.10262257605791092  |
Batch: 71  |  Train Loss: 0.08354306221008301  |
Batch: 72  |  Train Loss: 0.17740890383720398  |
Batch: 73  |  Train Loss: 0.10222459584474564  |
Batch: 74  |  Train Loss: 0.10901381075382233  |
Batch: 75  |  Train Loss: 0.13903093338012695  |
Batch: 76  |  Train Loss: 0.21395501494407654  |
Batch: 77  |  Train Loss: 0.09095030277967453  |
Batch: 78  |  Train Loss: 0.1926971673965454  |
Batch: 79  |  Train Loss: 0.13605186343193054  |
Batch: 80  |  Train Loss: 0.13925109803676605  |
Batch: 81  |  Train Loss: 0.10597849637269974  |
Batch: 82  |  Train Loss: 0.13815584778785706  |
Batch: 83  |  Train Loss: 0.14410515129566193  |
Batch: 84  |  Train Loss: 0.06465459614992142  |
Batch: 85  |  Train Loss: 0.08972859382629395  |
Batch: 86  |  Train Loss: 0.23173904418945312  |
Batch: 87  |  Train Loss: 0.11501585692167282  |
Batch: 88  |  Train Loss: 0.3474801480770111  |
Batch: 89  |  Train Loss: 0.12639892101287842  |
Batch: 90  |  Train Loss: 0.10965472459793091  |
Batch: 91  |  Train Loss: 0.107749804854393  |
Batch: 92  |  Train Loss: 0.09168581664562225  |
Batch: 93  |  Train Loss: 0.14270944893360138  |
Batch: 94  |  Train Loss: 0.15054620802402496  |
Batch: 95  |  Train Loss: 0.13429942727088928  |
Batch: 96  |  Train Loss: 0.13748888671398163  |
Batch: 97  |  Train Loss: 0.07342695444822311  |
Batch: 98  |  Train Loss: 0.13061511516571045  |
Batch: 99  |  Train Loss: 0.21218842267990112  |
Batch: 100  |  Train Loss: 0.10662167519330978  |
Batch: 101  |  Train Loss: 0.0796772837638855  |
Batch: 102  |  Train Loss: 0.14518211781978607  |
Batch: 103  |  Train Loss: 0.11915576457977295  |
Batch: 104  |  Train Loss: 0.11029185354709625  |
Batch: 105  |  Train Loss: 0.10164734721183777  |
Batch: 106  |  Train Loss: 0.08458133041858673  |
Batch: 107  |  Train Loss: 0.07017124444246292  |
Batch: 108  |  Train Loss: 0.12139354646205902  |
Batch: 109  |  Train Loss: 0.13387784361839294  |
Batch: 110  |  Train Loss: 0.16390059888362885  |
Batch: 111  |  Train Loss: 0.16445450484752655  |
Batch: 112  |  Train Loss: 0.12713120877742767  |
Batch: 113  |  Train Loss: 0.1749538779258728  |
Batch: 114  |  Train Loss: 0.13868209719657898  |
Batch: 115  |  Train Loss: 0.19748160243034363  |
Batch: 116  |  Train Loss: 0.1866331547498703  |
Batch: 117  |  Train Loss: 0.14006800949573517  |
Batch: 118  |  Train Loss: 0.11913464218378067  |
Batch: 119  |  Train Loss: 0.131076380610466  |
Batch: 120  |  Train Loss: 0.1374952644109726  |
Batch: 121  |  Train Loss: 0.18042203783988953  |
Batch: 122  |  Train Loss: 0.1280706375837326  |
Batch: 123  |  Train Loss: 0.1738176941871643  |
Batch: 124  |  Train Loss: 0.11869921535253525  |
Batch: 125  |  Train Loss: 0.1047600656747818  |
Batch: 126  |  Train Loss: 0.17317400872707367  |
Batch: 127  |  Train Loss: 0.1356852799654007  |
Batch: 128  |  Train Loss: 0.07342589646577835  |
Batch: 129  |  Train Loss: 0.14089460670948029  |
Batch: 130  |  Train Loss: 0.15630772709846497  |
Batch: 131  |  Train Loss: 0.17180204391479492  |
Batch: 132  |  Train Loss: 0.11667835712432861  |
Batch: 133  |  Train Loss: 0.11718209832906723  |
Batch: 134  |  Train Loss: 0.1586405634880066  |
Batch: 135  |  Train Loss: 0.10605350881814957  |
Batch: 136  |  Train Loss: 0.13809584081172943  |
Batch: 137  |  Train Loss: 0.075531966984272  |
Batch: 138  |  Train Loss: 0.08379827439785004  |
Batch: 139  |  Train Loss: 0.17023739218711853  |
Batch: 140  |  Train Loss: 0.1254444569349289  |
Batch: 141  |  Train Loss: 0.08169367164373398  |
Batch: 142  |  Train Loss: 0.07440082728862762  |
Batch: 143  |  Train Loss: 0.03867638483643532  |
Batch: 144  |  Train Loss: 0.16349148750305176  |
Batch: 145  |  Train Loss: 0.11803256720304489  |
Batch: 146  |  Train Loss: 0.17483359575271606  |
Batch: 147  |  Train Loss: 0.12543140351772308  |
Batch: 148  |  Train Loss: 0.1166023313999176  |
Batch: 149  |  Train Loss: 0.09492307901382446  |
Batch: 150  |  Train Loss: 0.12351632863283157  |
Batch: 151  |  Train Loss: 0.1225142702460289  |
Batch: 152  |  Train Loss: 0.22505943477153778  |
Batch: 153  |  Train Loss: 0.1305614709854126  |
Batch: 154  |  Train Loss: 0.17305633425712585  |
Batch: 155  |  Train Loss: 0.13464175164699554  |
Batch: 156  |  Train Loss: 0.08106397837400436  |
Batch: 157  |  Train Loss: 0.1310228705406189  |
Batch: 158  |  Train Loss: 0.14017516374588013  |
Batch: 159  |  Train Loss: 0.11332759261131287  |
Batch: 160  |  Train Loss: 0.14202605187892914  |
Batch: 161  |  Train Loss: 0.10449212789535522  |
Batch: 162  |  Train Loss: 0.34353145956993103  |
Batch: 163  |  Train Loss: 0.17612309753894806  |
Batch: 164  |  Train Loss: 0.12277869135141373  |
Batch: 165  |  Train Loss: 0.04597030580043793  |
Batch: 166  |  Train Loss: 0.2043207585811615  |
Batch: 167  |  Train Loss: 0.16663199663162231  |
Batch: 168  |  Train Loss: 0.09856081008911133  |
Batch: 169  |  Train Loss: 0.11178012192249298  |
Batch: 170  |  Train Loss: 0.1492493599653244  |
Batch: 171  |  Train Loss: 0.1140415146946907  |
Batch: 172  |  Train Loss: 0.09383860230445862  |
Batch: 173  |  Train Loss: 0.08813050389289856  |
Batch: 174  |  Train Loss: 0.2360459417104721  |
Batch: 175  |  Train Loss: 0.1549086719751358  |
Batch: 176  |  Train Loss: 0.13151252269744873  |
Batch: 177  |  Train Loss: 0.14738115668296814  |
Batch: 178  |  Train Loss: 0.062128301709890366  |
Batch: 179  |  Train Loss: 0.12190751731395721  |
Batch: 180  |  Train Loss: 0.10770980268716812  |
Batch: 181  |  Train Loss: 0.1499071568250656  |
Batch: 182  |  Train Loss: 0.12804566323757172  |
Batch: 183  |  Train Loss: 0.13142870366573334  |
Batch: 184  |  Train Loss: 0.09992297738790512  |
Epoch: 3  |  Train Loss: 0.13843978353448816
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.71it/s]
Binary results:█████████████████████████████| 1151/1151 [00:50<00:00, 22.30it/s]
################################################################################

Target prec: 0.610
Target recall: 0.629
Target F1: 0.619

Proportional results:
################################################################################

Target prec: 0.548
Target recall: 0.459
Target F1: 0.500

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.83it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.89it/s]
Binary results:████████████████████████████▉| 1150/1151 [00:50<00:00, 21.64it/s]
################################################################################

Target prec: 0.672
Target recall: 0.573
Target F1: 0.618

Proportional results:
################################################################################

Target prec: 0.549
Target recall: 0.364
Target F1: 0.438

################# END OF PIPELINE's RESULTS #################
 20%|███████▌                              | 4/20 [1:10:31<4:42:35, 1059.72s/it]Batch: 0  |  Train Loss: 0.1429641991853714  |
Batch: 1  |  Train Loss: 0.12368082255125046  |
Batch: 2  |  Train Loss: 0.09061019867658615  |
Batch: 3  |  Train Loss: 0.06602839380502701  |
Batch: 4  |  Train Loss: 0.09553730487823486  |
Batch: 5  |  Train Loss: 0.14053688943386078  |
Batch: 6  |  Train Loss: 0.11535301059484482  |
Batch: 7  |  Train Loss: 0.08193464577198029  |
Batch: 8  |  Train Loss: 0.08078603446483612  |
Batch: 9  |  Train Loss: 0.16688591241836548  |
Batch: 10  |  Train Loss: 0.10956086963415146  |
Batch: 11  |  Train Loss: 0.09918247908353806  |
Batch: 12  |  Train Loss: 0.14629776775836945  |
Batch: 13  |  Train Loss: 0.14637185633182526  |
Batch: 14  |  Train Loss: 0.14256764948368073  |
Batch: 15  |  Train Loss: 0.13050171732902527  |
Batch: 16  |  Train Loss: 0.11177708208560944  |
Batch: 17  |  Train Loss: 0.08263777196407318  |
Batch: 18  |  Train Loss: 0.13106383383274078  |
Batch: 19  |  Train Loss: 0.12144706398248672  |
Batch: 20  |  Train Loss: 0.06107788905501366  |
Batch: 21  |  Train Loss: 0.06225961074233055  |
Batch: 22  |  Train Loss: 0.07279922068119049  |
Batch: 23  |  Train Loss: 0.09086430072784424  |
Batch: 24  |  Train Loss: 0.15332752466201782  |
Batch: 25  |  Train Loss: 0.13571317493915558  |
Batch: 26  |  Train Loss: 0.07686648517847061  |
Batch: 27  |  Train Loss: 0.08935657888650894  |
Batch: 28  |  Train Loss: 0.08742722123861313  |
Batch: 29  |  Train Loss: 0.0878988578915596  |
Batch: 30  |  Train Loss: 0.12302188575267792  |
Batch: 31  |  Train Loss: 0.09772642701864243  |
Batch: 32  |  Train Loss: 0.06028870493173599  |
Batch: 33  |  Train Loss: 0.10643765330314636  |
Batch: 34  |  Train Loss: 0.06763011962175369  |
Batch: 35  |  Train Loss: 0.0714484378695488  |
Batch: 36  |  Train Loss: 0.10565003752708435  |
Batch: 37  |  Train Loss: 0.08850566297769547  |
Batch: 38  |  Train Loss: 0.04503713920712471  |
Batch: 39  |  Train Loss: 0.17103075981140137  |
Batch: 40  |  Train Loss: 0.10213588923215866  |
Batch: 41  |  Train Loss: 0.10773543268442154  |
Batch: 42  |  Train Loss: 0.1280280202627182  |
Batch: 43  |  Train Loss: 0.09727977961301804  |
Batch: 44  |  Train Loss: 0.08586093038320541  |
Batch: 45  |  Train Loss: 0.09988944977521896  |
Batch: 46  |  Train Loss: 0.12354421615600586  |
Batch: 47  |  Train Loss: 0.05512749031186104  |
Batch: 48  |  Train Loss: 0.10854128003120422  |
Batch: 49  |  Train Loss: 0.1527758538722992  |
Batch: 50  |  Train Loss: 0.14773622155189514  |
Batch: 51  |  Train Loss: 0.1201363131403923  |
Batch: 52  |  Train Loss: 0.08236539363861084  |
Batch: 53  |  Train Loss: 0.17234547436237335  |
Batch: 54  |  Train Loss: 0.15692657232284546  |
Batch: 55  |  Train Loss: 0.20686636865139008  |
Batch: 56  |  Train Loss: 0.11784470081329346  |
Batch: 57  |  Train Loss: 0.0914507806301117  |
Batch: 58  |  Train Loss: 0.12694896757602692  |
Batch: 59  |  Train Loss: 0.08776404708623886  |
Batch: 60  |  Train Loss: 0.14246273040771484  |
Batch: 61  |  Train Loss: 0.1611897349357605  |
Batch: 62  |  Train Loss: 0.0782853439450264  |
Batch: 63  |  Train Loss: 0.20221704244613647  |
Batch: 64  |  Train Loss: 0.14325566589832306  |
Batch: 65  |  Train Loss: 0.09753476083278656  |
Batch: 66  |  Train Loss: 0.14716079831123352  |
Batch: 67  |  Train Loss: 0.11397445946931839  |
Batch: 68  |  Train Loss: 0.24766653776168823  |
Batch: 69  |  Train Loss: 0.12503427267074585  |
Batch: 70  |  Train Loss: 0.08449417352676392  |
Batch: 71  |  Train Loss: 0.06680487096309662  |
Batch: 72  |  Train Loss: 0.09707771986722946  |
Batch: 73  |  Train Loss: 0.08063747733831406  |
Batch: 74  |  Train Loss: 0.10709361732006073  |
Batch: 75  |  Train Loss: 0.1271042823791504  |
Batch: 76  |  Train Loss: 0.08604058623313904  |
Batch: 77  |  Train Loss: 0.10430919378995895  |
Batch: 78  |  Train Loss: 0.07834195345640182  |
Batch: 79  |  Train Loss: 0.11680536717176437  |
Batch: 80  |  Train Loss: 0.1025114580988884  |
Batch: 81  |  Train Loss: 0.09617255628108978  |
Batch: 82  |  Train Loss: 0.07889802753925323  |
Batch: 83  |  Train Loss: 0.08469103276729584  |
Batch: 84  |  Train Loss: 0.11985214799642563  |
Batch: 85  |  Train Loss: 0.12137759476900101  |
Batch: 86  |  Train Loss: 0.11620373278856277  |
Batch: 87  |  Train Loss: 0.08055253326892853  |
Batch: 88  |  Train Loss: 0.0876380056142807  |
Batch: 89  |  Train Loss: 0.14848361909389496  |
Batch: 90  |  Train Loss: 0.0761101171374321  |
Batch: 91  |  Train Loss: 0.13871760666370392  |
Batch: 92  |  Train Loss: 0.07841859012842178  |
Batch: 93  |  Train Loss: 0.12767906486988068  |
Batch: 94  |  Train Loss: 0.08889172971248627  |
Batch: 95  |  Train Loss: 0.15413439273834229  |
Batch: 96  |  Train Loss: 0.17547129094600677  |
Batch: 97  |  Train Loss: 0.11534669250249863  |
Batch: 98  |  Train Loss: 0.13497613370418549  |
Batch: 99  |  Train Loss: 0.09638790041208267  |
Batch: 100  |  Train Loss: 0.09763245284557343  |
Batch: 101  |  Train Loss: 0.09875655919313431  |
Batch: 102  |  Train Loss: 0.059447359293699265  |
Batch: 103  |  Train Loss: 0.15694168210029602  |
Batch: 104  |  Train Loss: 0.15779244899749756  |
Batch: 105  |  Train Loss: 0.10033726692199707  |
Batch: 106  |  Train Loss: 0.06746946275234222  |
Batch: 107  |  Train Loss: 0.14406900107860565  |
Batch: 108  |  Train Loss: 0.12686561048030853  |
Batch: 109  |  Train Loss: 0.08276298642158508  |
Batch: 110  |  Train Loss: 0.09704943746328354  |
Batch: 111  |  Train Loss: 0.10253676772117615  |
Batch: 112  |  Train Loss: 0.11124201118946075  |
Batch: 113  |  Train Loss: 0.08094503730535507  |
Batch: 114  |  Train Loss: 0.1528577208518982  |
Batch: 115  |  Train Loss: 0.09607695788145065  |
Batch: 116  |  Train Loss: 0.13500815629959106  |
Batch: 117  |  Train Loss: 0.0865187868475914  |
Batch: 118  |  Train Loss: 0.1120510846376419  |
Batch: 119  |  Train Loss: 0.07177412509918213  |
Batch: 120  |  Train Loss: 0.07962853461503983  |
Batch: 121  |  Train Loss: 0.12745600938796997  |
Batch: 122  |  Train Loss: 0.10651944577693939  |
Batch: 123  |  Train Loss: 0.05918734148144722  |
Batch: 124  |  Train Loss: 0.15316811203956604  |
Batch: 125  |  Train Loss: 0.10281214118003845  |
Batch: 126  |  Train Loss: 0.07717515528202057  |
Batch: 127  |  Train Loss: 0.09473925083875656  |
Batch: 128  |  Train Loss: 0.1550721377134323  |
Batch: 129  |  Train Loss: 0.15594303607940674  |
Batch: 130  |  Train Loss: 0.10480319708585739  |
Batch: 131  |  Train Loss: 0.1670839786529541  |
Batch: 132  |  Train Loss: 0.12399635463953018  |
Batch: 133  |  Train Loss: 0.12335814535617828  |
Batch: 134  |  Train Loss: 0.14479704201221466  |
Batch: 135  |  Train Loss: 0.1044914722442627  |
Batch: 136  |  Train Loss: 0.10748883336782455  |
Batch: 137  |  Train Loss: 0.08680348843336105  |
Batch: 138  |  Train Loss: 0.09882574528455734  |
Batch: 139  |  Train Loss: 0.1296093910932541  |
Batch: 140  |  Train Loss: 0.11014135926961899  |
Batch: 141  |  Train Loss: 0.11294713616371155  |
Batch: 142  |  Train Loss: 0.14882437884807587  |
Batch: 143  |  Train Loss: 0.16556379199028015  |
Batch: 144  |  Train Loss: 0.09305807203054428  |
Batch: 145  |  Train Loss: 0.13734130561351776  |
Batch: 146  |  Train Loss: 0.08258192241191864  |
Batch: 147  |  Train Loss: 0.06397400796413422  |
Batch: 148  |  Train Loss: 0.07726089656352997  |
Batch: 149  |  Train Loss: 0.08406641334295273  |
Batch: 150  |  Train Loss: 0.1692311316728592  |
Batch: 151  |  Train Loss: 0.1881944090127945  |
Batch: 152  |  Train Loss: 0.10409658402204514  |
Batch: 153  |  Train Loss: 0.11540413647890091  |
Batch: 154  |  Train Loss: 0.16503451764583588  |
Batch: 155  |  Train Loss: 0.12904933094978333  |
Batch: 156  |  Train Loss: 0.12971653044223785  |
Batch: 157  |  Train Loss: 0.10109701752662659  |
Batch: 158  |  Train Loss: 0.10442645102739334  |
Batch: 159  |  Train Loss: 0.09284836798906326  |
Batch: 160  |  Train Loss: 0.16254395246505737  |
Batch: 161  |  Train Loss: 0.10709571838378906  |
Batch: 162  |  Train Loss: 0.09519050270318985  |
Batch: 163  |  Train Loss: 0.0692000761628151  |
Batch: 164  |  Train Loss: 0.14988058805465698  |
Batch: 165  |  Train Loss: 0.10152392834424973  |
Batch: 166  |  Train Loss: 0.08488330990076065  |
Batch: 167  |  Train Loss: 0.1408345103263855  |
Batch: 168  |  Train Loss: 0.06848006695508957  |
Batch: 169  |  Train Loss: 0.1536557674407959  |
Batch: 170  |  Train Loss: 0.14559587836265564  |
Batch: 171  |  Train Loss: 0.1559624820947647  |
Batch: 172  |  Train Loss: 0.09483983367681503  |
Batch: 173  |  Train Loss: 0.1421373039484024  |
Batch: 174  |  Train Loss: 0.1753220111131668  |
Batch: 175  |  Train Loss: 0.10162746161222458  |
Batch: 176  |  Train Loss: 0.14021433889865875  |
Batch: 177  |  Train Loss: 0.07986036688089371  |
Batch: 178  |  Train Loss: 0.09409792721271515  |
Batch: 179  |  Train Loss: 0.17452572286128998  |
Batch: 180  |  Train Loss: 0.12429305911064148  |
Batch: 181  |  Train Loss: 0.11200462281703949  |
Batch: 182  |  Train Loss: 0.0692719891667366  |
Batch: 183  |  Train Loss: 0.07210073620080948  |
Batch: 184  |  Train Loss: 0.09675164520740509  |
Epoch: 4  |  Train Loss: 0.1130229539565138
100%|███████████████████████████████████████| 1151/1151 [00:51<00:00, 22.55it/s]
Binary results:████████████████████████████▉| 1149/1151 [00:50<00:00, 22.35it/s]
################################################################################

Target prec: 0.604
Target recall: 0.625
Target F1: 0.614

Proportional results:
################################################################################

Target prec: 0.505
Target recall: 0.443
Target F1: 0.472

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.84it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.83it/s]
Binary results:████████████████████████████▉| 1150/1151 [00:50<00:00, 24.98it/s]
################################################################################

Target prec: 0.672
Target recall: 0.571
Target F1: 0.617

Proportional results:
################################################################################

Target prec: 0.523
Target recall: 0.358
Target F1: 0.425

################# END OF PIPELINE's RESULTS #################
 25%|█████████▌                            | 5/20 [1:28:22<4:25:55, 1063.70s/it]Batch: 0  |  Train Loss: 0.10203897207975388  |
Batch: 1  |  Train Loss: 0.11415482312440872  |
Batch: 2  |  Train Loss: 0.14361201226711273  |
Batch: 3  |  Train Loss: 0.060089848935604095  |
Batch: 4  |  Train Loss: 0.07121887058019638  |
Batch: 5  |  Train Loss: 0.0945025235414505  |
Batch: 6  |  Train Loss: 0.10701733827590942  |
Batch: 7  |  Train Loss: 0.10846135020256042  |
Batch: 8  |  Train Loss: 0.05317577347159386  |
Batch: 9  |  Train Loss: 0.13730958104133606  |
Batch: 10  |  Train Loss: 0.07024460285902023  |
Batch: 11  |  Train Loss: 0.09404975175857544  |
Batch: 12  |  Train Loss: 0.07181957364082336  |
Batch: 13  |  Train Loss: 0.1017858013510704  |
Batch: 14  |  Train Loss: 0.10874854028224945  |
Batch: 15  |  Train Loss: 0.05264020338654518  |
Batch: 16  |  Train Loss: 0.07812519371509552  |
Batch: 17  |  Train Loss: 0.10594627261161804  |
Batch: 18  |  Train Loss: 0.10642660409212112  |
Batch: 19  |  Train Loss: 0.18589086830615997  |
Batch: 20  |  Train Loss: 0.068924181163311  |
Batch: 21  |  Train Loss: 0.16095173358917236  |
Batch: 22  |  Train Loss: 0.049589842557907104  |
Batch: 23  |  Train Loss: 0.08073236048221588  |
Batch: 24  |  Train Loss: 0.07732643932104111  |
Batch: 25  |  Train Loss: 0.07249833643436432  |
Batch: 26  |  Train Loss: 0.11758455634117126  |
Batch: 27  |  Train Loss: 0.07746364921331406  |
Batch: 28  |  Train Loss: 0.0984719917178154  |
Batch: 29  |  Train Loss: 0.03992884233593941  |
Batch: 30  |  Train Loss: 0.06392442435026169  |
Batch: 31  |  Train Loss: 0.18640245497226715  |
Batch: 32  |  Train Loss: 0.10081934928894043  |
Batch: 33  |  Train Loss: 0.11173990368843079  |
Batch: 34  |  Train Loss: 0.09941233694553375  |
Batch: 35  |  Train Loss: 0.10014495253562927  |
Batch: 36  |  Train Loss: 0.19487209618091583  |
Batch: 37  |  Train Loss: 0.08401741087436676  |
Batch: 38  |  Train Loss: 0.13783910870552063  |
Batch: 39  |  Train Loss: 0.10844265669584274  |
Batch: 40  |  Train Loss: 0.05099032446742058  |
Batch: 41  |  Train Loss: 0.09813474118709564  |
Batch: 42  |  Train Loss: 0.04448513686656952  |
Batch: 43  |  Train Loss: 0.08603981137275696  |
Batch: 44  |  Train Loss: 0.06917580217123032  |
Batch: 45  |  Train Loss: 0.07001906633377075  |
Batch: 46  |  Train Loss: 0.12630359828472137  |
Batch: 47  |  Train Loss: 0.0845523476600647  |
Batch: 48  |  Train Loss: 0.07408080250024796  |
Batch: 49  |  Train Loss: 0.06480933725833893  |
Batch: 50  |  Train Loss: 0.11420730501413345  |
Batch: 51  |  Train Loss: 0.05083061009645462  |
Batch: 52  |  Train Loss: 0.13008925318717957  |
Batch: 53  |  Train Loss: 0.10407039523124695  |
Batch: 54  |  Train Loss: 0.03315132483839989  |
Batch: 55  |  Train Loss: 0.10908840596675873  |
Batch: 56  |  Train Loss: 0.10675503313541412  |
Batch: 57  |  Train Loss: 0.0797157734632492  |
Batch: 58  |  Train Loss: 0.11527635902166367  |
Batch: 59  |  Train Loss: 0.09391523897647858  |
Batch: 60  |  Train Loss: 0.15532609820365906  |
Batch: 61  |  Train Loss: 0.0931900143623352  |
Batch: 62  |  Train Loss: 0.11091209203004837  |
Batch: 63  |  Train Loss: 0.08671300113201141  |
Batch: 64  |  Train Loss: 0.07989124953746796  |
Batch: 65  |  Train Loss: 0.05050066113471985  |
Batch: 66  |  Train Loss: 0.09243863821029663  |
Batch: 67  |  Train Loss: 0.07849807292222977  |
Batch: 68  |  Train Loss: 0.08615003526210785  |
Batch: 69  |  Train Loss: 0.07068538665771484  |
Batch: 70  |  Train Loss: 0.07414937764406204  |
Batch: 71  |  Train Loss: 0.16339507699012756  |
Batch: 72  |  Train Loss: 0.11612483859062195  |
Batch: 73  |  Train Loss: 0.08045686036348343  |
Batch: 74  |  Train Loss: 0.0877578929066658  |
Batch: 75  |  Train Loss: 0.0896192342042923  |
Batch: 76  |  Train Loss: 0.09555274993181229  |
Batch: 77  |  Train Loss: 0.05017967149615288  |
Batch: 78  |  Train Loss: 0.11655686050653458  |
Batch: 79  |  Train Loss: 0.04761921241879463  |
Batch: 80  |  Train Loss: 0.09137286245822906  |
Batch: 81  |  Train Loss: 0.10258419066667557  |
Batch: 82  |  Train Loss: 0.04805852845311165  |
Batch: 83  |  Train Loss: 0.07076601684093475  |
Batch: 84  |  Train Loss: 0.09453040361404419  |
Batch: 85  |  Train Loss: 0.10032281279563904  |
Batch: 86  |  Train Loss: 0.13095392286777496  |
Batch: 87  |  Train Loss: 0.07729054242372513  |
Batch: 88  |  Train Loss: 0.059442684054374695  |
Batch: 89  |  Train Loss: 0.10704787075519562  |
Batch: 90  |  Train Loss: 0.07713966071605682  |
Batch: 91  |  Train Loss: 0.14574860036373138  |
Batch: 92  |  Train Loss: 0.07643350213766098  |
Batch: 93  |  Train Loss: 0.0671510100364685  |
Batch: 94  |  Train Loss: 0.1381891667842865  |
Batch: 95  |  Train Loss: 0.1008138582110405  |
Batch: 96  |  Train Loss: 0.0858721137046814  |
Batch: 97  |  Train Loss: 0.11530516296625137  |
Batch: 98  |  Train Loss: 0.09804769605398178  |
Batch: 99  |  Train Loss: 0.10243681818246841  |
Batch: 100  |  Train Loss: 0.10645922273397446  |
Batch: 101  |  Train Loss: 0.08026933670043945  |
Batch: 102  |  Train Loss: 0.06011107191443443  |
Batch: 103  |  Train Loss: 0.10861571133136749  |
Batch: 104  |  Train Loss: 0.09013530611991882  |
Batch: 105  |  Train Loss: 0.07305929064750671  |
Batch: 106  |  Train Loss: 0.07816017419099808  |
Batch: 107  |  Train Loss: 0.06053773686289787  |
Batch: 108  |  Train Loss: 0.14826682209968567  |
Batch: 109  |  Train Loss: 0.10142544656991959  |
Batch: 110  |  Train Loss: 0.13856138288974762  |
Batch: 111  |  Train Loss: 0.08128499239683151  |
Batch: 112  |  Train Loss: 0.06934861838817596  |
Batch: 113  |  Train Loss: 0.12717466056346893  |
Batch: 114  |  Train Loss: 0.0907374769449234  |
Batch: 115  |  Train Loss: 0.10922529548406601  |
Batch: 116  |  Train Loss: 0.09975489974021912  |
Batch: 117  |  Train Loss: 0.05838489904999733  |
Batch: 118  |  Train Loss: 0.1215159073472023  |
Batch: 119  |  Train Loss: 0.05211300030350685  |
Batch: 120  |  Train Loss: 0.07184826582670212  |
Batch: 121  |  Train Loss: 0.09044676274061203  |
Batch: 122  |  Train Loss: 0.10293684154748917  |
Batch: 123  |  Train Loss: 0.0836942195892334  |
Batch: 124  |  Train Loss: 0.08109112083911896  |
Batch: 125  |  Train Loss: 0.05991356819868088  |
Batch: 126  |  Train Loss: 0.13471582531929016  |
Batch: 127  |  Train Loss: 0.09795700013637543  |
Batch: 128  |  Train Loss: 0.07992644608020782  |
Batch: 129  |  Train Loss: 0.13090434670448303  |
Batch: 130  |  Train Loss: 0.07755323499441147  |
Batch: 131  |  Train Loss: 0.06666260957717896  |
Batch: 132  |  Train Loss: 0.04116620495915413  |
Batch: 133  |  Train Loss: 0.0728694349527359  |
Batch: 134  |  Train Loss: 0.09268517047166824  |
Batch: 135  |  Train Loss: 0.11996515095233917  |
Batch: 136  |  Train Loss: 0.10897980630397797  |
Batch: 137  |  Train Loss: 0.07886148244142532  |
Batch: 138  |  Train Loss: 0.12592677772045135  |
Batch: 139  |  Train Loss: 0.06939470767974854  |
Batch: 140  |  Train Loss: 0.11183953285217285  |
Batch: 141  |  Train Loss: 0.12435697019100189  |
Batch: 142  |  Train Loss: 0.05068051069974899  |
Batch: 143  |  Train Loss: 0.10867074131965637  |
Batch: 144  |  Train Loss: 0.0603942908346653  |
Batch: 145  |  Train Loss: 0.042164452373981476  |
Batch: 146  |  Train Loss: 0.169549360871315  |
Batch: 147  |  Train Loss: 0.09138848632574081  |
Batch: 148  |  Train Loss: 0.08739114552736282  |
Batch: 149  |  Train Loss: 0.054094526916742325  |
Batch: 150  |  Train Loss: 0.11207663267850876  |
Batch: 151  |  Train Loss: 0.07340465486049652  |
Batch: 152  |  Train Loss: 0.12363401055335999  |
Batch: 153  |  Train Loss: 0.09969674795866013  |
Batch: 154  |  Train Loss: 0.11147920787334442  |
Batch: 155  |  Train Loss: 0.04358833283185959  |
Batch: 156  |  Train Loss: 0.10807233303785324  |
Batch: 157  |  Train Loss: 0.05646432936191559  |
Batch: 158  |  Train Loss: 0.1106509119272232  |
Batch: 159  |  Train Loss: 0.05416940152645111  |
Batch: 160  |  Train Loss: 0.10708010941743851  |
Batch: 161  |  Train Loss: 0.06253999471664429  |
Batch: 162  |  Train Loss: 0.0750468373298645  |
Batch: 163  |  Train Loss: 0.11026862263679504  |
Batch: 164  |  Train Loss: 0.06910216063261032  |
Batch: 165  |  Train Loss: 0.07182876765727997  |
Batch: 166  |  Train Loss: 0.1375671923160553  |
Batch: 167  |  Train Loss: 0.06889808177947998  |
Batch: 168  |  Train Loss: 0.05680270493030548  |
Batch: 169  |  Train Loss: 0.1589655727148056  |
Batch: 170  |  Train Loss: 0.08118321746587753  |
Batch: 171  |  Train Loss: 0.08463431894779205  |
Batch: 172  |  Train Loss: 0.10029271990060806  |
Batch: 173  |  Train Loss: 0.07076940685510635  |
Batch: 174  |  Train Loss: 0.08467673510313034  |
Batch: 175  |  Train Loss: 0.09434013068675995  |
Batch: 176  |  Train Loss: 0.07722701877355576  |
Batch: 177  |  Train Loss: 0.07917378842830658  |
Batch: 178  |  Train Loss: 0.0718901976943016  |
Batch: 179  |  Train Loss: 0.1084323599934578  |
Batch: 180  |  Train Loss: 0.07778311520814896  |
Batch: 181  |  Train Loss: 0.06851537525653839  |
Batch: 182  |  Train Loss: 0.03617610037326813  |
Batch: 183  |  Train Loss: 0.08590835332870483  |
Batch: 184  |  Train Loss: 0.1880447119474411  |
Epoch: 5  |  Train Loss: 0.09233953866201478
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.96it/s]
Binary results:████████████████████████████▉| 1149/1151 [00:50<00:00, 23.83it/s]
################################################################################

Target prec: 0.608
Target recall: 0.620
Target F1: 0.614

Proportional results:
################################################################################

Target prec: 0.531
Target recall: 0.455
Target F1: 0.490

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.79it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.88it/s]
Binary results:████████████████████████████▉| 1149/1151 [00:50<00:00, 23.13it/s]
################################################################################

Target prec: 0.680
Target recall: 0.568
Target F1: 0.619

Proportional results:
################################################################################

Target prec: 0.552
Target recall: 0.363
Target F1: 0.438

################# END OF PIPELINE's RESULTS #################
 30%|███████████▍                          | 6/20 [1:46:11<4:08:35, 1065.39s/it]Batch: 0  |  Train Loss: 0.05705726891756058  |
Batch: 1  |  Train Loss: 0.04338410124182701  |
Batch: 2  |  Train Loss: 0.0780174508690834  |
Batch: 3  |  Train Loss: 0.043961819261312485  |
Batch: 4  |  Train Loss: 0.059343189001083374  |
Batch: 5  |  Train Loss: 0.09942125529050827  |
Batch: 6  |  Train Loss: 0.08157208561897278  |
Batch: 7  |  Train Loss: 0.12379898130893707  |
Batch: 8  |  Train Loss: 0.09093432873487473  |
Batch: 9  |  Train Loss: 0.06574765592813492  |
Batch: 10  |  Train Loss: 0.06754244118928909  |
Batch: 11  |  Train Loss: 0.05580341815948486  |
Batch: 12  |  Train Loss: 0.05739862099289894  |
Batch: 13  |  Train Loss: 0.06617545336484909  |
Batch: 14  |  Train Loss: 0.06162822246551514  |
Batch: 15  |  Train Loss: 0.08257688581943512  |
Batch: 16  |  Train Loss: 0.051074620336294174  |
Batch: 17  |  Train Loss: 0.05590002238750458  |
Batch: 18  |  Train Loss: 0.04574645310640335  |
Batch: 19  |  Train Loss: 0.09466627240180969  |
Batch: 20  |  Train Loss: 0.061766840517520905  |
Batch: 21  |  Train Loss: 0.07479061186313629  |
Batch: 22  |  Train Loss: 0.1187487542629242  |
Batch: 23  |  Train Loss: 0.08551802486181259  |
Batch: 24  |  Train Loss: 0.0362863764166832  |
Batch: 25  |  Train Loss: 0.07032155245542526  |
Batch: 26  |  Train Loss: 0.0734679102897644  |
Batch: 27  |  Train Loss: 0.06349223852157593  |
Batch: 28  |  Train Loss: 0.059569746255874634  |
Batch: 29  |  Train Loss: 0.06261438131332397  |
Batch: 30  |  Train Loss: 0.07384848594665527  |
Batch: 31  |  Train Loss: 0.09609104692935944  |
Batch: 32  |  Train Loss: 0.03854347765445709  |
Batch: 33  |  Train Loss: 0.08390720188617706  |
Batch: 34  |  Train Loss: 0.10150831192731857  |
Batch: 35  |  Train Loss: 0.1305321604013443  |
Batch: 36  |  Train Loss: 0.03445000946521759  |
Batch: 37  |  Train Loss: 0.07485394179821014  |
Batch: 38  |  Train Loss: 0.10131117701530457  |
Batch: 39  |  Train Loss: 0.07727522403001785  |
Batch: 40  |  Train Loss: 0.05411955714225769  |
Batch: 41  |  Train Loss: 0.1071675717830658  |
Batch: 42  |  Train Loss: 0.041045110672712326  |
Batch: 43  |  Train Loss: 0.06584205478429794  |
Batch: 44  |  Train Loss: 0.10361304134130478  |
Batch: 45  |  Train Loss: 0.09388009458780289  |
Batch: 46  |  Train Loss: 0.04846050962805748  |
Batch: 47  |  Train Loss: 0.10486321151256561  |
Batch: 48  |  Train Loss: 0.07776904851198196  |
Batch: 49  |  Train Loss: 0.1089809387922287  |
Batch: 50  |  Train Loss: 0.09392429888248444  |
Batch: 51  |  Train Loss: 0.051542919129133224  |
Batch: 52  |  Train Loss: 0.0415295772254467  |
Batch: 53  |  Train Loss: 0.08322487026453018  |
Batch: 54  |  Train Loss: 0.06601735949516296  |
Batch: 55  |  Train Loss: 0.065217986702919  |
Batch: 56  |  Train Loss: 0.045879803597927094  |
Batch: 57  |  Train Loss: 0.07414048910140991  |
Batch: 58  |  Train Loss: 0.0694451630115509  |
Batch: 59  |  Train Loss: 0.06546912342309952  |
Batch: 60  |  Train Loss: 0.11780285835266113  |
Batch: 61  |  Train Loss: 0.14239536225795746  |
Batch: 62  |  Train Loss: 0.07793696224689484  |
Batch: 63  |  Train Loss: 0.0670088604092598  |
Batch: 64  |  Train Loss: 0.13225653767585754  |
Batch: 65  |  Train Loss: 0.046052876859903336  |
Batch: 66  |  Train Loss: 0.06850570440292358  |
Batch: 67  |  Train Loss: 0.08802134543657303  |
Batch: 68  |  Train Loss: 0.1044909879565239  |
Batch: 69  |  Train Loss: 0.09085860103368759  |
Batch: 70  |  Train Loss: 0.04624125361442566  |
Batch: 71  |  Train Loss: 0.06660722941160202  |
Batch: 72  |  Train Loss: 0.0729227215051651  |
Batch: 73  |  Train Loss: 0.08288101851940155  |
Batch: 74  |  Train Loss: 0.09902338683605194  |
Batch: 75  |  Train Loss: 0.09540616720914841  |
Batch: 76  |  Train Loss: 0.07971496134996414  |
Batch: 77  |  Train Loss: 0.06543440371751785  |
Batch: 78  |  Train Loss: 0.051951367408037186  |
Batch: 79  |  Train Loss: 0.10056430101394653  |
Batch: 80  |  Train Loss: 0.08336441963911057  |
Batch: 81  |  Train Loss: 0.09906511008739471  |
Batch: 82  |  Train Loss: 0.1070278063416481  |
Batch: 83  |  Train Loss: 0.06417703628540039  |
Batch: 84  |  Train Loss: 0.0791744813323021  |
Batch: 85  |  Train Loss: 0.08738633245229721  |
Batch: 86  |  Train Loss: 0.09501249343156815  |
Batch: 87  |  Train Loss: 0.07573898881673813  |
Batch: 88  |  Train Loss: 0.075624980032444  |
Batch: 89  |  Train Loss: 0.046276528388261795  |
Batch: 90  |  Train Loss: 0.03863522410392761  |
Batch: 91  |  Train Loss: 0.06742355972528458  |
Batch: 92  |  Train Loss: 0.09647626429796219  |
Batch: 93  |  Train Loss: 0.05966596677899361  |
Batch: 94  |  Train Loss: 0.09781160950660706  |
Batch: 95  |  Train Loss: 0.13304458558559418  |
Batch: 96  |  Train Loss: 0.06701473891735077  |
Batch: 97  |  Train Loss: 0.0647793710231781  |
Batch: 98  |  Train Loss: 0.061969440430402756  |
Batch: 99  |  Train Loss: 0.05395990610122681  |
Batch: 100  |  Train Loss: 0.059197232127189636  |
Batch: 101  |  Train Loss: 0.10505279153585434  |
Batch: 102  |  Train Loss: 0.07774277031421661  |
Batch: 103  |  Train Loss: 0.0844363272190094  |
Batch: 104  |  Train Loss: 0.08530371636152267  |
Batch: 105  |  Train Loss: 0.13578659296035767  |
Batch: 106  |  Train Loss: 0.08080972731113434  |
Batch: 107  |  Train Loss: 0.079536572098732  |
Batch: 108  |  Train Loss: 0.09002390503883362  |
Batch: 109  |  Train Loss: 0.055270832031965256  |
Batch: 110  |  Train Loss: 0.08834230899810791  |
Batch: 111  |  Train Loss: 0.0213263388723135  |
Batch: 112  |  Train Loss: 0.06691661477088928  |
Batch: 113  |  Train Loss: 0.09143234044313431  |
Batch: 114  |  Train Loss: 0.07857132703065872  |
Batch: 115  |  Train Loss: 0.08292369544506073  |
Batch: 116  |  Train Loss: 0.06078706681728363  |
Batch: 117  |  Train Loss: 0.12877139449119568  |
Batch: 118  |  Train Loss: 0.11112504452466965  |
Batch: 119  |  Train Loss: 0.03952774778008461  |
Batch: 120  |  Train Loss: 0.05024469271302223  |
Batch: 121  |  Train Loss: 0.08683667331933975  |
Batch: 122  |  Train Loss: 0.03579992800951004  |
Batch: 123  |  Train Loss: 0.09120891243219376  |
Batch: 124  |  Train Loss: 0.08985445648431778  |
Batch: 125  |  Train Loss: 0.08387643098831177  |
Batch: 126  |  Train Loss: 0.04305644705891609  |
Batch: 127  |  Train Loss: 0.10911797732114792  |
Batch: 128  |  Train Loss: 0.09591975063085556  |
Batch: 129  |  Train Loss: 0.04572351649403572  |
Batch: 130  |  Train Loss: 0.08607268333435059  |
Batch: 131  |  Train Loss: 0.08611571788787842  |
Batch: 132  |  Train Loss: 0.11355258524417877  |
Batch: 133  |  Train Loss: 0.10874451696872711  |
Batch: 134  |  Train Loss: 0.08031004667282104  |
Batch: 135  |  Train Loss: 0.055884793400764465  |
Batch: 136  |  Train Loss: 0.10707439482212067  |
Batch: 137  |  Train Loss: 0.08898963034152985  |
Batch: 138  |  Train Loss: 0.06290899962186813  |
Batch: 139  |  Train Loss: 0.06946557015180588  |
Batch: 140  |  Train Loss: 0.07165703922510147  |
Batch: 141  |  Train Loss: 0.08125486224889755  |
Batch: 142  |  Train Loss: 0.13487932085990906  |
Batch: 143  |  Train Loss: 0.0881526917219162  |
Batch: 144  |  Train Loss: 0.0377466194331646  |
Batch: 145  |  Train Loss: 0.08971673250198364  |
Batch: 146  |  Train Loss: 0.09159214794635773  |
Batch: 147  |  Train Loss: 0.07368603348731995  |
Batch: 148  |  Train Loss: 0.05548744276165962  |
Batch: 149  |  Train Loss: 0.03220662847161293  |
Batch: 150  |  Train Loss: 0.165802001953125  |
Batch: 151  |  Train Loss: 0.1129462942481041  |
Batch: 152  |  Train Loss: 0.06457860767841339  |
Batch: 153  |  Train Loss: 0.06168482452630997  |
Batch: 154  |  Train Loss: 0.09097974002361298  |
Batch: 155  |  Train Loss: 0.04236270859837532  |
Batch: 156  |  Train Loss: 0.03827764838933945  |
Batch: 157  |  Train Loss: 0.15308012068271637  |
Batch: 158  |  Train Loss: 0.044300515204668045  |
Batch: 159  |  Train Loss: 0.08125637471675873  |
Batch: 160  |  Train Loss: 0.048266761004924774  |
Batch: 161  |  Train Loss: 0.05421984940767288  |
Batch: 162  |  Train Loss: 0.07008252292871475  |
Batch: 163  |  Train Loss: 0.11408231407403946  |
Batch: 164  |  Train Loss: 0.12995021045207977  |
Batch: 165  |  Train Loss: 0.058081209659576416  |
Batch: 166  |  Train Loss: 0.1155405342578888  |
Batch: 167  |  Train Loss: 0.1207328662276268  |
Batch: 168  |  Train Loss: 0.0714084804058075  |
Batch: 169  |  Train Loss: 0.08483574539422989  |
Batch: 170  |  Train Loss: 0.11420392245054245  |
Batch: 171  |  Train Loss: 0.06301215291023254  |
Batch: 172  |  Train Loss: 0.06746301054954529  |
Batch: 173  |  Train Loss: 0.07601631432771683  |
Batch: 174  |  Train Loss: 0.06978404521942139  |
Batch: 175  |  Train Loss: 0.20297527313232422  |
Batch: 176  |  Train Loss: 0.055268559604883194  |
Batch: 177  |  Train Loss: 0.08922950178384781  |
Batch: 178  |  Train Loss: 0.0730549618601799  |
Batch: 179  |  Train Loss: 0.06363008171319962  |
Batch: 180  |  Train Loss: 0.02924884669482708  |
Batch: 181  |  Train Loss: 0.09424717724323273  |
Batch: 182  |  Train Loss: 0.07764240354299545  |
Batch: 183  |  Train Loss: 0.03667226433753967  |
Batch: 184  |  Train Loss: 0.07553257793188095  |
Epoch: 6  |  Train Loss: 0.07834031628193082
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.77it/s]
Binary results:████████████████████████████▉| 1149/1151 [00:50<00:00, 24.56it/s]
################################################################################

Target prec: 0.657
Target recall: 0.526
Target F1: 0.584

Proportional results:
################################################################################

Target prec: 0.588
Target recall: 0.390
Target F1: 0.469

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.76it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.88it/s]
Binary results:█████████████████████████████| 1151/1151 [00:50<00:00, 23.90it/s]
################################################################################

Target prec: 0.718
Target recall: 0.484
Target F1: 0.578

Proportional results:
################################################################################

Target prec: 0.596
Target recall: 0.324
Target F1: 0.419

################# END OF PIPELINE's RESULTS #################
 35%|█████████████▎                        | 7/20 [2:03:50<3:50:24, 1063.43s/it]Batch: 0  |  Train Loss: 0.06643074005842209  |
Batch: 1  |  Train Loss: 0.03833884745836258  |
Batch: 2  |  Train Loss: 0.04250531271100044  |
Batch: 3  |  Train Loss: 0.07849486172199249  |
Batch: 4  |  Train Loss: 0.05150420963764191  |
Batch: 5  |  Train Loss: 0.04871669039130211  |
Batch: 6  |  Train Loss: 0.08112629503011703  |
Batch: 7  |  Train Loss: 0.06645990163087845  |
Batch: 8  |  Train Loss: 0.0646962970495224  |
Batch: 9  |  Train Loss: 0.049264948815107346  |
Batch: 10  |  Train Loss: 0.04253260791301727  |
Batch: 11  |  Train Loss: 0.0652271956205368  |
Batch: 12  |  Train Loss: 0.07527685910463333  |
Batch: 13  |  Train Loss: 0.05501975119113922  |
Batch: 14  |  Train Loss: 0.05280812457203865  |
Batch: 15  |  Train Loss: 0.05785958096385002  |
Batch: 16  |  Train Loss: 0.11287785321474075  |
Batch: 17  |  Train Loss: 0.046582140028476715  |
Batch: 18  |  Train Loss: 0.05920951068401337  |
Batch: 19  |  Train Loss: 0.07663683593273163  |
Batch: 20  |  Train Loss: 0.06842274218797684  |
Batch: 21  |  Train Loss: 0.07447364926338196  |
Batch: 22  |  Train Loss: 0.06870570778846741  |
Batch: 23  |  Train Loss: 0.05616936832666397  |
Batch: 24  |  Train Loss: 0.06906524300575256  |
Batch: 25  |  Train Loss: 0.07563648372888565  |
Batch: 26  |  Train Loss: 0.05866518244147301  |
Batch: 27  |  Train Loss: 0.08761516958475113  |
Batch: 28  |  Train Loss: 0.07315102964639664  |
Batch: 29  |  Train Loss: 0.07616312801837921  |
Batch: 30  |  Train Loss: 0.10684405267238617  |
Batch: 31  |  Train Loss: 0.03466741740703583  |
Batch: 32  |  Train Loss: 0.06570670008659363  |
Batch: 33  |  Train Loss: 0.10090339183807373  |
Batch: 34  |  Train Loss: 0.05593767762184143  |
Batch: 35  |  Train Loss: 0.07318077981472015  |
Batch: 36  |  Train Loss: 0.04091760516166687  |
Batch: 37  |  Train Loss: 0.035245198756456375  |
Batch: 38  |  Train Loss: 0.0858164131641388  |
Batch: 39  |  Train Loss: 0.05343163013458252  |
Batch: 40  |  Train Loss: 0.06854802370071411  |
Batch: 41  |  Train Loss: 0.02846115082502365  |
Batch: 42  |  Train Loss: 0.0723142996430397  |
Batch: 43  |  Train Loss: 0.056589074432849884  |
Batch: 44  |  Train Loss: 0.044457562267780304  |
Batch: 45  |  Train Loss: 0.08053706586360931  |
Batch: 46  |  Train Loss: 0.050645917654037476  |
Batch: 47  |  Train Loss: 0.0610848143696785  |
Batch: 48  |  Train Loss: 0.0527871809899807  |
Batch: 49  |  Train Loss: 0.06984330713748932  |
Batch: 50  |  Train Loss: 0.06699609011411667  |
Batch: 51  |  Train Loss: 0.061594218015670776  |
Batch: 52  |  Train Loss: 0.06722182035446167  |
Batch: 53  |  Train Loss: 0.0429205596446991  |
Batch: 54  |  Train Loss: 0.036672040820121765  |
Batch: 55  |  Train Loss: 0.07708201557397842  |
Batch: 56  |  Train Loss: 0.09364784508943558  |
Batch: 57  |  Train Loss: 0.04169871658086777  |
Batch: 58  |  Train Loss: 0.10014771670103073  |
Batch: 59  |  Train Loss: 0.07658134400844574  |
Batch: 60  |  Train Loss: 0.022777507081627846  |
Batch: 61  |  Train Loss: 0.09587764739990234  |
Batch: 62  |  Train Loss: 0.08388541638851166  |
Batch: 63  |  Train Loss: 0.05749240517616272  |
Batch: 64  |  Train Loss: 0.06523261219263077  |
Batch: 65  |  Train Loss: 0.09345734864473343  |
Batch: 66  |  Train Loss: 0.058537065982818604  |
Batch: 67  |  Train Loss: 0.0747859850525856  |
Batch: 68  |  Train Loss: 0.1826293021440506  |
Batch: 69  |  Train Loss: 0.07401259243488312  |
Batch: 70  |  Train Loss: 0.07271645218133926  |
Batch: 71  |  Train Loss: 0.05039481818675995  |
Batch: 72  |  Train Loss: 0.041382551193237305  |
Batch: 73  |  Train Loss: 0.06502611935138702  |
Batch: 74  |  Train Loss: 0.04347337409853935  |
Batch: 75  |  Train Loss: 0.0691741332411766  |
Batch: 76  |  Train Loss: 0.07994413375854492  |
Batch: 77  |  Train Loss: 0.10846738517284393  |
Batch: 78  |  Train Loss: 0.07594205439090729  |
Batch: 79  |  Train Loss: 0.045081086456775665  |
Batch: 80  |  Train Loss: 0.054289329797029495  |
Batch: 81  |  Train Loss: 0.04496731609106064  |
Batch: 82  |  Train Loss: 0.07498172670602798  |
Batch: 83  |  Train Loss: 0.03389738127589226  |
Batch: 84  |  Train Loss: 0.03344101831316948  |
Batch: 85  |  Train Loss: 0.08176185935735703  |
Batch: 86  |  Train Loss: 0.09907329082489014  |
Batch: 87  |  Train Loss: 0.06941425800323486  |
Batch: 88  |  Train Loss: 0.05647962540388107  |
Batch: 89  |  Train Loss: 0.05950094386935234  |
Batch: 90  |  Train Loss: 0.06634865701198578  |
Batch: 91  |  Train Loss: 0.06656205654144287  |
Batch: 92  |  Train Loss: 0.06089482828974724  |
Batch: 93  |  Train Loss: 0.055657729506492615  |
Batch: 94  |  Train Loss: 0.05988522619009018  |
Batch: 95  |  Train Loss: 0.06304843723773956  |
Batch: 96  |  Train Loss: 0.026448074728250504  |
Batch: 97  |  Train Loss: 0.05131500959396362  |
Batch: 98  |  Train Loss: 0.07720272243022919  |
Batch: 99  |  Train Loss: 0.07303567230701447  |
Batch: 100  |  Train Loss: 0.07135164737701416  |
Batch: 101  |  Train Loss: 0.09004326164722443  |
Batch: 102  |  Train Loss: 0.07034971565008163  |
Batch: 103  |  Train Loss: 0.040346164256334305  |
Batch: 104  |  Train Loss: 0.07642446458339691  |
Batch: 105  |  Train Loss: 0.05760534480214119  |
Batch: 106  |  Train Loss: 0.06472696363925934  |
Batch: 107  |  Train Loss: 0.039716411381959915  |
Batch: 108  |  Train Loss: 0.05351020395755768  |
Batch: 109  |  Train Loss: 0.07843606173992157  |
Batch: 110  |  Train Loss: 0.08187352865934372  |
Batch: 111  |  Train Loss: 0.022124966606497765  |
Batch: 112  |  Train Loss: 0.10056481510400772  |
Batch: 113  |  Train Loss: 0.02055603638291359  |
Batch: 114  |  Train Loss: 0.09677845239639282  |
Batch: 115  |  Train Loss: 0.13225939869880676  |
Batch: 116  |  Train Loss: 0.05590009689331055  |
Batch: 117  |  Train Loss: 0.058558087795972824  |
Batch: 118  |  Train Loss: 0.11048363149166107  |
Batch: 119  |  Train Loss: 0.0668693333864212  |
Batch: 120  |  Train Loss: 0.040639955550432205  |
Batch: 121  |  Train Loss: 0.058567218482494354  |
Batch: 122  |  Train Loss: 0.03368431329727173  |
Batch: 123  |  Train Loss: 0.07475487887859344  |
Batch: 124  |  Train Loss: 0.06294403970241547  |
Batch: 125  |  Train Loss: 0.08980116248130798  |
Batch: 126  |  Train Loss: 0.11259770393371582  |
Batch: 127  |  Train Loss: 0.05851433053612709  |
Batch: 128  |  Train Loss: 0.06970880180597305  |
Batch: 129  |  Train Loss: 0.05106573551893234  |
Batch: 130  |  Train Loss: 0.09655705839395523  |
Batch: 131  |  Train Loss: 0.04755965247750282  |
Batch: 132  |  Train Loss: 0.041402097791433334  |
Batch: 133  |  Train Loss: 0.05384635180234909  |
Batch: 134  |  Train Loss: 0.05287682265043259  |
Batch: 135  |  Train Loss: 0.050097186118364334  |
Batch: 136  |  Train Loss: 0.0637563019990921  |
Batch: 137  |  Train Loss: 0.05710618942975998  |
Batch: 138  |  Train Loss: 0.05987856537103653  |
Batch: 139  |  Train Loss: 0.10460592806339264  |
Batch: 140  |  Train Loss: 0.09184475988149643  |
Batch: 141  |  Train Loss: 0.06572338193655014  |
Batch: 142  |  Train Loss: 0.05800105258822441  |
Batch: 143  |  Train Loss: 0.047201916575431824  |
Batch: 144  |  Train Loss: 0.05239860340952873  |
Batch: 145  |  Train Loss: 0.04199104383587837  |
Batch: 146  |  Train Loss: 0.03970934823155403  |
Batch: 147  |  Train Loss: 0.05088603496551514  |
Batch: 148  |  Train Loss: 0.036857087165117264  |
Batch: 149  |  Train Loss: 0.04368070140480995  |
Batch: 150  |  Train Loss: 0.0690983235836029  |
Batch: 151  |  Train Loss: 0.06121665611863136  |
Batch: 152  |  Train Loss: 0.08865662664175034  |
Batch: 153  |  Train Loss: 0.08253210783004761  |
Batch: 154  |  Train Loss: 0.06354124844074249  |
Batch: 155  |  Train Loss: 0.051579948514699936  |
Batch: 156  |  Train Loss: 0.057594917714595795  |
Batch: 157  |  Train Loss: 0.04126543924212456  |
Batch: 158  |  Train Loss: 0.029407715424895287  |
Batch: 159  |  Train Loss: 0.053314752876758575  |
Batch: 160  |  Train Loss: 0.06720779091119766  |
Batch: 161  |  Train Loss: 0.06636833399534225  |
Batch: 162  |  Train Loss: 0.052374038845300674  |
Batch: 163  |  Train Loss: 0.05670538917183876  |
Batch: 164  |  Train Loss: 0.08369163423776627  |
Batch: 165  |  Train Loss: 0.05750992149114609  |
Batch: 166  |  Train Loss: 0.060874082148075104  |
Batch: 167  |  Train Loss: 0.05271138250827789  |
Batch: 168  |  Train Loss: 0.06235227733850479  |
Batch: 169  |  Train Loss: 0.06961431354284286  |
Batch: 170  |  Train Loss: 0.04245245084166527  |
Batch: 171  |  Train Loss: 0.12953916192054749  |
Batch: 172  |  Train Loss: 0.08578156679868698  |
Batch: 173  |  Train Loss: 0.06625089794397354  |
Batch: 174  |  Train Loss: 0.09647827595472336  |
Batch: 175  |  Train Loss: 0.056757617741823196  |
Batch: 176  |  Train Loss: 0.08981236815452576  |
Batch: 177  |  Train Loss: 0.03896016255021095  |
Batch: 178  |  Train Loss: 0.08207248896360397  |
Batch: 179  |  Train Loss: 0.12757447361946106  |
Batch: 180  |  Train Loss: 0.06890896707773209  |
Batch: 181  |  Train Loss: 0.07286999374628067  |
Batch: 182  |  Train Loss: 0.02830040082335472  |
Batch: 183  |  Train Loss: 0.06966397911310196  |
Batch: 184  |  Train Loss: 0.0428260937333107  |
Epoch: 7  |  Train Loss: 0.06504440898629459
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.89it/s]
Binary results:████████████████████████████▉| 1150/1151 [00:50<00:00, 22.58it/s]
################################################################################

Target prec: 0.660
Target recall: 0.537
Target F1: 0.592

Proportional results:
################################################################################

Target prec: 0.571
Target recall: 0.377
Target F1: 0.455

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.90it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.85it/s]
Binary results:████████████████████████████▉| 1149/1151 [00:50<00:00, 22.04it/s]
################################################################################

Target prec: 0.714
Target recall: 0.498
Target F1: 0.586

Proportional results:
################################################################################

Target prec: 0.580
Target recall: 0.318
Target F1: 0.411

################# END OF PIPELINE's RESULTS #################
 40%|███████████████▏                      | 8/20 [2:21:41<3:33:11, 1065.95s/it]Batch: 0  |  Train Loss: 0.08989280462265015  |
Batch: 1  |  Train Loss: 0.07521864026784897  |
Batch: 2  |  Train Loss: 0.06423989683389664  |
Batch: 3  |  Train Loss: 0.055142853409051895  |
Batch: 4  |  Train Loss: 0.12773649394512177  |
Batch: 5  |  Train Loss: 0.05593879520893097  |
Batch: 6  |  Train Loss: 0.0549367293715477  |
Batch: 7  |  Train Loss: 0.05737283080816269  |
Batch: 8  |  Train Loss: 0.04183277487754822  |
Batch: 9  |  Train Loss: 0.1110890731215477  |
Batch: 10  |  Train Loss: 0.034851979464292526  |
Batch: 11  |  Train Loss: 0.06629983335733414  |
Batch: 12  |  Train Loss: 0.02458501048386097  |
Batch: 13  |  Train Loss: 0.07084055989980698  |
Batch: 14  |  Train Loss: 0.07224126160144806  |
Batch: 15  |  Train Loss: 0.0379762127995491  |
Batch: 16  |  Train Loss: 0.07422264665365219  |
Batch: 17  |  Train Loss: 0.047211334109306335  |
Batch: 18  |  Train Loss: 0.08423790335655212  |
Batch: 19  |  Train Loss: 0.049164269119501114  |
Batch: 20  |  Train Loss: 0.06360722333192825  |
Batch: 21  |  Train Loss: 0.05464470386505127  |
Batch: 22  |  Train Loss: 0.06108101084828377  |
Batch: 23  |  Train Loss: 0.04636775702238083  |
Batch: 24  |  Train Loss: 0.04930145666003227  |
Batch: 25  |  Train Loss: 0.03862510994076729  |
Batch: 26  |  Train Loss: 0.0251428484916687  |
Batch: 27  |  Train Loss: 0.03781783953309059  |
Batch: 28  |  Train Loss: 0.06612975895404816  |
Batch: 29  |  Train Loss: 0.06977733224630356  |
Batch: 30  |  Train Loss: 0.056002747267484665  |
Batch: 31  |  Train Loss: 0.0782100111246109  |
Batch: 32  |  Train Loss: 0.05609599128365517  |
Batch: 33  |  Train Loss: 0.0804239884018898  |
Batch: 34  |  Train Loss: 0.07034602016210556  |
Batch: 35  |  Train Loss: 0.07779756188392639  |
Batch: 36  |  Train Loss: 0.05366427078843117  |
Batch: 37  |  Train Loss: 0.04544176161289215  |
Batch: 38  |  Train Loss: 0.05229393392801285  |
Batch: 39  |  Train Loss: 0.07614541798830032  |
Batch: 40  |  Train Loss: 0.060767095535993576  |
Batch: 41  |  Train Loss: 0.06415832787752151  |
Batch: 42  |  Train Loss: 0.024161677807569504  |
Batch: 43  |  Train Loss: 0.015674231573939323  |
Batch: 44  |  Train Loss: 0.08866941183805466  |
Batch: 45  |  Train Loss: 0.04550158232450485  |
Batch: 46  |  Train Loss: 0.019969116896390915  |
Batch: 47  |  Train Loss: 0.044989217072725296  |
Batch: 48  |  Train Loss: 0.053976692259311676  |
Batch: 49  |  Train Loss: 0.06678780168294907  |
Batch: 50  |  Train Loss: 0.06104264408349991  |
Batch: 51  |  Train Loss: 0.049918025732040405  |
Batch: 52  |  Train Loss: 0.058775752782821655  |
Batch: 53  |  Train Loss: 0.04135744273662567  |
Batch: 54  |  Train Loss: 0.07850279659032822  |
Batch: 55  |  Train Loss: 0.05211739242076874  |
Batch: 56  |  Train Loss: 0.06097017228603363  |
Batch: 57  |  Train Loss: 0.06662453711032867  |
Batch: 58  |  Train Loss: 0.05494152754545212  |
Batch: 59  |  Train Loss: 0.05319789797067642  |
Batch: 60  |  Train Loss: 0.049263034015893936  |
Batch: 61  |  Train Loss: 0.09144081175327301  |
Batch: 62  |  Train Loss: 0.053084153681993484  |
Batch: 63  |  Train Loss: 0.06542876362800598  |
Batch: 64  |  Train Loss: 0.0935087651014328  |
Batch: 65  |  Train Loss: 0.05495327711105347  |
Batch: 66  |  Train Loss: 0.09627269953489304  |
Batch: 67  |  Train Loss: 0.03149617463350296  |
Batch: 68  |  Train Loss: 0.09337440878152847  |
Batch: 69  |  Train Loss: 0.06762237846851349  |
Batch: 70  |  Train Loss: 0.11813603341579437  |
Batch: 71  |  Train Loss: 0.06066348776221275  |
Batch: 72  |  Train Loss: 0.032794252038002014  |
Batch: 73  |  Train Loss: 0.10050865262746811  |
Batch: 74  |  Train Loss: 0.026387261226773262  |
Batch: 75  |  Train Loss: 0.03417746350169182  |
Batch: 76  |  Train Loss: 0.02260972559452057  |
Batch: 77  |  Train Loss: 0.02759222500026226  |
Batch: 78  |  Train Loss: 0.026185471564531326  |
Batch: 79  |  Train Loss: 0.06397552043199539  |
Batch: 80  |  Train Loss: 0.06809322535991669  |
Batch: 81  |  Train Loss: 0.05800781771540642  |
Batch: 82  |  Train Loss: 0.06401295214891434  |
Batch: 83  |  Train Loss: 0.07859332114458084  |
Batch: 84  |  Train Loss: 0.06166459992527962  |
Batch: 85  |  Train Loss: 0.10714378952980042  |
Batch: 86  |  Train Loss: 0.049231890588998795  |
Batch: 87  |  Train Loss: 0.05108034610748291  |
Batch: 88  |  Train Loss: 0.04490285739302635  |
Batch: 89  |  Train Loss: 0.04157133772969246  |
Batch: 90  |  Train Loss: 0.05313027650117874  |
Batch: 91  |  Train Loss: 0.036014460027217865  |
Batch: 92  |  Train Loss: 0.036207545548677444  |
Batch: 93  |  Train Loss: 0.07564924657344818  |
Batch: 94  |  Train Loss: 0.10082066059112549  |
Batch: 95  |  Train Loss: 0.07402163743972778  |
Batch: 96  |  Train Loss: 0.032091349363327026  |
Batch: 97  |  Train Loss: 0.034625280648469925  |
Batch: 98  |  Train Loss: 0.05908755585551262  |
Batch: 99  |  Train Loss: 0.05110868439078331  |
Batch: 100  |  Train Loss: 0.044255103915929794  |
Batch: 101  |  Train Loss: 0.046041592955589294  |
Batch: 102  |  Train Loss: 0.038709867745637894  |
Batch: 103  |  Train Loss: 0.04758087173104286  |
Batch: 104  |  Train Loss: 0.06286156922578812  |
Batch: 105  |  Train Loss: 0.06011674553155899  |
Batch: 106  |  Train Loss: 0.033092424273490906  |
Batch: 107  |  Train Loss: 0.06076447665691376  |
Batch: 108  |  Train Loss: 0.04342823475599289  |
Batch: 109  |  Train Loss: 0.039279572665691376  |
Batch: 110  |  Train Loss: 0.0508514866232872  |
Batch: 111  |  Train Loss: 0.05417734757065773  |
Batch: 112  |  Train Loss: 0.1252424567937851  |
Batch: 113  |  Train Loss: 0.03754178434610367  |
Batch: 114  |  Train Loss: 0.06088373810052872  |
Batch: 115  |  Train Loss: 0.06185431033372879  |
Batch: 116  |  Train Loss: 0.06566904485225677  |
Batch: 117  |  Train Loss: 0.08452098816633224  |
Batch: 118  |  Train Loss: 0.08678950369358063  |
Batch: 119  |  Train Loss: 0.04709458351135254  |
Batch: 120  |  Train Loss: 0.02109379507601261  |
Batch: 121  |  Train Loss: 0.04420086368918419  |
Batch: 122  |  Train Loss: 0.06248105689883232  |
Batch: 123  |  Train Loss: 0.044661734253168106  |
Batch: 124  |  Train Loss: 0.0676170140504837  |
Batch: 125  |  Train Loss: 0.04856071621179581  |
Batch: 126  |  Train Loss: 0.08072017133235931  |
Batch: 127  |  Train Loss: 0.030360130593180656  |
Batch: 128  |  Train Loss: 0.08384016156196594  |
Batch: 129  |  Train Loss: 0.054759226739406586  |
Batch: 130  |  Train Loss: 0.027799692004919052  |
Batch: 131  |  Train Loss: 0.09377032518386841  |
Batch: 132  |  Train Loss: 0.05110303685069084  |
Batch: 133  |  Train Loss: 0.05442513898015022  |
Batch: 134  |  Train Loss: 0.03389811888337135  |
Batch: 135  |  Train Loss: 0.05410245805978775  |
Batch: 136  |  Train Loss: 0.10900937765836716  |
Batch: 137  |  Train Loss: 0.03952423855662346  |
Batch: 138  |  Train Loss: 0.0646420493721962  |
Batch: 139  |  Train Loss: 0.05048375576734543  |
Batch: 140  |  Train Loss: 0.06345302611589432  |
Batch: 141  |  Train Loss: 0.053002212196588516  |
Batch: 142  |  Train Loss: 0.101502925157547  |
Batch: 143  |  Train Loss: 0.04682695493102074  |
Batch: 144  |  Train Loss: 0.0387679822742939  |
Batch: 145  |  Train Loss: 0.049172475934028625  |
Batch: 146  |  Train Loss: 0.09878887236118317  |
Batch: 147  |  Train Loss: 0.04930667579174042  |
Batch: 148  |  Train Loss: 0.027212049812078476  |
Batch: 149  |  Train Loss: 0.05300296097993851  |
Batch: 150  |  Train Loss: 0.035861190408468246  |
Batch: 151  |  Train Loss: 0.04688666760921478  |
Batch: 152  |  Train Loss: 0.02204163745045662  |
Batch: 153  |  Train Loss: 0.054943084716796875  |
Batch: 154  |  Train Loss: 0.06693147867918015  |
Batch: 155  |  Train Loss: 0.12959271669387817  |
Batch: 156  |  Train Loss: 0.07681101560592651  |
Batch: 157  |  Train Loss: 0.034105084836483  |
Batch: 158  |  Train Loss: 0.05945209413766861  |
Batch: 159  |  Train Loss: 0.011230604723095894  |
Batch: 160  |  Train Loss: 0.05625426769256592  |
Batch: 161  |  Train Loss: 0.037023529410362244  |
Batch: 162  |  Train Loss: 0.07684487849473953  |
Batch: 163  |  Train Loss: 0.048742637038230896  |
Batch: 164  |  Train Loss: 0.02734234556555748  |
Batch: 165  |  Train Loss: 0.04275922104716301  |
Batch: 166  |  Train Loss: 0.03233550488948822  |
Batch: 167  |  Train Loss: 0.033444732427597046  |
Batch: 168  |  Train Loss: 0.03950435295701027  |
Batch: 169  |  Train Loss: 0.05727379024028778  |
Batch: 170  |  Train Loss: 0.03170226886868477  |
Batch: 171  |  Train Loss: 0.031182486563920975  |
Batch: 172  |  Train Loss: 0.07441368699073792  |
Batch: 173  |  Train Loss: 0.08654989302158356  |
Batch: 174  |  Train Loss: 0.033208832144737244  |
Batch: 175  |  Train Loss: 0.09793518483638763  |
Batch: 176  |  Train Loss: 0.05174093693494797  |
Batch: 177  |  Train Loss: 0.01685297302901745  |
Batch: 178  |  Train Loss: 0.07325972616672516  |
Batch: 179  |  Train Loss: 0.06335970014333725  |
Batch: 180  |  Train Loss: 0.07087470591068268  |
Batch: 181  |  Train Loss: 0.05377938225865364  |
Batch: 182  |  Train Loss: 0.07861760258674622  |
Batch: 183  |  Train Loss: 0.06498567759990692  |
Batch: 184  |  Train Loss: 0.06122323498129845  |
Epoch: 8  |  Train Loss: 0.057462148187128276
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.83it/s]
Binary results:████████████████████████████▉| 1149/1151 [00:50<00:00, 23.54it/s]
################################################################################

Target prec: 0.582
Target recall: 0.658
Target F1: 0.617

Proportional results:
################################################################################

Target prec: 0.505
Target recall: 0.486
Target F1: 0.495

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.97it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.78it/s]
Binary results:█████████████████████████████| 1151/1151 [00:50<00:00, 22.24it/s]
################################################################################

Target prec: 0.655
Target recall: 0.587
Target F1: 0.619

Proportional results:
################################################################################

Target prec: 0.533
Target recall: 0.379
Target F1: 0.443

################# END OF PIPELINE's RESULTS #################
 45%|█████████████████                     | 9/20 [2:39:21<3:15:02, 1063.84s/it]Batch: 0  |  Train Loss: 0.03496910259127617  |
Batch: 1  |  Train Loss: 0.04997889697551727  |
Batch: 2  |  Train Loss: 0.03048059530556202  |
Batch: 3  |  Train Loss: 0.026840373873710632  |
Batch: 4  |  Train Loss: 0.09553223848342896  |
Batch: 5  |  Train Loss: 0.061408501118421555  |
Batch: 6  |  Train Loss: 0.021145598962903023  |
Batch: 7  |  Train Loss: 0.03364301472902298  |
Batch: 8  |  Train Loss: 0.04601427540183067  |
Batch: 9  |  Train Loss: 0.04876602813601494  |
Batch: 10  |  Train Loss: 0.06121012568473816  |
Batch: 11  |  Train Loss: 0.06490696221590042  |
Batch: 12  |  Train Loss: 0.03658951818943024  |
Batch: 13  |  Train Loss: 0.05475480854511261  |
Batch: 14  |  Train Loss: 0.05286118760704994  |
Batch: 15  |  Train Loss: 0.07666463404893875  |
Batch: 16  |  Train Loss: 0.05109677463769913  |
Batch: 17  |  Train Loss: 0.021200276911258698  |
Batch: 18  |  Train Loss: 0.0443640872836113  |
Batch: 19  |  Train Loss: 0.06391039490699768  |
Batch: 20  |  Train Loss: 0.05667012929916382  |
Batch: 21  |  Train Loss: 0.03449555113911629  |
Batch: 22  |  Train Loss: 0.05029521882534027  |
Batch: 23  |  Train Loss: 0.07418826967477798  |
Batch: 24  |  Train Loss: 0.0638972595334053  |
Batch: 25  |  Train Loss: 0.04515284672379494  |
Batch: 26  |  Train Loss: 0.059964556246995926  |
Batch: 27  |  Train Loss: 0.04710563272237778  |
Batch: 28  |  Train Loss: 0.030435709282755852  |
Batch: 29  |  Train Loss: 0.04240573197603226  |
Batch: 30  |  Train Loss: 0.049425046890974045  |
Batch: 31  |  Train Loss: 0.062398720532655716  |
Batch: 32  |  Train Loss: 0.06738493591547012  |
Batch: 33  |  Train Loss: 0.0586426705121994  |
Batch: 34  |  Train Loss: 0.05231963470578194  |
Batch: 35  |  Train Loss: 0.10495326668024063  |
Batch: 36  |  Train Loss: 0.06078944727778435  |
Batch: 37  |  Train Loss: 0.08877959847450256  |
Batch: 38  |  Train Loss: 0.0848119854927063  |
Batch: 39  |  Train Loss: 0.03184201568365097  |
Batch: 40  |  Train Loss: 0.026799023151397705  |
Batch: 41  |  Train Loss: 0.02176624722778797  |
Batch: 42  |  Train Loss: 0.057372525334358215  |
Batch: 43  |  Train Loss: 0.07080265879631042  |
Batch: 44  |  Train Loss: 0.03493402898311615  |
Batch: 45  |  Train Loss: 0.06726934015750885  |
Batch: 46  |  Train Loss: 0.07389173656702042  |
Batch: 47  |  Train Loss: 0.05374550819396973  |
Batch: 48  |  Train Loss: 0.06148166209459305  |
Batch: 49  |  Train Loss: 0.0787305235862732  |
Batch: 50  |  Train Loss: 0.03660768270492554  |
Batch: 51  |  Train Loss: 0.05767082795500755  |
Batch: 52  |  Train Loss: 0.026223277673125267  |
Batch: 53  |  Train Loss: 0.05657023563981056  |
Batch: 54  |  Train Loss: 0.06740886718034744  |
Batch: 55  |  Train Loss: 0.04046190530061722  |
Batch: 56  |  Train Loss: 0.05070678889751434  |
Batch: 57  |  Train Loss: 0.04727707803249359  |
Batch: 58  |  Train Loss: 0.07894094288349152  |
Batch: 59  |  Train Loss: 0.06940377503633499  |
Batch: 60  |  Train Loss: 0.039376746863126755  |
Batch: 61  |  Train Loss: 0.07045792788267136  |
Batch: 62  |  Train Loss: 0.02214599959552288  |
Batch: 63  |  Train Loss: 0.05168993026018143  |
Batch: 64  |  Train Loss: 0.07962534576654434  |
Batch: 65  |  Train Loss: 0.08212092518806458  |
Batch: 66  |  Train Loss: 0.028557483106851578  |
Batch: 67  |  Train Loss: 0.047005873173475266  |
Batch: 68  |  Train Loss: 0.017738819122314453  |
Batch: 69  |  Train Loss: 0.10660072416067123  |
Batch: 70  |  Train Loss: 0.0841575562953949  |
Batch: 71  |  Train Loss: 0.02043452300131321  |
Batch: 72  |  Train Loss: 0.021258555352687836  |
Batch: 73  |  Train Loss: 0.01835007406771183  |
Batch: 74  |  Train Loss: 0.06326659023761749  |
Batch: 75  |  Train Loss: 0.06793481111526489  |
Batch: 76  |  Train Loss: 0.03217131271958351  |
Batch: 77  |  Train Loss: 0.05477204918861389  |
Batch: 78  |  Train Loss: 0.03186095505952835  |
Batch: 79  |  Train Loss: 0.05163413658738136  |
Batch: 80  |  Train Loss: 0.08973433077335358  |
Batch: 81  |  Train Loss: 0.061293624341487885  |
Batch: 82  |  Train Loss: 0.031746070832014084  |
Batch: 83  |  Train Loss: 0.05760667845606804  |
Batch: 84  |  Train Loss: 0.04879183694720268  |
Batch: 85  |  Train Loss: 0.0352967344224453  |
Batch: 86  |  Train Loss: 0.029042724519968033  |
Batch: 87  |  Train Loss: 0.0459556058049202  |
Batch: 88  |  Train Loss: 0.027654068544507027  |
Batch: 89  |  Train Loss: 0.041660383343696594  |
Batch: 90  |  Train Loss: 0.051654279232025146  |
Batch: 91  |  Train Loss: 0.03365520387887955  |
Batch: 92  |  Train Loss: 0.01981242001056671  |
Batch: 93  |  Train Loss: 0.07997845858335495  |
Batch: 94  |  Train Loss: 0.045116789638996124  |
Batch: 95  |  Train Loss: 0.09360300004482269  |
Batch: 96  |  Train Loss: 0.04746356979012489  |
Batch: 97  |  Train Loss: 0.049626510590314865  |
Batch: 98  |  Train Loss: 0.034281935542821884  |
Batch: 99  |  Train Loss: 0.0216376930475235  |
Batch: 100  |  Train Loss: 0.04488413780927658  |
Batch: 101  |  Train Loss: 0.07382723689079285  |
Batch: 102  |  Train Loss: 0.04845963791012764  |
Batch: 103  |  Train Loss: 0.046295490115880966  |
Batch: 104  |  Train Loss: 0.08064062148332596  |
Batch: 105  |  Train Loss: 0.047562383115291595  |
Batch: 106  |  Train Loss: 0.01994522102177143  |
Batch: 107  |  Train Loss: 0.058159057050943375  |
Batch: 108  |  Train Loss: 0.047575414180755615  |
Batch: 109  |  Train Loss: 0.03578028082847595  |
Batch: 110  |  Train Loss: 0.061954956501722336  |
Batch: 111  |  Train Loss: 0.049563273787498474  |
Batch: 112  |  Train Loss: 0.05319494754076004  |
Batch: 113  |  Train Loss: 0.02941148541867733  |
Batch: 114  |  Train Loss: 0.04522300511598587  |
Batch: 115  |  Train Loss: 0.061990682035684586  |
Batch: 116  |  Train Loss: 0.04080119729042053  |
Batch: 117  |  Train Loss: 0.054291535168886185  |
Batch: 118  |  Train Loss: 0.03291846066713333  |
Batch: 119  |  Train Loss: 0.06733796745538712  |
Batch: 120  |  Train Loss: 0.05829310417175293  |
Batch: 121  |  Train Loss: 0.03586038202047348  |
Batch: 122  |  Train Loss: 0.03911624103784561  |
Batch: 123  |  Train Loss: 0.07264745235443115  |
Batch: 124  |  Train Loss: 0.041932206600904465  |
Batch: 125  |  Train Loss: 0.037094514816999435  |
Batch: 126  |  Train Loss: 0.041701480746269226  |
Batch: 127  |  Train Loss: 0.026696693152189255  |
Batch: 128  |  Train Loss: 0.01954806037247181  |
Batch: 129  |  Train Loss: 0.03843570500612259  |
Batch: 130  |  Train Loss: 0.03407146409153938  |
Batch: 131  |  Train Loss: 0.06899197399616241  |
Batch: 132  |  Train Loss: 0.023286806419491768  |
Batch: 133  |  Train Loss: 0.041464176028966904  |
Batch: 134  |  Train Loss: 0.03933912143111229  |
Batch: 135  |  Train Loss: 0.06363361328840256  |
Batch: 136  |  Train Loss: 0.10329587757587433  |
Batch: 137  |  Train Loss: 0.04270089790225029  |
Batch: 138  |  Train Loss: 0.11588317900896072  |
Batch: 139  |  Train Loss: 0.06534897536039352  |
Batch: 140  |  Train Loss: 0.027448095381259918  |
Batch: 141  |  Train Loss: 0.014549603685736656  |
Batch: 142  |  Train Loss: 0.0315827876329422  |
Batch: 143  |  Train Loss: 0.04635178670287132  |
Batch: 144  |  Train Loss: 0.01649363338947296  |
Batch: 145  |  Train Loss: 0.07588036358356476  |
Batch: 146  |  Train Loss: 0.049263112246990204  |
Batch: 147  |  Train Loss: 0.060371946543455124  |
Batch: 148  |  Train Loss: 0.06818895041942596  |
Batch: 149  |  Train Loss: 0.038034241646528244  |
Batch: 150  |  Train Loss: 0.016285056248307228  |
Batch: 151  |  Train Loss: 0.04312668740749359  |
Batch: 152  |  Train Loss: 0.04036783054471016  |
Batch: 153  |  Train Loss: 0.05047018826007843  |
Batch: 154  |  Train Loss: 0.04923044517636299  |
Batch: 155  |  Train Loss: 0.032889872789382935  |
Batch: 156  |  Train Loss: 0.05617346242070198  |
Batch: 157  |  Train Loss: 0.06583509594202042  |
Batch: 158  |  Train Loss: 0.029468683525919914  |
Batch: 159  |  Train Loss: 0.0160958394408226  |
Batch: 160  |  Train Loss: 0.04783806949853897  |
Batch: 161  |  Train Loss: 0.04831983521580696  |
Batch: 162  |  Train Loss: 0.08301883935928345  |
Batch: 163  |  Train Loss: 0.03367389738559723  |
Batch: 164  |  Train Loss: 0.0420127771794796  |
Batch: 165  |  Train Loss: 0.0471348911523819  |
Batch: 166  |  Train Loss: 0.03319309279322624  |
Batch: 167  |  Train Loss: 0.07301641255617142  |
Batch: 168  |  Train Loss: 0.027364300563931465  |
Batch: 169  |  Train Loss: 0.03781173750758171  |
Batch: 170  |  Train Loss: 0.05169669911265373  |
Batch: 171  |  Train Loss: 0.04863358289003372  |
Batch: 172  |  Train Loss: 0.09449044615030289  |
Batch: 173  |  Train Loss: 0.05844854936003685  |
Batch: 174  |  Train Loss: 0.025048699229955673  |
Batch: 175  |  Train Loss: 0.05442003160715103  |
Batch: 176  |  Train Loss: 0.05217527225613594  |
Batch: 177  |  Train Loss: 0.0168205127120018  |
Batch: 178  |  Train Loss: 0.05646495148539543  |
Batch: 179  |  Train Loss: 0.07283791899681091  |
Batch: 180  |  Train Loss: 0.04376731440424919  |
Batch: 181  |  Train Loss: 0.0263651292771101  |
Batch: 182  |  Train Loss: 0.045443661510944366  |
Batch: 183  |  Train Loss: 0.1102912649512291  |
Batch: 184  |  Train Loss: 0.053142473101615906  |
Epoch: 9  |  Train Loss: 0.050150429598383
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.83it/s]
Binary results:████████████████████████████▉| 1149/1151 [00:50<00:00, 26.14it/s]
################################################################################

Target prec: 0.603
Target recall: 0.659
Target F1: 0.630

Proportional results:
################################################################################

Target prec: 0.511
Target recall: 0.472
Target F1: 0.491

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.77it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.78it/s]
Binary results:████████████████████████████▉| 1150/1151 [00:50<00:00, 23.04it/s]
################################################################################

Target prec: 0.664
Target recall: 0.582
Target F1: 0.620

Proportional results:
################################################################################

Target prec: 0.536
Target recall: 0.375
Target F1: 0.441

################# END OF PIPELINE's RESULTS #################
 50%|██████████████████▌                  | 10/20 [2:57:14<2:57:46, 1066.69s/it]Batch: 0  |  Train Loss: 0.033302322030067444  |
Batch: 1  |  Train Loss: 0.06653840839862823  |
Batch: 2  |  Train Loss: 0.054316774010658264  |
Batch: 3  |  Train Loss: 0.046697959303855896  |
Batch: 4  |  Train Loss: 0.058963093906641006  |
Batch: 5  |  Train Loss: 0.06390111148357391  |
Batch: 6  |  Train Loss: 0.04169657826423645  |
Batch: 7  |  Train Loss: 0.04178132489323616  |
Batch: 8  |  Train Loss: 0.0333535261452198  |
Batch: 9  |  Train Loss: 0.03571632131934166  |
Batch: 10  |  Train Loss: 0.021812891587615013  |
Batch: 11  |  Train Loss: 0.02676808275282383  |
Batch: 12  |  Train Loss: 0.02820092812180519  |
Batch: 13  |  Train Loss: 0.04654482752084732  |
Batch: 14  |  Train Loss: 0.035854678601026535  |
Batch: 15  |  Train Loss: 0.043348394334316254  |
Batch: 16  |  Train Loss: 0.014315617270767689  |
Batch: 17  |  Train Loss: 0.01900791935622692  |
Batch: 18  |  Train Loss: 0.08064312487840652  |
Batch: 19  |  Train Loss: 0.015043772757053375  |
Batch: 20  |  Train Loss: 0.04211851581931114  |
Batch: 21  |  Train Loss: 0.03304365649819374  |
Batch: 22  |  Train Loss: 0.019833426922559738  |
Batch: 23  |  Train Loss: 0.039221037179231644  |
Batch: 24  |  Train Loss: 0.04468275606632233  |
Batch: 25  |  Train Loss: 0.05937015265226364  |
Batch: 26  |  Train Loss: 0.05920407921075821  |
Batch: 27  |  Train Loss: 0.035908471792936325  |
Batch: 28  |  Train Loss: 0.07090375572443008  |
Batch: 29  |  Train Loss: 0.03193970024585724  |
Batch: 30  |  Train Loss: 0.0350346565246582  |
Batch: 31  |  Train Loss: 0.03311360627412796  |
Batch: 32  |  Train Loss: 0.10850530117750168  |
Batch: 33  |  Train Loss: 0.06178567185997963  |
Batch: 34  |  Train Loss: 0.02215389348566532  |
Batch: 35  |  Train Loss: 0.015124659985303879  |
Batch: 36  |  Train Loss: 0.04556923732161522  |
Batch: 37  |  Train Loss: 0.04333803802728653  |
Batch: 38  |  Train Loss: 0.03453187644481659  |
Batch: 39  |  Train Loss: 0.03019416518509388  |
Batch: 40  |  Train Loss: 0.03277147561311722  |
Batch: 41  |  Train Loss: 0.06755582243204117  |
Batch: 42  |  Train Loss: 0.04032233729958534  |
Batch: 43  |  Train Loss: 0.05707859992980957  |
Batch: 44  |  Train Loss: 0.07395108044147491  |
Batch: 45  |  Train Loss: 0.09174780547618866  |
Batch: 46  |  Train Loss: 0.033205047249794006  |
Batch: 47  |  Train Loss: 0.06897586584091187  |
Batch: 48  |  Train Loss: 0.03875812515616417  |
Batch: 49  |  Train Loss: 0.05354137718677521  |
Batch: 50  |  Train Loss: 0.0436127707362175  |
Batch: 51  |  Train Loss: 0.076329305768013  |
Batch: 52  |  Train Loss: 0.06008124724030495  |
Batch: 53  |  Train Loss: 0.05158364400267601  |
Batch: 54  |  Train Loss: 0.06712911278009415  |
Batch: 55  |  Train Loss: 0.0269636120647192  |
Batch: 56  |  Train Loss: 0.03975895419716835  |
Batch: 57  |  Train Loss: 0.01413691695779562  |
Batch: 58  |  Train Loss: 0.03781569004058838  |
Batch: 59  |  Train Loss: 0.03888135030865669  |
Batch: 60  |  Train Loss: 0.05410609394311905  |
Batch: 61  |  Train Loss: 0.02897689864039421  |
Batch: 62  |  Train Loss: 0.026858462020754814  |
Batch: 63  |  Train Loss: 0.025975732132792473  |
Batch: 64  |  Train Loss: 0.05675075948238373  |
Batch: 65  |  Train Loss: 0.023465927690267563  |
Batch: 66  |  Train Loss: 0.04339929670095444  |
Batch: 67  |  Train Loss: 0.06626219302415848  |
Batch: 68  |  Train Loss: 0.09694960713386536  |
Batch: 69  |  Train Loss: 0.043159764260053635  |
Batch: 70  |  Train Loss: 0.029453301802277565  |
Batch: 71  |  Train Loss: 0.04419238492846489  |
Batch: 72  |  Train Loss: 0.030208097770810127  |
Batch: 73  |  Train Loss: 0.019888922572135925  |
Batch: 74  |  Train Loss: 0.07648194581270218  |
Batch: 75  |  Train Loss: 0.05270536243915558  |
Batch: 76  |  Train Loss: 0.027628954499959946  |
Batch: 77  |  Train Loss: 0.03156954422593117  |
Batch: 78  |  Train Loss: 0.02833728864789009  |
Batch: 79  |  Train Loss: 0.047864239662885666  |
Batch: 80  |  Train Loss: 0.07639853656291962  |
Batch: 81  |  Train Loss: 0.09574595093727112  |
Batch: 82  |  Train Loss: 0.030762018635869026  |
Batch: 83  |  Train Loss: 0.04197612777352333  |
Batch: 84  |  Train Loss: 0.04732313007116318  |
Batch: 85  |  Train Loss: 0.04948549345135689  |
Batch: 86  |  Train Loss: 0.023264676332473755  |
Batch: 87  |  Train Loss: 0.025946268811821938  |
Batch: 88  |  Train Loss: 0.042032331228256226  |
Batch: 89  |  Train Loss: 0.06147703528404236  |
Batch: 90  |  Train Loss: 0.023934224620461464  |
Batch: 91  |  Train Loss: 0.037112269550561905  |
Batch: 92  |  Train Loss: 0.05523477867245674  |
Batch: 93  |  Train Loss: 0.036589570343494415  |
Batch: 94  |  Train Loss: 0.06244809925556183  |
Batch: 95  |  Train Loss: 0.04020396247506142  |
Batch: 96  |  Train Loss: 0.046424273401498795  |
Batch: 97  |  Train Loss: 0.020842375233769417  |
Batch: 98  |  Train Loss: 0.047871097922325134  |
Batch: 99  |  Train Loss: 0.07381586730480194  |
Batch: 100  |  Train Loss: 0.06313968449831009  |
Batch: 101  |  Train Loss: 0.05795362964272499  |
Batch: 102  |  Train Loss: 0.04003703594207764  |
Batch: 103  |  Train Loss: 0.03673326224088669  |
Batch: 104  |  Train Loss: 0.03164194896817207  |
Batch: 105  |  Train Loss: 0.05320611596107483  |
Batch: 106  |  Train Loss: 0.024426674470305443  |
Batch: 107  |  Train Loss: 0.04679136350750923  |
Batch: 108  |  Train Loss: 0.08317957818508148  |
Batch: 109  |  Train Loss: 0.05873296409845352  |
Batch: 110  |  Train Loss: 0.04066050797700882  |
Batch: 111  |  Train Loss: 0.05753207579255104  |
Batch: 112  |  Train Loss: 0.027728283777832985  |
Batch: 113  |  Train Loss: 0.06541436910629272  |
Batch: 114  |  Train Loss: 0.038124509155750275  |
Batch: 115  |  Train Loss: 0.039071545004844666  |
Batch: 116  |  Train Loss: 0.034362953156232834  |
Batch: 117  |  Train Loss: 0.06173210218548775  |
Batch: 118  |  Train Loss: 0.02930314838886261  |
Batch: 119  |  Train Loss: 0.024977726861834526  |
Batch: 120  |  Train Loss: 0.04483027383685112  |
Batch: 121  |  Train Loss: 0.006896237377077341  |
Batch: 122  |  Train Loss: 0.04278695210814476  |
Batch: 123  |  Train Loss: 0.05603118613362312  |
Batch: 124  |  Train Loss: 0.029256118461489677  |
Batch: 125  |  Train Loss: 0.028392890468239784  |
Batch: 126  |  Train Loss: 0.060717325657606125  |
Batch: 127  |  Train Loss: 0.10228031128644943  |
Batch: 128  |  Train Loss: 0.04908236116170883  |
Batch: 129  |  Train Loss: 0.06305529922246933  |
Batch: 130  |  Train Loss: 0.024601658806204796  |
Batch: 131  |  Train Loss: 0.02414582669734955  |
Batch: 132  |  Train Loss: 0.07710708677768707  |
Batch: 133  |  Train Loss: 0.031078532338142395  |
Batch: 134  |  Train Loss: 0.038945943117141724  |
Batch: 135  |  Train Loss: 0.036149442195892334  |
Batch: 136  |  Train Loss: 0.029843278229236603  |
Batch: 137  |  Train Loss: 0.03268012776970863  |
Batch: 138  |  Train Loss: 0.06302471458911896  |
Batch: 139  |  Train Loss: 0.03887328505516052  |
Batch: 140  |  Train Loss: 0.03743956610560417  |
Batch: 141  |  Train Loss: 0.04206635802984238  |
Batch: 142  |  Train Loss: 0.06049976870417595  |
Batch: 143  |  Train Loss: 0.0465657114982605  |
Batch: 144  |  Train Loss: 0.030029410496354103  |
Batch: 145  |  Train Loss: 0.06539898365736008  |
Batch: 146  |  Train Loss: 0.03939204290509224  |
Batch: 147  |  Train Loss: 0.040619175881147385  |
Batch: 148  |  Train Loss: 0.028342321515083313  |
Batch: 149  |  Train Loss: 0.025501688942313194  |
Batch: 150  |  Train Loss: 0.033749792724847794  |
Batch: 151  |  Train Loss: 0.06093346327543259  |
Batch: 152  |  Train Loss: 0.060541678220033646  |
Batch: 153  |  Train Loss: 0.023534173145890236  |
Batch: 154  |  Train Loss: 0.02410866878926754  |
Batch: 155  |  Train Loss: 0.04950511455535889  |
Batch: 156  |  Train Loss: 0.04625003784894943  |
Batch: 157  |  Train Loss: 0.044088102877140045  |
Batch: 158  |  Train Loss: 0.06255993247032166  |
Batch: 159  |  Train Loss: 0.03973262012004852  |
Batch: 160  |  Train Loss: 0.037779372185468674  |
Batch: 161  |  Train Loss: 0.05136168375611305  |
Batch: 162  |  Train Loss: 0.04860706999897957  |
Batch: 163  |  Train Loss: 0.03305402025580406  |
Batch: 164  |  Train Loss: 0.048516836017370224  |
Batch: 165  |  Train Loss: 0.024965450167655945  |
Batch: 166  |  Train Loss: 0.024274548515677452  |
Batch: 167  |  Train Loss: 0.03383783996105194  |
Batch: 168  |  Train Loss: 0.02634003385901451  |
Batch: 169  |  Train Loss: 0.05057161673903465  |
Batch: 170  |  Train Loss: 0.05511707067489624  |
Batch: 171  |  Train Loss: 0.05107871815562248  |
Batch: 172  |  Train Loss: 0.012701268307864666  |
Batch: 173  |  Train Loss: 0.03486338257789612  |
Batch: 174  |  Train Loss: 0.030637789517641068  |
Batch: 175  |  Train Loss: 0.03699018061161041  |
Batch: 176  |  Train Loss: 0.0745398998260498  |
Batch: 177  |  Train Loss: 0.027545571327209473  |
Batch: 178  |  Train Loss: 0.022193700075149536  |
Batch: 179  |  Train Loss: 0.04434497654438019  |
Batch: 180  |  Train Loss: 0.038317903876304626  |
Batch: 181  |  Train Loss: 0.02163858339190483  |
Batch: 182  |  Train Loss: 0.015854349359869957  |
Batch: 183  |  Train Loss: 0.026576468721032143  |
Batch: 184  |  Train Loss: 0.05653300881385803  |
Epoch: 10  |  Train Loss: 0.04359100327852207
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.72it/s]
Binary results:█████████████████████████████| 1151/1151 [00:50<00:00, 21.42it/s]
################################################################################

Target prec: 0.644
Target recall: 0.603
Target F1: 0.623

Proportional results:
################################################################################

Target prec: 0.559
Target recall: 0.421
Target F1: 0.480

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.98it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.83it/s]
Binary results:████████████████████████████▉| 1150/1151 [00:50<00:00, 24.33it/s]
################################################################################

Target prec: 0.700
Target recall: 0.547
Target F1: 0.614

Proportional results:
################################################################################

Target prec: 0.568
Target recall: 0.345
Target F1: 0.429

################# END OF PIPELINE's RESULTS #################
 55%|████████████████████▎                | 11/20 [3:15:02<2:40:03, 1067.09s/it]Batch: 0  |  Train Loss: 0.0649377703666687  |
Batch: 1  |  Train Loss: 0.02180015854537487  |
Batch: 2  |  Train Loss: 0.03871593624353409  |
Batch: 3  |  Train Loss: 0.051294151693582535  |
Batch: 4  |  Train Loss: 0.008227013051509857  |
Batch: 5  |  Train Loss: 0.026237990707159042  |
Batch: 6  |  Train Loss: 0.04047723487019539  |
Batch: 7  |  Train Loss: 0.022858209908008575  |
Batch: 8  |  Train Loss: 0.028302190825343132  |
Batch: 9  |  Train Loss: 0.0705130323767662  |
Batch: 10  |  Train Loss: 0.04006612300872803  |
Batch: 11  |  Train Loss: 0.019269216805696487  |
Batch: 12  |  Train Loss: 0.07525139302015305  |
Batch: 13  |  Train Loss: 0.031869351863861084  |
Batch: 14  |  Train Loss: 0.03298882395029068  |
Batch: 15  |  Train Loss: 0.027248911559581757  |
Batch: 16  |  Train Loss: 0.025964263826608658  |
Batch: 17  |  Train Loss: 0.02285648323595524  |
Batch: 18  |  Train Loss: 0.052602481096982956  |
Batch: 19  |  Train Loss: 0.011624724604189396  |
Batch: 20  |  Train Loss: 0.07255526632070541  |
Batch: 21  |  Train Loss: 0.020408589392900467  |
Batch: 22  |  Train Loss: 0.013249693438410759  |
Batch: 23  |  Train Loss: 0.02038375660777092  |
Batch: 24  |  Train Loss: 0.02822919189929962  |
Batch: 25  |  Train Loss: 0.060740817338228226  |
Batch: 26  |  Train Loss: 0.028248311951756477  |
Batch: 27  |  Train Loss: 0.037024807184934616  |
Batch: 28  |  Train Loss: 0.030489027500152588  |
Batch: 29  |  Train Loss: 0.02189941145479679  |
Batch: 30  |  Train Loss: 0.037703804671764374  |
Batch: 31  |  Train Loss: 0.06522078812122345  |
Batch: 32  |  Train Loss: 0.0425846129655838  |
Batch: 33  |  Train Loss: 0.033268969506025314  |
Batch: 34  |  Train Loss: 0.01170994620770216  |
Batch: 35  |  Train Loss: 0.03557370603084564  |
Batch: 36  |  Train Loss: 0.035859737545251846  |
Batch: 37  |  Train Loss: 0.04455558583140373  |
Batch: 38  |  Train Loss: 0.07619691640138626  |
Batch: 39  |  Train Loss: 0.04051584377884865  |
Batch: 40  |  Train Loss: 0.022111354395747185  |
Batch: 41  |  Train Loss: 0.043220795691013336  |
Batch: 42  |  Train Loss: 0.03620929643511772  |
Batch: 43  |  Train Loss: 0.02537093311548233  |
Batch: 44  |  Train Loss: 0.058794308453798294  |
Batch: 45  |  Train Loss: 0.03961408883333206  |
Batch: 46  |  Train Loss: 0.03452146053314209  |
Batch: 47  |  Train Loss: 0.03788139671087265  |
Batch: 48  |  Train Loss: 0.02514071762561798  |
Batch: 49  |  Train Loss: 0.030416375026106834  |
Batch: 50  |  Train Loss: 0.03415177762508392  |
Batch: 51  |  Train Loss: 0.03202446922659874  |
Batch: 52  |  Train Loss: 0.05892859399318695  |
Batch: 53  |  Train Loss: 0.06095531955361366  |
Batch: 54  |  Train Loss: 0.07032476365566254  |
Batch: 55  |  Train Loss: 0.022740887477993965  |
Batch: 56  |  Train Loss: 0.06558870524168015  |
Batch: 57  |  Train Loss: 0.034062571823596954  |
Batch: 58  |  Train Loss: 0.03633291646838188  |
Batch: 59  |  Train Loss: 0.04211709275841713  |
Batch: 60  |  Train Loss: 0.026648636907339096  |
Batch: 61  |  Train Loss: 0.03354661539196968  |
Batch: 62  |  Train Loss: 0.04472106695175171  |
Batch: 63  |  Train Loss: 0.031129421666264534  |
Batch: 64  |  Train Loss: 0.03744405135512352  |
Batch: 65  |  Train Loss: 0.031409941613674164  |
Batch: 66  |  Train Loss: 0.03886233642697334  |
Batch: 67  |  Train Loss: 0.019385507330298424  |
Batch: 68  |  Train Loss: 0.02226581610739231  |
Batch: 69  |  Train Loss: 0.048371780663728714  |
Batch: 70  |  Train Loss: 0.019826529547572136  |
Batch: 71  |  Train Loss: 0.08411463350057602  |
Batch: 72  |  Train Loss: 0.050889331847429276  |
Batch: 73  |  Train Loss: 0.023845521733164787  |
Batch: 74  |  Train Loss: 0.04852752014994621  |
Batch: 75  |  Train Loss: 0.051262374967336655  |
Batch: 76  |  Train Loss: 0.02862652763724327  |
Batch: 77  |  Train Loss: 0.06068364158272743  |
Batch: 78  |  Train Loss: 0.04577424377202988  |
Batch: 79  |  Train Loss: 0.04291145130991936  |
Batch: 80  |  Train Loss: 0.03066185675561428  |
Batch: 81  |  Train Loss: 0.028319045901298523  |
Batch: 82  |  Train Loss: 0.026692165061831474  |
Batch: 83  |  Train Loss: 0.06230366975069046  |
Batch: 84  |  Train Loss: 0.036797747015953064  |
Batch: 85  |  Train Loss: 0.05002874881029129  |
Batch: 86  |  Train Loss: 0.04640841484069824  |
Batch: 87  |  Train Loss: 0.041698016226291656  |
Batch: 88  |  Train Loss: 0.027621721848845482  |
Batch: 89  |  Train Loss: 0.05596577003598213  |
Batch: 90  |  Train Loss: 0.009727435186505318  |
Batch: 91  |  Train Loss: 0.04198398441076279  |
Batch: 92  |  Train Loss: 0.0435568206012249  |
Batch: 93  |  Train Loss: 0.02368362993001938  |
Batch: 94  |  Train Loss: 0.04855964332818985  |
Batch: 95  |  Train Loss: 0.07548154145479202  |
Batch: 96  |  Train Loss: 0.010594116523861885  |
Batch: 97  |  Train Loss: 0.03973686695098877  |
Batch: 98  |  Train Loss: 0.03743408992886543  |
Batch: 99  |  Train Loss: 0.031123587861657143  |
Batch: 100  |  Train Loss: 0.06910775601863861  |
Batch: 101  |  Train Loss: 0.031407590955495834  |
Batch: 102  |  Train Loss: 0.013324952684342861  |
Batch: 103  |  Train Loss: 0.031084982678294182  |
Batch: 104  |  Train Loss: 0.03721119090914726  |
Batch: 105  |  Train Loss: 0.03318729251623154  |
Batch: 106  |  Train Loss: 0.0692455917596817  |
Batch: 107  |  Train Loss: 0.04399850219488144  |
Batch: 108  |  Train Loss: 0.055379487574100494  |
Batch: 109  |  Train Loss: 0.06386785954236984  |
Batch: 110  |  Train Loss: 0.02138546295464039  |
Batch: 111  |  Train Loss: 0.018812570720911026  |
Batch: 112  |  Train Loss: 0.03030979447066784  |
Batch: 113  |  Train Loss: 0.017423396930098534  |
Batch: 114  |  Train Loss: 0.08003012835979462  |
Batch: 115  |  Train Loss: 0.06546757370233536  |
Batch: 116  |  Train Loss: 0.0371849462389946  |
Batch: 117  |  Train Loss: 0.036198582500219345  |
Batch: 118  |  Train Loss: 0.013502681627869606  |
Batch: 119  |  Train Loss: 0.040715232491493225  |
Batch: 120  |  Train Loss: 0.023675719276070595  |
Batch: 121  |  Train Loss: 0.032940883189439774  |
Batch: 122  |  Train Loss: 0.017442360520362854  |
Batch: 123  |  Train Loss: 0.0509476363658905  |
Batch: 124  |  Train Loss: 0.040267590433359146  |
Batch: 125  |  Train Loss: 0.06667454540729523  |
Batch: 126  |  Train Loss: 0.01835896261036396  |
Batch: 127  |  Train Loss: 0.035708654671907425  |
Batch: 128  |  Train Loss: 0.009907286614179611  |
Batch: 129  |  Train Loss: 0.05550511181354523  |
Batch: 130  |  Train Loss: 0.028833754360675812  |
Batch: 131  |  Train Loss: 0.029521813616156578  |
Batch: 132  |  Train Loss: 0.028045548126101494  |
Batch: 133  |  Train Loss: 0.0498073473572731  |
Batch: 134  |  Train Loss: 0.054673317819833755  |
Batch: 135  |  Train Loss: 0.04982863366603851  |
Batch: 136  |  Train Loss: 0.025507375597953796  |
Batch: 137  |  Train Loss: 0.0526471883058548  |
Batch: 138  |  Train Loss: 0.024896932765841484  |
Batch: 139  |  Train Loss: 0.052833084017038345  |
Batch: 140  |  Train Loss: 0.017146097496151924  |
Batch: 141  |  Train Loss: 0.07305485755205154  |
Batch: 142  |  Train Loss: 0.0869113877415657  |
Batch: 143  |  Train Loss: 0.016484636813402176  |
Batch: 144  |  Train Loss: 0.04644724726676941  |
Batch: 145  |  Train Loss: 0.02446221560239792  |
Batch: 146  |  Train Loss: 0.018768971785902977  |
Batch: 147  |  Train Loss: 0.07116818428039551  |
Batch: 148  |  Train Loss: 0.024120768532156944  |
Batch: 149  |  Train Loss: 0.030076749622821808  |
Batch: 150  |  Train Loss: 0.036335721611976624  |
Batch: 151  |  Train Loss: 0.03518783673644066  |
Batch: 152  |  Train Loss: 0.07279882580041885  |
Batch: 153  |  Train Loss: 0.04765564948320389  |
Batch: 154  |  Train Loss: 0.04016657918691635  |
Batch: 155  |  Train Loss: 0.023115191608667374  |
Batch: 156  |  Train Loss: 0.05111559480428696  |
Batch: 157  |  Train Loss: 0.01764264702796936  |
Batch: 158  |  Train Loss: 0.07600269466638565  |
Batch: 159  |  Train Loss: 0.03809560462832451  |
Batch: 160  |  Train Loss: 0.02318507619202137  |
Batch: 161  |  Train Loss: 0.04297606274485588  |
Batch: 162  |  Train Loss: 0.06905701756477356  |
Batch: 163  |  Train Loss: 0.12831881642341614  |
Batch: 164  |  Train Loss: 0.04286148399114609  |
Batch: 165  |  Train Loss: 0.05519012734293938  |
Batch: 166  |  Train Loss: 0.013577817939221859  |
Batch: 167  |  Train Loss: 0.020119117572903633  |
Batch: 168  |  Train Loss: 0.039837248623371124  |
Batch: 169  |  Train Loss: 0.06596598029136658  |
Batch: 170  |  Train Loss: 0.004956248216331005  |
Batch: 171  |  Train Loss: 0.053025804460048676  |
Batch: 172  |  Train Loss: 0.009671937674283981  |
Batch: 173  |  Train Loss: 0.04336664453148842  |
Batch: 174  |  Train Loss: 0.01659555733203888  |
Batch: 175  |  Train Loss: 0.0159895196557045  |
Batch: 176  |  Train Loss: 0.020646944642066956  |
Batch: 177  |  Train Loss: 0.049252949655056  |
Batch: 178  |  Train Loss: 0.041993532329797745  |
Batch: 179  |  Train Loss: 0.028442123904824257  |
Batch: 180  |  Train Loss: 0.023747874423861504  |
Batch: 181  |  Train Loss: 0.038095515221357346  |
Batch: 182  |  Train Loss: 0.018528876826167107  |
Batch: 183  |  Train Loss: 0.025108423084020615  |
Batch: 184  |  Train Loss: 0.035044729709625244  |
Epoch: 11  |  Train Loss: 0.038745081671387765
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.74it/s]
Binary results:████████████████████████████▉| 1150/1151 [00:50<00:00, 18.95it/s]
################################################################################

Target prec: 0.629
Target recall: 0.615
Target F1: 0.622

Proportional results:
################################################################################

Target prec: 0.540
Target recall: 0.437
Target F1: 0.483

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.86it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.94it/s]
Binary results:█████████████████████████████| 1151/1151 [00:50<00:00, 26.50it/s]
################################################################################

Target prec: 0.696
Target recall: 0.553
Target F1: 0.616

Proportional results:
################################################################################

Target prec: 0.570
Target recall: 0.356
Target F1: 0.438

################# END OF PIPELINE's RESULTS #################
 60%|██████████████████████▏              | 12/20 [3:32:41<2:21:56, 1064.62s/it]Batch: 0  |  Train Loss: 0.03268960863351822  |
Batch: 1  |  Train Loss: 0.024634184315800667  |
Batch: 2  |  Train Loss: 0.01625063642859459  |
Batch: 3  |  Train Loss: 0.03265124931931496  |
Batch: 4  |  Train Loss: 0.016259675845503807  |
Batch: 5  |  Train Loss: 0.02329082414507866  |
Batch: 6  |  Train Loss: 0.032172154635190964  |
Batch: 7  |  Train Loss: 0.013881971128284931  |
Batch: 8  |  Train Loss: 0.034205593168735504  |
Batch: 9  |  Train Loss: 0.03744259104132652  |
Batch: 10  |  Train Loss: 0.036970943212509155  |
Batch: 11  |  Train Loss: 0.06364867836236954  |
Batch: 12  |  Train Loss: 0.051055990159511566  |
Batch: 13  |  Train Loss: 0.05318097025156021  |
Batch: 14  |  Train Loss: 0.022951297461986542  |
Batch: 15  |  Train Loss: 0.054447025060653687  |
Batch: 16  |  Train Loss: 0.014987132512032986  |
Batch: 17  |  Train Loss: 0.013887853361666203  |
Batch: 18  |  Train Loss: 0.013790825381875038  |
Batch: 19  |  Train Loss: 0.020797718316316605  |
Batch: 20  |  Train Loss: 0.0469406358897686  |
Batch: 21  |  Train Loss: 0.03712769225239754  |
Batch: 22  |  Train Loss: 0.022012833505868912  |
Batch: 23  |  Train Loss: 0.02130461297929287  |
Batch: 24  |  Train Loss: 0.040030330419540405  |
Batch: 25  |  Train Loss: 0.024935618042945862  |
Batch: 26  |  Train Loss: 0.04454297572374344  |
Batch: 27  |  Train Loss: 0.01951543055474758  |
Batch: 28  |  Train Loss: 0.023158317431807518  |
Batch: 29  |  Train Loss: 0.03370172530412674  |
Batch: 30  |  Train Loss: 0.050701454281806946  |
Batch: 31  |  Train Loss: 0.014892138540744781  |
Batch: 32  |  Train Loss: 0.018729571253061295  |
Batch: 33  |  Train Loss: 0.03350972384214401  |
Batch: 34  |  Train Loss: 0.03778033331036568  |
Batch: 35  |  Train Loss: 0.03867093846201897  |
Batch: 36  |  Train Loss: 0.048701658844947815  |
Batch: 37  |  Train Loss: 0.02467508241534233  |
Batch: 38  |  Train Loss: 0.027301177382469177  |
Batch: 39  |  Train Loss: 0.06747014075517654  |
Batch: 40  |  Train Loss: 0.06171984598040581  |
Batch: 41  |  Train Loss: 0.02475772425532341  |
Batch: 42  |  Train Loss: 0.03804013133049011  |
Batch: 43  |  Train Loss: 0.02418290264904499  |
Batch: 44  |  Train Loss: 0.017362840473651886  |
Batch: 45  |  Train Loss: 0.03119085542857647  |
Batch: 46  |  Train Loss: 0.024482132866978645  |
Batch: 47  |  Train Loss: 0.07456450909376144  |
Batch: 48  |  Train Loss: 0.03263141214847565  |
Batch: 49  |  Train Loss: 0.03962725028395653  |
Batch: 50  |  Train Loss: 0.025497766211628914  |
Batch: 51  |  Train Loss: 0.02643144130706787  |
Batch: 52  |  Train Loss: 0.055395063012838364  |
Batch: 53  |  Train Loss: 0.053171444684267044  |
Batch: 54  |  Train Loss: 0.09494487196207047  |
Batch: 55  |  Train Loss: 0.027227988466620445  |
Batch: 56  |  Train Loss: 0.02601984702050686  |
Batch: 57  |  Train Loss: 0.05942823737859726  |
Batch: 58  |  Train Loss: 0.05380938947200775  |
Batch: 59  |  Train Loss: 0.03980264067649841  |
Batch: 60  |  Train Loss: 0.025544311851263046  |
Batch: 61  |  Train Loss: 0.026449186727404594  |
Batch: 62  |  Train Loss: 0.016550589352846146  |
Batch: 63  |  Train Loss: 0.018696337938308716  |
Batch: 64  |  Train Loss: 0.04440515860915184  |
Batch: 65  |  Train Loss: 0.032623641192913055  |
Batch: 66  |  Train Loss: 0.03695019707083702  |
Batch: 67  |  Train Loss: 0.0541970357298851  |
Batch: 68  |  Train Loss: 0.007322231773287058  |
Batch: 69  |  Train Loss: 0.04084787890315056  |
Batch: 70  |  Train Loss: 0.018931958824396133  |
Batch: 71  |  Train Loss: 0.0117449089884758  |
Batch: 72  |  Train Loss: 0.02380179427564144  |
Batch: 73  |  Train Loss: 0.03785066306591034  |
Batch: 74  |  Train Loss: 0.042085204273462296  |
Batch: 75  |  Train Loss: 0.010483420453965664  |
Batch: 76  |  Train Loss: 0.029248440638184547  |
Batch: 77  |  Train Loss: 0.050753239542245865  |
Batch: 78  |  Train Loss: 0.02661120519042015  |
Batch: 79  |  Train Loss: 0.0353815071284771  |
Batch: 80  |  Train Loss: 0.008714212104678154  |
Batch: 81  |  Train Loss: 0.045704666525125504  |
Batch: 82  |  Train Loss: 0.04184108227491379  |
Batch: 83  |  Train Loss: 0.03643438220024109  |
Batch: 84  |  Train Loss: 0.011205784045159817  |
Batch: 85  |  Train Loss: 0.03819134831428528  |
Batch: 86  |  Train Loss: 0.04922877252101898  |
Batch: 87  |  Train Loss: 0.040156543254852295  |
Batch: 88  |  Train Loss: 0.033867090940475464  |
Batch: 89  |  Train Loss: 0.03597399592399597  |
Batch: 90  |  Train Loss: 0.06729809939861298  |
Batch: 91  |  Train Loss: 0.03459743410348892  |
Batch: 92  |  Train Loss: 0.04484652727842331  |
Batch: 93  |  Train Loss: 0.03886310011148453  |
Batch: 94  |  Train Loss: 0.057842012494802475  |
Batch: 95  |  Train Loss: 0.025401825085282326  |
Batch: 96  |  Train Loss: 0.04485455900430679  |
Batch: 97  |  Train Loss: 0.034011028707027435  |
Batch: 98  |  Train Loss: 0.03472716733813286  |
Batch: 99  |  Train Loss: 0.03396134078502655  |
Batch: 100  |  Train Loss: 0.05784354731440544  |
Batch: 101  |  Train Loss: 0.0700594037771225  |
Batch: 102  |  Train Loss: 0.021259650588035583  |
Batch: 103  |  Train Loss: 0.02677968144416809  |
Batch: 104  |  Train Loss: 0.060616642236709595  |
Batch: 105  |  Train Loss: 0.025413552299141884  |
Batch: 106  |  Train Loss: 0.039964403957128525  |
Batch: 107  |  Train Loss: 0.0249367356300354  |
Batch: 108  |  Train Loss: 0.05018625035881996  |
Batch: 109  |  Train Loss: 0.0339982733130455  |
Batch: 110  |  Train Loss: 0.02657712996006012  |
Batch: 111  |  Train Loss: 0.03548980504274368  |
Batch: 112  |  Train Loss: 0.023069774731993675  |
Batch: 113  |  Train Loss: 0.02215493656694889  |
Batch: 114  |  Train Loss: 0.03714201599359512  |
Batch: 115  |  Train Loss: 0.041386134922504425  |
Batch: 116  |  Train Loss: 0.014256976544857025  |
Batch: 117  |  Train Loss: 0.05056534335017204  |
Batch: 118  |  Train Loss: 0.011179856024682522  |
Batch: 119  |  Train Loss: 0.017761673778295517  |
Batch: 120  |  Train Loss: 0.05373529717326164  |
Batch: 121  |  Train Loss: 0.02656879648566246  |
Batch: 122  |  Train Loss: 0.026454390957951546  |
Batch: 123  |  Train Loss: 0.05654773488640785  |
Batch: 124  |  Train Loss: 0.01598067581653595  |
Batch: 125  |  Train Loss: 0.03187993913888931  |
Batch: 126  |  Train Loss: 0.01335306465625763  |
Batch: 127  |  Train Loss: 0.03238007053732872  |
Batch: 128  |  Train Loss: 0.045781590044498444  |
Batch: 129  |  Train Loss: 0.010978338308632374  |
Batch: 130  |  Train Loss: 0.03821860998868942  |
Batch: 131  |  Train Loss: 0.02557968534529209  |
Batch: 132  |  Train Loss: 0.01335142645984888  |
Batch: 133  |  Train Loss: 0.05183076485991478  |
Batch: 134  |  Train Loss: 0.040388479828834534  |
Batch: 135  |  Train Loss: 0.04668942466378212  |
Batch: 136  |  Train Loss: 0.05723295360803604  |
Batch: 137  |  Train Loss: 0.0491434670984745  |
Batch: 138  |  Train Loss: 0.055764999240636826  |
Batch: 139  |  Train Loss: 0.024135269224643707  |
Batch: 140  |  Train Loss: 0.03843553364276886  |
Batch: 141  |  Train Loss: 0.04386339336633682  |
Batch: 142  |  Train Loss: 0.033402442932128906  |
Batch: 143  |  Train Loss: 0.02266560308635235  |
Batch: 144  |  Train Loss: 0.02605426125228405  |
Batch: 145  |  Train Loss: 0.04701989144086838  |
Batch: 146  |  Train Loss: 0.037926360964775085  |
Batch: 147  |  Train Loss: 0.019535787403583527  |
Batch: 148  |  Train Loss: 0.032353565096855164  |
Batch: 149  |  Train Loss: 0.026837965473532677  |
Batch: 150  |  Train Loss: 0.020580193027853966  |
Batch: 151  |  Train Loss: 0.03452916815876961  |
Batch: 152  |  Train Loss: 0.04964809864759445  |
Batch: 153  |  Train Loss: 0.07201511412858963  |
Batch: 154  |  Train Loss: 0.0341988280415535  |
Batch: 155  |  Train Loss: 0.04788454622030258  |
Batch: 156  |  Train Loss: 0.03352455049753189  |
Batch: 157  |  Train Loss: 0.029806219041347504  |
Batch: 158  |  Train Loss: 0.01717809960246086  |
Batch: 159  |  Train Loss: 0.037773750722408295  |
Batch: 160  |  Train Loss: 0.03566758707165718  |
Batch: 161  |  Train Loss: 0.024878839030861855  |
Batch: 162  |  Train Loss: 0.06765923649072647  |
Batch: 163  |  Train Loss: 0.06165355443954468  |
Batch: 164  |  Train Loss: 0.038511838763952255  |
Batch: 165  |  Train Loss: 0.05047550052404404  |
Batch: 166  |  Train Loss: 0.027289507910609245  |
Batch: 167  |  Train Loss: 0.018234502524137497  |
Batch: 168  |  Train Loss: 0.029560767114162445  |
Batch: 169  |  Train Loss: 0.010757369920611382  |
Batch: 170  |  Train Loss: 0.014112953096628189  |
Batch: 171  |  Train Loss: 0.015588948503136635  |
Batch: 172  |  Train Loss: 0.02839355543255806  |
Batch: 173  |  Train Loss: 0.026939714327454567  |
Batch: 174  |  Train Loss: 0.02376117743551731  |
Batch: 175  |  Train Loss: 0.061695221811532974  |
Batch: 176  |  Train Loss: 0.02118128165602684  |
Batch: 177  |  Train Loss: 0.029960831627249718  |
Batch: 178  |  Train Loss: 0.06159104034304619  |
Batch: 179  |  Train Loss: 0.032149069011211395  |
Batch: 180  |  Train Loss: 0.05194207280874252  |
Batch: 181  |  Train Loss: 0.025800611823797226  |
Batch: 182  |  Train Loss: 0.05184904485940933  |
Batch: 183  |  Train Loss: 0.01856902427971363  |
Batch: 184  |  Train Loss: 0.03986703231930733  |
Epoch: 12  |  Train Loss: 0.034828907646540855
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.76it/s]
Binary results:████████████████████████████▉| 1149/1151 [00:50<00:00, 24.74it/s]
################################################################################

Target prec: 0.607
Target recall: 0.617
Target F1: 0.612

Proportional results:
################################################################################

Target prec: 0.527
Target recall: 0.447
Target F1: 0.484

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.77it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.81it/s]
Binary results:████████████████████████████▉| 1150/1151 [00:50<00:00, 24.28it/s]
################################################################################

Target prec: 0.679
Target recall: 0.556
Target F1: 0.611

Proportional results:
################################################################################

Target prec: 0.548
Target recall: 0.359
Target F1: 0.434

################# END OF PIPELINE's RESULTS #################
 65%|████████████████████████             | 13/20 [3:50:35<2:04:32, 1067.54s/it]Batch: 0  |  Train Loss: 0.059931714087724686  |
Batch: 1  |  Train Loss: 0.02855617180466652  |
Batch: 2  |  Train Loss: 0.02972414344549179  |
Batch: 3  |  Train Loss: 0.03382732719182968  |
Batch: 4  |  Train Loss: 0.024389080703258514  |
Batch: 5  |  Train Loss: 0.02992921508848667  |
Batch: 6  |  Train Loss: 0.013912048190832138  |
Batch: 7  |  Train Loss: 0.02660214900970459  |
Batch: 8  |  Train Loss: 0.012691856361925602  |
Batch: 9  |  Train Loss: 0.024793429300189018  |
Batch: 10  |  Train Loss: 0.02965412847697735  |
Batch: 11  |  Train Loss: 0.02413952723145485  |
Batch: 12  |  Train Loss: 0.02865585871040821  |
Batch: 13  |  Train Loss: 0.04949766397476196  |
Batch: 14  |  Train Loss: 0.030431082472205162  |
Batch: 15  |  Train Loss: 0.02130623161792755  |
Batch: 16  |  Train Loss: 0.014420241117477417  |
Batch: 17  |  Train Loss: 0.011944186873733997  |
Batch: 18  |  Train Loss: 0.028880702331662178  |
Batch: 19  |  Train Loss: 0.06821099668741226  |
Batch: 20  |  Train Loss: 0.022124800831079483  |
Batch: 21  |  Train Loss: 0.03768008574843407  |
Batch: 22  |  Train Loss: 0.016276618465781212  |
Batch: 23  |  Train Loss: 0.01980995386838913  |
Batch: 24  |  Train Loss: 0.028622286394238472  |
Batch: 25  |  Train Loss: 0.0240651685744524  |
Batch: 26  |  Train Loss: 0.03667931631207466  |
Batch: 27  |  Train Loss: 0.040018532425165176  |
Batch: 28  |  Train Loss: 0.008111493661999702  |
Batch: 29  |  Train Loss: 0.034154362976551056  |
Batch: 30  |  Train Loss: 0.05196787044405937  |
Batch: 31  |  Train Loss: 0.04631693661212921  |
Batch: 32  |  Train Loss: 0.04158037528395653  |
Batch: 33  |  Train Loss: 0.027167702093720436  |
Batch: 34  |  Train Loss: 0.05506184324622154  |
Batch: 35  |  Train Loss: 0.04874621704220772  |
Batch: 36  |  Train Loss: 0.028486032038927078  |
Batch: 37  |  Train Loss: 0.05478774011135101  |
Batch: 38  |  Train Loss: 0.03423116356134415  |
Batch: 39  |  Train Loss: 0.01232071127742529  |
Batch: 40  |  Train Loss: 0.019601138308644295  |
Batch: 41  |  Train Loss: 0.014124940149486065  |
Batch: 42  |  Train Loss: 0.023285770788788795  |
Batch: 43  |  Train Loss: 0.0646476000547409  |
Batch: 44  |  Train Loss: 0.0237722285091877  |
Batch: 45  |  Train Loss: 0.012784210965037346  |
Batch: 46  |  Train Loss: 0.010936695151031017  |
Batch: 47  |  Train Loss: 0.04206610098481178  |
Batch: 48  |  Train Loss: 0.044500287622213364  |
Batch: 49  |  Train Loss: 0.028242172673344612  |
Batch: 50  |  Train Loss: 0.030045386403799057  |
Batch: 51  |  Train Loss: 0.05085980147123337  |
Batch: 52  |  Train Loss: 0.02239253930747509  |
Batch: 53  |  Train Loss: 0.014074699021875858  |
Batch: 54  |  Train Loss: 0.03874223679304123  |
Batch: 55  |  Train Loss: 0.037341102957725525  |
Batch: 56  |  Train Loss: 0.019954241812229156  |
Batch: 57  |  Train Loss: 0.011567624285817146  |
Batch: 58  |  Train Loss: 0.021886665374040604  |
Batch: 59  |  Train Loss: 0.04306177422404289  |
Batch: 60  |  Train Loss: 0.030887814238667488  |
Batch: 61  |  Train Loss: 0.014024585485458374  |
Batch: 62  |  Train Loss: 0.04948365315794945  |
Batch: 63  |  Train Loss: 0.043148674070835114  |
Batch: 64  |  Train Loss: 0.0163877010345459  |
Batch: 65  |  Train Loss: 0.025158531963825226  |
Batch: 66  |  Train Loss: 0.02480653114616871  |
Batch: 67  |  Train Loss: 0.04060783237218857  |
Batch: 68  |  Train Loss: 0.026435209438204765  |
Batch: 69  |  Train Loss: 0.03216645121574402  |
Batch: 70  |  Train Loss: 0.030329568311572075  |
Batch: 71  |  Train Loss: 0.055933885276317596  |
Batch: 72  |  Train Loss: 0.05140376091003418  |
Batch: 73  |  Train Loss: 0.06432905048131943  |
Batch: 74  |  Train Loss: 0.03586546704173088  |
Batch: 75  |  Train Loss: 0.038204122334718704  |
Batch: 76  |  Train Loss: 0.018962664529681206  |
Batch: 77  |  Train Loss: 0.029120154678821564  |
Batch: 78  |  Train Loss: 0.0352785587310791  |
Batch: 79  |  Train Loss: 0.011864208616316319  |
Batch: 80  |  Train Loss: 0.030758878216147423  |
Batch: 81  |  Train Loss: 0.03643162176012993  |
Batch: 82  |  Train Loss: 0.016540179029107094  |
Batch: 83  |  Train Loss: 0.06262189149856567  |
Batch: 84  |  Train Loss: 0.02768034115433693  |
Batch: 85  |  Train Loss: 0.0377337709069252  |
Batch: 86  |  Train Loss: 0.02268275059759617  |
Batch: 87  |  Train Loss: 0.024301141500473022  |
Batch: 88  |  Train Loss: 0.014868269674479961  |
Batch: 89  |  Train Loss: 0.04570956528186798  |
Batch: 90  |  Train Loss: 0.01629909873008728  |
Batch: 91  |  Train Loss: 0.014979756437242031  |
Batch: 92  |  Train Loss: 0.03843744471669197  |
Batch: 93  |  Train Loss: 0.03242387995123863  |
Batch: 94  |  Train Loss: 0.027847740799188614  |
Batch: 95  |  Train Loss: 0.026328211650252342  |
Batch: 96  |  Train Loss: 0.017697442322969437  |
Batch: 97  |  Train Loss: 0.024290917441248894  |
Batch: 98  |  Train Loss: 0.04470934346318245  |
Batch: 99  |  Train Loss: 0.015944696962833405  |
Batch: 100  |  Train Loss: 0.014111602678894997  |
Batch: 101  |  Train Loss: 0.039285387843847275  |
Batch: 102  |  Train Loss: 0.0199996680021286  |
Batch: 103  |  Train Loss: 0.0427960641682148  |
Batch: 104  |  Train Loss: 0.03275895118713379  |
Batch: 105  |  Train Loss: 0.016096239909529686  |
Batch: 106  |  Train Loss: 0.012727870605885983  |
Batch: 107  |  Train Loss: 0.037936098873615265  |
Batch: 108  |  Train Loss: 0.05301530659198761  |
Batch: 109  |  Train Loss: 0.013171976432204247  |
Batch: 110  |  Train Loss: 0.05787666141986847  |
Batch: 111  |  Train Loss: 0.03320989012718201  |
Batch: 112  |  Train Loss: 0.030621392652392387  |
Batch: 113  |  Train Loss: 0.006479564122855663  |
Batch: 114  |  Train Loss: 0.043134905397892  |
Batch: 115  |  Train Loss: 0.028451286256313324  |
Batch: 116  |  Train Loss: 0.03218868747353554  |
Batch: 117  |  Train Loss: 0.01097923330962658  |
Batch: 118  |  Train Loss: 0.027447976171970367  |
Batch: 119  |  Train Loss: 0.06085314601659775  |
Batch: 120  |  Train Loss: 0.036904267966747284  |
Batch: 121  |  Train Loss: 0.026658937335014343  |
Batch: 122  |  Train Loss: 0.053149979561567307  |
Batch: 123  |  Train Loss: 0.034307222813367844  |
Batch: 124  |  Train Loss: 0.01592370867729187  |
Batch: 125  |  Train Loss: 0.01109270378947258  |
Batch: 126  |  Train Loss: 0.03907458111643791  |
Batch: 127  |  Train Loss: 0.03164280951023102  |
Batch: 128  |  Train Loss: 0.029583679512143135  |
Batch: 129  |  Train Loss: 0.06268608570098877  |
Batch: 130  |  Train Loss: 0.033285606652498245  |
Batch: 131  |  Train Loss: 0.0374193973839283  |
Batch: 132  |  Train Loss: 0.04185715690255165  |
Batch: 133  |  Train Loss: 0.015897050499916077  |
Batch: 134  |  Train Loss: 0.020326634868979454  |
Batch: 135  |  Train Loss: 0.03422117978334427  |
Batch: 136  |  Train Loss: 0.06820139288902283  |
Batch: 137  |  Train Loss: 0.034984104335308075  |
Batch: 138  |  Train Loss: 0.07375762611627579  |
Batch: 139  |  Train Loss: 0.02888794057071209  |
Batch: 140  |  Train Loss: 0.02153492346405983  |
Batch: 141  |  Train Loss: 0.01805206574499607  |
Batch: 142  |  Train Loss: 0.02987596020102501  |
Batch: 143  |  Train Loss: 0.049383170902729034  |
Batch: 144  |  Train Loss: 0.016291998326778412  |
Batch: 145  |  Train Loss: 0.023265892639756203  |
Batch: 146  |  Train Loss: 0.04028763622045517  |
Batch: 147  |  Train Loss: 0.03549989312887192  |
Batch: 148  |  Train Loss: 0.03271676227450371  |
Batch: 149  |  Train Loss: 0.015598938800394535  |
Batch: 150  |  Train Loss: 0.012947342358529568  |
Batch: 151  |  Train Loss: 0.007089867722243071  |
Batch: 152  |  Train Loss: 0.0276868287473917  |
Batch: 153  |  Train Loss: 0.022335799410939217  |
Batch: 154  |  Train Loss: 0.027564985677599907  |
Batch: 155  |  Train Loss: 0.05635545775294304  |
Batch: 156  |  Train Loss: 0.013005414977669716  |
Batch: 157  |  Train Loss: 0.01735072396695614  |
Batch: 158  |  Train Loss: 0.0342172235250473  |
Batch: 159  |  Train Loss: 0.030695443972945213  |
Batch: 160  |  Train Loss: 0.041285958141088486  |
Batch: 161  |  Train Loss: 0.042789947241544724  |
Batch: 162  |  Train Loss: 0.04266607016324997  |
Batch: 163  |  Train Loss: 0.03929606452584267  |
Batch: 164  |  Train Loss: 0.006785864010453224  |
Batch: 165  |  Train Loss: 0.012094877660274506  |
Batch: 166  |  Train Loss: 0.04476412758231163  |
Batch: 167  |  Train Loss: 0.024020081385970116  |
Batch: 168  |  Train Loss: 0.04698538780212402  |
Batch: 169  |  Train Loss: 0.00434945710003376  |
Batch: 170  |  Train Loss: 0.015681389719247818  |
Batch: 171  |  Train Loss: 0.04881403595209122  |
Batch: 172  |  Train Loss: 0.03758588805794716  |
Batch: 173  |  Train Loss: 0.025785809382796288  |
Batch: 174  |  Train Loss: 0.07866941392421722  |
Batch: 175  |  Train Loss: 0.028991807252168655  |
Batch: 176  |  Train Loss: 0.033955659717321396  |
Batch: 177  |  Train Loss: 0.012520506046712399  |
Batch: 178  |  Train Loss: 0.02502181939780712  |
Batch: 179  |  Train Loss: 0.0375259593129158  |
Batch: 180  |  Train Loss: 0.03423599898815155  |
Batch: 181  |  Train Loss: 0.018735626712441444  |
Batch: 182  |  Train Loss: 0.03631429374217987  |
Batch: 183  |  Train Loss: 0.03737157583236694  |
Batch: 184  |  Train Loss: 0.03189413994550705  |
Epoch: 13  |  Train Loss: 0.03118476548257309
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.80it/s]
Binary results:█████████████████████████████| 1151/1151 [00:50<00:00, 21.82it/s]
################################################################################

Target prec: 0.602
Target recall: 0.669
Target F1: 0.634

Proportional results:
################################################################################

Target prec: 0.515
Target recall: 0.492
Target F1: 0.503

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.85it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.76it/s]
Binary results:████████████████████████████▉| 1149/1151 [00:50<00:00, 22.49it/s]
################################################################################

Target prec: 0.680
Target recall: 0.594
Target F1: 0.634

Proportional results:
################################################################################

Target prec: 0.551
Target recall: 0.387
Target F1: 0.454

################# END OF PIPELINE's RESULTS #################
 70%|█████████████████████████▉           | 14/20 [4:08:20<1:46:41, 1066.91s/it]Batch: 0  |  Train Loss: 0.005730276927351952  |
Batch: 1  |  Train Loss: 0.02334657497704029  |
Batch: 2  |  Train Loss: 0.062258683145046234  |
Batch: 3  |  Train Loss: 0.045370712876319885  |
Batch: 4  |  Train Loss: 0.01866641826927662  |
Batch: 5  |  Train Loss: 0.07781956344842911  |
Batch: 6  |  Train Loss: 0.05029936507344246  |
Batch: 7  |  Train Loss: 0.015603894367814064  |
Batch: 8  |  Train Loss: 0.026904959231615067  |
Batch: 9  |  Train Loss: 0.017129000276327133  |
Batch: 10  |  Train Loss: 0.015805412083864212  |
Batch: 11  |  Train Loss: 0.010471913032233715  |
Batch: 12  |  Train Loss: 0.011086158454418182  |
Batch: 13  |  Train Loss: 0.028842462226748466  |
Batch: 14  |  Train Loss: 0.005814581643790007  |
Batch: 15  |  Train Loss: 0.0347798690199852  |
Batch: 16  |  Train Loss: 0.017984138801693916  |
Batch: 17  |  Train Loss: 0.014809923246502876  |
Batch: 18  |  Train Loss: 0.010972147807478905  |
Batch: 19  |  Train Loss: 0.025572480633854866  |
Batch: 20  |  Train Loss: 0.04592989757657051  |
Batch: 21  |  Train Loss: 0.010659534484148026  |
Batch: 22  |  Train Loss: 0.015843357890844345  |
Batch: 23  |  Train Loss: 0.019443806260824203  |
Batch: 24  |  Train Loss: 0.04470028355717659  |
Batch: 25  |  Train Loss: 0.04797198623418808  |
Batch: 26  |  Train Loss: 0.034604497253894806  |
Batch: 27  |  Train Loss: 0.020976079627871513  |
Batch: 28  |  Train Loss: 0.03950079530477524  |
Batch: 29  |  Train Loss: 0.03571062907576561  |
Batch: 30  |  Train Loss: 0.02291739545762539  |
Batch: 31  |  Train Loss: 0.010290805250406265  |
Batch: 32  |  Train Loss: 0.035229023545980453  |
Batch: 33  |  Train Loss: 0.027381105348467827  |
Batch: 34  |  Train Loss: 0.013626706786453724  |
Batch: 35  |  Train Loss: 0.015742333605885506  |
Batch: 36  |  Train Loss: 0.038980063050985336  |
Batch: 37  |  Train Loss: 0.018382294103503227  |
Batch: 38  |  Train Loss: 0.036570556461811066  |
Batch: 39  |  Train Loss: 0.025804517790675163  |
Batch: 40  |  Train Loss: 0.03212372958660126  |
Batch: 41  |  Train Loss: 0.05749606341123581  |
Batch: 42  |  Train Loss: 0.05043722689151764  |
Batch: 43  |  Train Loss: 0.05509641766548157  |
Batch: 44  |  Train Loss: 0.059743933379650116  |
Batch: 45  |  Train Loss: 0.015947364270687103  |
Batch: 46  |  Train Loss: 0.00561228534206748  |
Batch: 47  |  Train Loss: 0.08601019531488419  |
Batch: 48  |  Train Loss: 0.03843957185745239  |
Batch: 49  |  Train Loss: 0.05040845647454262  |
Batch: 50  |  Train Loss: 0.03090003877878189  |
Batch: 51  |  Train Loss: 0.05927170813083649  |
Batch: 52  |  Train Loss: 0.0445530042052269  |
Batch: 53  |  Train Loss: 0.028594372794032097  |
Batch: 54  |  Train Loss: 0.010652734898030758  |
Batch: 55  |  Train Loss: 0.044891562312841415  |
Batch: 56  |  Train Loss: 0.05334795266389847  |
Batch: 57  |  Train Loss: 0.043009836226701736  |
Batch: 58  |  Train Loss: 0.027894753962755203  |
Batch: 59  |  Train Loss: 0.06624317169189453  |
Batch: 60  |  Train Loss: 0.01680080220103264  |
Batch: 61  |  Train Loss: 0.047360606491565704  |
Batch: 62  |  Train Loss: 0.059044260531663895  |
Batch: 63  |  Train Loss: 0.016858698800206184  |
Batch: 64  |  Train Loss: 0.024833902716636658  |
Batch: 65  |  Train Loss: 0.006182462442666292  |
Batch: 66  |  Train Loss: 0.019941041246056557  |
Batch: 67  |  Train Loss: 0.034127913415431976  |
Batch: 68  |  Train Loss: 0.018289104104042053  |
Batch: 69  |  Train Loss: 0.02200569584965706  |
Batch: 70  |  Train Loss: 0.019123809412121773  |
Batch: 71  |  Train Loss: 0.03583613038063049  |
Batch: 72  |  Train Loss: 0.08639354258775711  |
Batch: 73  |  Train Loss: 0.039783161133527756  |
Batch: 74  |  Train Loss: 0.024053066968917847  |
Batch: 75  |  Train Loss: 0.02764235995709896  |
Batch: 76  |  Train Loss: 0.03866661712527275  |
Batch: 77  |  Train Loss: 0.02960572950541973  |
Batch: 78  |  Train Loss: 0.01749141328036785  |
Batch: 79  |  Train Loss: 0.028764983639121056  |
Batch: 80  |  Train Loss: 0.005694221705198288  |
Batch: 81  |  Train Loss: 0.058980900794267654  |
Batch: 82  |  Train Loss: 0.011527957394719124  |
Batch: 83  |  Train Loss: 0.049087971448898315  |
Batch: 84  |  Train Loss: 0.023290108889341354  |
Batch: 85  |  Train Loss: 0.0320003367960453  |
Batch: 86  |  Train Loss: 0.025952383875846863  |
Batch: 87  |  Train Loss: 0.015870891511440277  |
Batch: 88  |  Train Loss: 0.06275131553411484  |
Batch: 89  |  Train Loss: 0.017514020204544067  |
Batch: 90  |  Train Loss: 0.03179960697889328  |
Batch: 91  |  Train Loss: 0.02206997573375702  |
Batch: 92  |  Train Loss: 0.027356503531336784  |
Batch: 93  |  Train Loss: 0.013267110101878643  |
Batch: 94  |  Train Loss: 0.018543487414717674  |
Batch: 95  |  Train Loss: 0.014593309722840786  |
Batch: 96  |  Train Loss: 0.05286889523267746  |
Batch: 97  |  Train Loss: 0.00945686362683773  |
Batch: 98  |  Train Loss: 0.011536222882568836  |
Batch: 99  |  Train Loss: 0.03471722826361656  |
Batch: 100  |  Train Loss: 0.03132617101073265  |
Batch: 101  |  Train Loss: 0.027200311422348022  |
Batch: 102  |  Train Loss: 0.02400451898574829  |
Batch: 103  |  Train Loss: 0.02905319444835186  |
Batch: 104  |  Train Loss: 0.016095800325274467  |
Batch: 105  |  Train Loss: 0.04999541491270065  |
Batch: 106  |  Train Loss: 0.0206060279160738  |
Batch: 107  |  Train Loss: 0.02107859030365944  |
Batch: 108  |  Train Loss: 0.007903398014605045  |
Batch: 109  |  Train Loss: 0.020323781296610832  |
Batch: 110  |  Train Loss: 0.030146479606628418  |
Batch: 111  |  Train Loss: 0.0040903412736952305  |
Batch: 112  |  Train Loss: 0.01438024453818798  |
Batch: 113  |  Train Loss: 0.04972400516271591  |
Batch: 114  |  Train Loss: 0.014909579418599606  |
Batch: 115  |  Train Loss: 0.029010474681854248  |
Batch: 116  |  Train Loss: 0.007272027432918549  |
Batch: 117  |  Train Loss: 0.06863458454608917  |
Batch: 118  |  Train Loss: 0.026906656101346016  |
Batch: 119  |  Train Loss: 0.022929640486836433  |
Batch: 120  |  Train Loss: 0.008948683738708496  |
Batch: 121  |  Train Loss: 0.009358144365251064  |
Batch: 122  |  Train Loss: 0.022328361868858337  |
Batch: 123  |  Train Loss: 0.02956767939031124  |
Batch: 124  |  Train Loss: 0.06060302257537842  |
Batch: 125  |  Train Loss: 0.030382098630070686  |
Batch: 126  |  Train Loss: 0.030101848766207695  |
Batch: 127  |  Train Loss: 0.026750141754746437  |
Batch: 128  |  Train Loss: 0.017525486648082733  |
Batch: 129  |  Train Loss: 0.004812687635421753  |
Batch: 130  |  Train Loss: 0.03605292737483978  |
Batch: 131  |  Train Loss: 0.020836392417550087  |
Batch: 132  |  Train Loss: 0.04427178576588631  |
Batch: 133  |  Train Loss: 0.03473092243075371  |
Batch: 134  |  Train Loss: 0.014946901239454746  |
Batch: 135  |  Train Loss: 0.03340115025639534  |
Batch: 136  |  Train Loss: 0.022638609632849693  |
Batch: 137  |  Train Loss: 0.034284353256225586  |
Batch: 138  |  Train Loss: 0.007923937402665615  |
Batch: 139  |  Train Loss: 0.010306288488209248  |
Batch: 140  |  Train Loss: 0.07247917354106903  |
Batch: 141  |  Train Loss: 0.05485314503312111  |
Batch: 142  |  Train Loss: 0.016927799209952354  |
Batch: 143  |  Train Loss: 0.025021545588970184  |
Batch: 144  |  Train Loss: 0.03694644570350647  |
Batch: 145  |  Train Loss: 0.03319389745593071  |
Batch: 146  |  Train Loss: 0.07113916426897049  |
Batch: 147  |  Train Loss: 0.033782634884119034  |
Batch: 148  |  Train Loss: 0.020484939217567444  |
Batch: 149  |  Train Loss: 0.021683769300580025  |
Batch: 150  |  Train Loss: 0.015711279585957527  |
Batch: 151  |  Train Loss: 0.018471483141183853  |
Batch: 152  |  Train Loss: 0.024250106886029243  |
Batch: 153  |  Train Loss: 0.03267044201493263  |
Batch: 154  |  Train Loss: 0.01899249292910099  |
Batch: 155  |  Train Loss: 0.04627428203821182  |
Batch: 156  |  Train Loss: 0.013346035033464432  |
Batch: 157  |  Train Loss: 0.006225760094821453  |
Batch: 158  |  Train Loss: 0.022084945812821388  |
Batch: 159  |  Train Loss: 0.03786250948905945  |
Batch: 160  |  Train Loss: 0.07461412996053696  |
Batch: 161  |  Train Loss: 0.02288467437028885  |
Batch: 162  |  Train Loss: 0.02699894830584526  |
Batch: 163  |  Train Loss: 0.016868900507688522  |
Batch: 164  |  Train Loss: 0.028095917776226997  |
Batch: 165  |  Train Loss: 0.026171602308750153  |
Batch: 166  |  Train Loss: 0.014239051379263401  |
Batch: 167  |  Train Loss: 0.04452313110232353  |
Batch: 168  |  Train Loss: 0.05007733404636383  |
Batch: 169  |  Train Loss: 0.025994764640927315  |
Batch: 170  |  Train Loss: 0.019231976941227913  |
Batch: 171  |  Train Loss: 0.03358319774270058  |
Batch: 172  |  Train Loss: 0.04092146456241608  |
Batch: 173  |  Train Loss: 0.03336266055703163  |
Batch: 174  |  Train Loss: 0.0326271615922451  |
Batch: 175  |  Train Loss: 0.01844477467238903  |
Batch: 176  |  Train Loss: 0.027667758986353874  |
Batch: 177  |  Train Loss: 0.01485429983586073  |
Batch: 178  |  Train Loss: 0.04099411889910698  |
Batch: 179  |  Train Loss: 0.020305117592215538  |
Batch: 180  |  Train Loss: 0.026495566591620445  |
Batch: 181  |  Train Loss: 0.024433184415102005  |
Batch: 182  |  Train Loss: 0.08712586015462875  |
Batch: 183  |  Train Loss: 0.01083791721612215  |
Batch: 184  |  Train Loss: 0.024834997951984406  |
Epoch: 14  |  Train Loss: 0.029815385007374996
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.84it/s]
Binary results:████████████████████████████▉| 1150/1151 [00:50<00:00, 23.77it/s]
################################################################################

Target prec: 0.597
Target recall: 0.615
Target F1: 0.606

Proportional results:
################################################################################

Target prec: 0.518
Target recall: 0.426
Target F1: 0.467

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.95it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.71it/s]
Binary results:█████████████████████████████| 1151/1151 [00:50<00:00, 21.49it/s]
################################################################################

Target prec: 0.682
Target recall: 0.549
Target F1: 0.609

Proportional results:
################################################################################

Target prec: 0.555
Target recall: 0.351
Target F1: 0.430

################# END OF PIPELINE's RESULTS #################
 75%|███████████████████████████▊         | 15/20 [4:26:11<1:29:00, 1068.08s/it]Batch: 0  |  Train Loss: 0.020596010610461235  |
Batch: 1  |  Train Loss: 0.05185769498348236  |
Batch: 2  |  Train Loss: 0.018994299694895744  |
Batch: 3  |  Train Loss: 0.04181710630655289  |
Batch: 4  |  Train Loss: 0.023271610960364342  |
Batch: 5  |  Train Loss: 0.01755685918033123  |
Batch: 6  |  Train Loss: 0.010303574614226818  |
Batch: 7  |  Train Loss: 0.01505318097770214  |
Batch: 8  |  Train Loss: 0.022173959761857986  |
Batch: 9  |  Train Loss: 0.03294551372528076  |
Batch: 10  |  Train Loss: 0.05051232874393463  |
Batch: 11  |  Train Loss: 0.022395942360162735  |
Batch: 12  |  Train Loss: 0.040287360548973083  |
Batch: 13  |  Train Loss: 0.01327972300350666  |
Batch: 14  |  Train Loss: 0.04834626615047455  |
Batch: 15  |  Train Loss: 0.0365154966711998  |
Batch: 16  |  Train Loss: 0.023548077791929245  |
Batch: 17  |  Train Loss: 0.013538787141442299  |
Batch: 18  |  Train Loss: 0.037554118782281876  |
Batch: 19  |  Train Loss: 0.00977094005793333  |
Batch: 20  |  Train Loss: 0.009145690128207207  |
Batch: 21  |  Train Loss: 0.032886914908885956  |
Batch: 22  |  Train Loss: 0.021488534286618233  |
Batch: 23  |  Train Loss: 0.020267164334654808  |
Batch: 24  |  Train Loss: 0.00799440685659647  |
Batch: 25  |  Train Loss: 0.04130938649177551  |
Batch: 26  |  Train Loss: 0.010140257887542248  |
Batch: 27  |  Train Loss: 0.016527852043509483  |
Batch: 28  |  Train Loss: 0.0338132344186306  |
Batch: 29  |  Train Loss: 0.04625929892063141  |
Batch: 30  |  Train Loss: 0.01930336095392704  |
Batch: 31  |  Train Loss: 0.042375653982162476  |
Batch: 32  |  Train Loss: 0.05722520500421524  |
Batch: 33  |  Train Loss: 0.03222346305847168  |
Batch: 34  |  Train Loss: 0.010042482987046242  |
Batch: 35  |  Train Loss: 0.011863593012094498  |
Batch: 36  |  Train Loss: 0.034390222281217575  |
Batch: 37  |  Train Loss: 0.017305642366409302  |
Batch: 38  |  Train Loss: 0.05119016021490097  |
Batch: 39  |  Train Loss: 0.028477102518081665  |
Batch: 40  |  Train Loss: 0.03727884218096733  |
Batch: 41  |  Train Loss: 0.0204897653311491  |
Batch: 42  |  Train Loss: 0.012655502185225487  |
Batch: 43  |  Train Loss: 0.02420751564204693  |
Batch: 44  |  Train Loss: 0.005053046625107527  |
Batch: 45  |  Train Loss: 0.03670583292841911  |
Batch: 46  |  Train Loss: 0.01692015491425991  |
Batch: 47  |  Train Loss: 0.021801313385367393  |
Batch: 48  |  Train Loss: 0.018656473606824875  |
Batch: 49  |  Train Loss: 0.014762465842068195  |
Batch: 50  |  Train Loss: 0.022140877321362495  |
Batch: 51  |  Train Loss: 0.012824810110032558  |
Batch: 52  |  Train Loss: 0.018894366919994354  |
Batch: 53  |  Train Loss: 0.05201295018196106  |
Batch: 54  |  Train Loss: 0.02592293918132782  |
Batch: 55  |  Train Loss: 0.012794031761586666  |
Batch: 56  |  Train Loss: 0.02263970673084259  |
Batch: 57  |  Train Loss: 0.01609519124031067  |
Batch: 58  |  Train Loss: 0.03241248428821564  |
Batch: 59  |  Train Loss: 0.04323204979300499  |
Batch: 60  |  Train Loss: 0.03764394298195839  |
Batch: 61  |  Train Loss: 0.022277027368545532  |
Batch: 62  |  Train Loss: 0.007244377862662077  |
Batch: 63  |  Train Loss: 0.01581553928554058  |
Batch: 64  |  Train Loss: 0.0551835373044014  |
Batch: 65  |  Train Loss: 0.025958377867937088  |
Batch: 66  |  Train Loss: 0.020353365689516068  |
Batch: 67  |  Train Loss: 0.011844550259411335  |
Batch: 68  |  Train Loss: 0.025707174092531204  |
Batch: 69  |  Train Loss: 0.03391893580555916  |
Batch: 70  |  Train Loss: 0.013776029460132122  |
Batch: 71  |  Train Loss: 0.046455174684524536  |
Batch: 72  |  Train Loss: 0.009790566749870777  |
Batch: 73  |  Train Loss: 0.010869370773434639  |
Batch: 74  |  Train Loss: 0.029326792806386948  |
Batch: 75  |  Train Loss: 0.014836042188107967  |
Batch: 76  |  Train Loss: 0.013193316757678986  |
Batch: 77  |  Train Loss: 0.007624272722750902  |
Batch: 78  |  Train Loss: 0.014085394330322742  |
Batch: 79  |  Train Loss: 0.01165093295276165  |
Batch: 80  |  Train Loss: 0.014476992189884186  |
Batch: 81  |  Train Loss: 0.03948100283741951  |
Batch: 82  |  Train Loss: 0.033283136785030365  |
Batch: 83  |  Train Loss: 0.011088015511631966  |
Batch: 84  |  Train Loss: 0.052322108298540115  |
Batch: 85  |  Train Loss: 0.02627124823629856  |
Batch: 86  |  Train Loss: 0.038289833813905716  |
Batch: 87  |  Train Loss: 0.02275959774851799  |
Batch: 88  |  Train Loss: 0.030626509338617325  |
Batch: 89  |  Train Loss: 0.009171364828944206  |
Batch: 90  |  Train Loss: 0.03170449286699295  |
Batch: 91  |  Train Loss: 0.03838780149817467  |
Batch: 92  |  Train Loss: 0.0026645103935152292  |
Batch: 93  |  Train Loss: 0.025110425427556038  |
Batch: 94  |  Train Loss: 0.012282372452318668  |
Batch: 95  |  Train Loss: 0.017078803852200508  |
Batch: 96  |  Train Loss: 0.029971886426210403  |
Batch: 97  |  Train Loss: 0.012479384429752827  |
Batch: 98  |  Train Loss: 0.029829783365130424  |
Batch: 99  |  Train Loss: 0.0264092106372118  |
Batch: 100  |  Train Loss: 0.02491462416946888  |
Batch: 101  |  Train Loss: 0.02297484502196312  |
Batch: 102  |  Train Loss: 0.0799754410982132  |
Batch: 103  |  Train Loss: 0.003592098131775856  |
Batch: 104  |  Train Loss: 0.012606829404830933  |
Batch: 105  |  Train Loss: 0.018828880041837692  |
Batch: 106  |  Train Loss: 0.05478592589497566  |
Batch: 107  |  Train Loss: 0.010733741335570812  |
Batch: 108  |  Train Loss: 0.03290141373872757  |
Batch: 109  |  Train Loss: 0.017722971737384796  |
Batch: 110  |  Train Loss: 0.029358407482504845  |
Batch: 111  |  Train Loss: 0.029403695836663246  |
Batch: 112  |  Train Loss: 0.02607516013085842  |
Batch: 113  |  Train Loss: 0.02224073000252247  |
Batch: 114  |  Train Loss: 0.08919164538383484  |
Batch: 115  |  Train Loss: 0.027562692761421204  |
Batch: 116  |  Train Loss: 0.026166679337620735  |
Batch: 117  |  Train Loss: 0.026066100224852562  |
Batch: 118  |  Train Loss: 0.027070853859186172  |
Batch: 119  |  Train Loss: 0.026360999792814255  |
Batch: 120  |  Train Loss: 0.011245939880609512  |
Batch: 121  |  Train Loss: 0.012743711471557617  |
Batch: 122  |  Train Loss: 0.047219421714544296  |
Batch: 123  |  Train Loss: 0.010974104516208172  |
Batch: 124  |  Train Loss: 0.005282477010041475  |
Batch: 125  |  Train Loss: 0.03266850486397743  |
Batch: 126  |  Train Loss: 0.007676670327782631  |
Batch: 127  |  Train Loss: 0.01689181849360466  |
Batch: 128  |  Train Loss: 0.03167520463466644  |
Batch: 129  |  Train Loss: 0.030831674113869667  |
Batch: 130  |  Train Loss: 0.04006225988268852  |
Batch: 131  |  Train Loss: 0.003119443077594042  |
Batch: 132  |  Train Loss: 0.01974540390074253  |
Batch: 133  |  Train Loss: 0.027272814884781837  |
Batch: 134  |  Train Loss: 0.027890097349882126  |
Batch: 135  |  Train Loss: 0.08901216089725494  |
Batch: 136  |  Train Loss: 0.012371167540550232  |
Batch: 137  |  Train Loss: 0.008894260041415691  |
Batch: 138  |  Train Loss: 0.017782321199774742  |
Batch: 139  |  Train Loss: 0.03406814858317375  |
Batch: 140  |  Train Loss: 0.03589824587106705  |
Batch: 141  |  Train Loss: 0.022146791219711304  |
Batch: 142  |  Train Loss: 0.055650386959314346  |
Batch: 143  |  Train Loss: 0.0341789685189724  |
Batch: 144  |  Train Loss: 0.04090388864278793  |
Batch: 145  |  Train Loss: 0.02421450801193714  |
Batch: 146  |  Train Loss: 0.020015453919768333  |
Batch: 147  |  Train Loss: 0.017835333943367004  |
Batch: 148  |  Train Loss: 0.05159357190132141  |
Batch: 149  |  Train Loss: 0.02744259685277939  |
Batch: 150  |  Train Loss: 0.04553978517651558  |
Batch: 151  |  Train Loss: 0.03845492750406265  |
Batch: 152  |  Train Loss: 0.03566056117415428  |
Batch: 153  |  Train Loss: 0.012252965942025185  |
Batch: 154  |  Train Loss: 0.04487552121281624  |
Batch: 155  |  Train Loss: 0.021411580964922905  |
Batch: 156  |  Train Loss: 0.011577432043850422  |
Batch: 157  |  Train Loss: 0.028215738013386726  |
Batch: 158  |  Train Loss: 0.021290607750415802  |
Batch: 159  |  Train Loss: 0.04485972970724106  |
Batch: 160  |  Train Loss: 0.012392474338412285  |
Batch: 161  |  Train Loss: 0.019556595012545586  |
Batch: 162  |  Train Loss: 0.06233963370323181  |
Batch: 163  |  Train Loss: 0.019390976056456566  |
Batch: 164  |  Train Loss: 0.02375250682234764  |
Batch: 165  |  Train Loss: 0.020301315933465958  |
Batch: 166  |  Train Loss: 0.0063313692808151245  |
Batch: 167  |  Train Loss: 0.019179843366146088  |
Batch: 168  |  Train Loss: 0.0316687673330307  |
Batch: 169  |  Train Loss: 0.025532186031341553  |
Batch: 170  |  Train Loss: 0.013706649653613567  |
Batch: 171  |  Train Loss: 0.038066983222961426  |
Batch: 172  |  Train Loss: 0.03420446068048477  |
Batch: 173  |  Train Loss: 0.03758096322417259  |
Batch: 174  |  Train Loss: 0.0271481741219759  |
Batch: 175  |  Train Loss: 0.018864484503865242  |
Batch: 176  |  Train Loss: 0.031039707362651825  |
Batch: 177  |  Train Loss: 0.03064061887562275  |
Batch: 178  |  Train Loss: 0.01249531377106905  |
Batch: 179  |  Train Loss: 0.01997596211731434  |
Batch: 180  |  Train Loss: 0.011896617710590363  |
Batch: 181  |  Train Loss: 0.04174305498600006  |
Batch: 182  |  Train Loss: 0.07162515819072723  |
Batch: 183  |  Train Loss: 0.02330734394490719  |
Batch: 184  |  Train Loss: 0.03913754224777222  |
Epoch: 15  |  Train Loss: 0.026568381834422818
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.82it/s]
Binary results:█████████████████████████████| 1151/1151 [00:50<00:00, 22.25it/s]
################################################################################

Target prec: 0.635
Target recall: 0.563
Target F1: 0.597

Proportional results:
################################################################################

Target prec: 0.541
Target recall: 0.388
Target F1: 0.452

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.93it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.64it/s]
Binary results:████████████████████████████▉| 1150/1151 [00:50<00:00, 22.40it/s]
################################################################################

Target prec: 0.698
Target recall: 0.516
Target F1: 0.593

Proportional results:
################################################################################

Target prec: 0.553
Target recall: 0.322
Target F1: 0.407

################# END OF PIPELINE's RESULTS #################
 80%|█████████████████████████████▌       | 16/20 [4:43:52<1:11:03, 1065.97s/it]Batch: 0  |  Train Loss: 0.018551858142018318  |
Batch: 1  |  Train Loss: 0.011625220999121666  |
Batch: 2  |  Train Loss: 0.016255682334303856  |
Batch: 3  |  Train Loss: 0.021479671820998192  |
Batch: 4  |  Train Loss: 0.02644839510321617  |
Batch: 5  |  Train Loss: 0.020394721999764442  |
Batch: 6  |  Train Loss: 0.012481886893510818  |
Batch: 7  |  Train Loss: 0.03225601464509964  |
Batch: 8  |  Train Loss: 0.01515896338969469  |
Batch: 9  |  Train Loss: 0.025209860876202583  |
Batch: 10  |  Train Loss: 0.023647218942642212  |
Batch: 11  |  Train Loss: 0.01214894000440836  |
Batch: 12  |  Train Loss: 0.054743606597185135  |
Batch: 13  |  Train Loss: 0.025627218186855316  |
Batch: 14  |  Train Loss: 0.02895597368478775  |
Batch: 15  |  Train Loss: 0.0244256854057312  |
Batch: 16  |  Train Loss: 0.025205649435520172  |
Batch: 17  |  Train Loss: 0.031062215566635132  |
Batch: 18  |  Train Loss: 0.05309595540165901  |
Batch: 19  |  Train Loss: 0.027507292106747627  |
Batch: 20  |  Train Loss: 0.00972591433674097  |
Batch: 21  |  Train Loss: 0.027270035818219185  |
Batch: 22  |  Train Loss: 0.015912692993879318  |
Batch: 23  |  Train Loss: 0.025083769112825394  |
Batch: 24  |  Train Loss: 0.025317786261439323  |
Batch: 25  |  Train Loss: 0.01136492658406496  |
Batch: 26  |  Train Loss: 0.014840184710919857  |
Batch: 27  |  Train Loss: 0.028439883142709732  |
Batch: 28  |  Train Loss: 0.027997305616736412  |
Batch: 29  |  Train Loss: 0.04188409075140953  |
Batch: 30  |  Train Loss: 0.02751343511044979  |
Batch: 31  |  Train Loss: 0.02742450125515461  |
Batch: 32  |  Train Loss: 0.026799222454428673  |
Batch: 33  |  Train Loss: 0.013725199736654758  |
Batch: 34  |  Train Loss: 0.01412617415189743  |
Batch: 35  |  Train Loss: 0.01461011078208685  |
Batch: 36  |  Train Loss: 0.022053448483347893  |
Batch: 37  |  Train Loss: 0.04259677231311798  |
Batch: 38  |  Train Loss: 0.009108197875320911  |
Batch: 39  |  Train Loss: 0.06690021604299545  |
Batch: 40  |  Train Loss: 0.0048632691614329815  |
Batch: 41  |  Train Loss: 0.013565064407885075  |
Batch: 42  |  Train Loss: 0.013805323280394077  |
Batch: 43  |  Train Loss: 0.007337020244449377  |
Batch: 44  |  Train Loss: 0.051465000957250595  |
Batch: 45  |  Train Loss: 0.018816569820046425  |
Batch: 46  |  Train Loss: 0.027395278215408325  |
Batch: 47  |  Train Loss: 0.014669995754957199  |
Batch: 48  |  Train Loss: 0.011027076281607151  |
Batch: 49  |  Train Loss: 0.031529560685157776  |
Batch: 50  |  Train Loss: 0.013296535238623619  |
Batch: 51  |  Train Loss: 0.028007593005895615  |
Batch: 52  |  Train Loss: 0.022750848904252052  |
Batch: 53  |  Train Loss: 0.039288487285375595  |
Batch: 54  |  Train Loss: 0.04400883987545967  |
Batch: 55  |  Train Loss: 0.018620993942022324  |
Batch: 56  |  Train Loss: 0.04930663853883743  |
Batch: 57  |  Train Loss: 0.05271517112851143  |
Batch: 58  |  Train Loss: 0.010533012449741364  |
Batch: 59  |  Train Loss: 0.016551801934838295  |
Batch: 60  |  Train Loss: 0.011491500772535801  |
Batch: 61  |  Train Loss: 0.018832163885235786  |
Batch: 62  |  Train Loss: 0.004424648825079203  |
Batch: 63  |  Train Loss: 0.03931264206767082  |
Batch: 64  |  Train Loss: 0.014831473119556904  |
Batch: 65  |  Train Loss: 0.028668712824583054  |
Batch: 66  |  Train Loss: 0.04921402409672737  |
Batch: 67  |  Train Loss: 0.052989017218351364  |
Batch: 68  |  Train Loss: 0.01363696251064539  |
Batch: 69  |  Train Loss: 0.020584914833307266  |
Batch: 70  |  Train Loss: 0.007066700607538223  |
Batch: 71  |  Train Loss: 0.021115154027938843  |
Batch: 72  |  Train Loss: 0.010875020176172256  |
Batch: 73  |  Train Loss: 0.03923678398132324  |
Batch: 74  |  Train Loss: 0.0468035489320755  |
Batch: 75  |  Train Loss: 0.009002216160297394  |
Batch: 76  |  Train Loss: 0.04425457864999771  |
Batch: 77  |  Train Loss: 0.044553641229867935  |
Batch: 78  |  Train Loss: 0.014783518388867378  |
Batch: 79  |  Train Loss: 0.04998277500271797  |
Batch: 80  |  Train Loss: 0.038761645555496216  |
Batch: 81  |  Train Loss: 0.024210184812545776  |
Batch: 82  |  Train Loss: 0.010534617118537426  |
Batch: 83  |  Train Loss: 0.05478411540389061  |
Batch: 84  |  Train Loss: 0.027177324518561363  |
Batch: 85  |  Train Loss: 0.006796883884817362  |
Batch: 86  |  Train Loss: 0.07378291338682175  |
Batch: 87  |  Train Loss: 0.024398798123002052  |
Batch: 88  |  Train Loss: 0.030113451182842255  |
Batch: 89  |  Train Loss: 0.03560946136713028  |
Batch: 90  |  Train Loss: 0.04240650311112404  |
Batch: 91  |  Train Loss: 0.005984924267977476  |
Batch: 92  |  Train Loss: 0.042553797364234924  |
Batch: 93  |  Train Loss: 0.012252816930413246  |
Batch: 94  |  Train Loss: 0.03761768713593483  |
Batch: 95  |  Train Loss: 0.005930435378104448  |
Batch: 96  |  Train Loss: 0.028012963011860847  |
Batch: 97  |  Train Loss: 0.014952907338738441  |
Batch: 98  |  Train Loss: 0.014321640133857727  |
Batch: 99  |  Train Loss: 0.016013190150260925  |
Batch: 100  |  Train Loss: 0.012602557428181171  |
Batch: 101  |  Train Loss: 0.018821364268660545  |
Batch: 102  |  Train Loss: 0.008496026508510113  |
Batch: 103  |  Train Loss: 0.04405992850661278  |
Batch: 104  |  Train Loss: 0.023876743391156197  |
Batch: 105  |  Train Loss: 0.014574415981769562  |
Batch: 106  |  Train Loss: 0.024447498843073845  |
Batch: 107  |  Train Loss: 0.035795003175735474  |
Batch: 108  |  Train Loss: 0.016085177659988403  |
Batch: 109  |  Train Loss: 0.07087782025337219  |
Batch: 110  |  Train Loss: 0.02603955566883087  |
Batch: 111  |  Train Loss: 0.0200031790882349  |
Batch: 112  |  Train Loss: 0.032882798463106155  |
Batch: 113  |  Train Loss: 0.01972019113600254  |
Batch: 114  |  Train Loss: 0.005229633301496506  |
Batch: 115  |  Train Loss: 0.018974117934703827  |
Batch: 116  |  Train Loss: 0.040259137749671936  |
Batch: 117  |  Train Loss: 0.012579192407429218  |
Batch: 118  |  Train Loss: 0.019847365096211433  |
Batch: 119  |  Train Loss: 0.020275529474020004  |
Batch: 120  |  Train Loss: 0.013999883085489273  |
Batch: 121  |  Train Loss: 0.050234317779541016  |
Batch: 122  |  Train Loss: 0.04003442823886871  |
Batch: 123  |  Train Loss: 0.03728201612830162  |
Batch: 124  |  Train Loss: 0.038254689425230026  |
Batch: 125  |  Train Loss: 0.015437840484082699  |
Batch: 126  |  Train Loss: 0.011374909430742264  |
Batch: 127  |  Train Loss: 0.024235833436250687  |
Batch: 128  |  Train Loss: 0.0119959507137537  |
Batch: 129  |  Train Loss: 0.01321596372872591  |
Batch: 130  |  Train Loss: 0.017625952139496803  |
Batch: 131  |  Train Loss: 0.049980565905570984  |
Batch: 132  |  Train Loss: 0.03371388465166092  |
Batch: 133  |  Train Loss: 0.014735099859535694  |
Batch: 134  |  Train Loss: 0.022405192255973816  |
Batch: 135  |  Train Loss: 0.01537280809134245  |
Batch: 136  |  Train Loss: 0.043475985527038574  |
Batch: 137  |  Train Loss: 0.008560579270124435  |
Batch: 138  |  Train Loss: 0.03666245937347412  |
Batch: 139  |  Train Loss: 0.015895266085863113  |
Batch: 140  |  Train Loss: 0.030047178268432617  |
Batch: 141  |  Train Loss: 0.020255813375115395  |
Batch: 142  |  Train Loss: 0.02031676657497883  |
Batch: 143  |  Train Loss: 0.018595637753605843  |
Batch: 144  |  Train Loss: 0.03692745789885521  |
Batch: 145  |  Train Loss: 0.017778443172574043  |
Batch: 146  |  Train Loss: 0.004696595948189497  |
Batch: 147  |  Train Loss: 0.0334654301404953  |
Batch: 148  |  Train Loss: 0.005498415324836969  |
Batch: 149  |  Train Loss: 0.023334288969635963  |
Batch: 150  |  Train Loss: 0.02951064519584179  |
Batch: 151  |  Train Loss: 0.009570298716425896  |
Batch: 152  |  Train Loss: 0.030477918684482574  |
Batch: 153  |  Train Loss: 0.0056931935250759125  |
Batch: 154  |  Train Loss: 0.008501524105668068  |
Batch: 155  |  Train Loss: 0.022638067603111267  |
Batch: 156  |  Train Loss: 0.034838490188121796  |
Batch: 157  |  Train Loss: 0.03518226742744446  |
Batch: 158  |  Train Loss: 0.031167203560471535  |
Batch: 159  |  Train Loss: 0.03140036761760712  |
Batch: 160  |  Train Loss: 0.015886927023530006  |
Batch: 161  |  Train Loss: 0.00967543013393879  |
Batch: 162  |  Train Loss: 0.014634967781603336  |
Batch: 163  |  Train Loss: 0.05360505357384682  |
Batch: 164  |  Train Loss: 0.020159652456641197  |
Batch: 165  |  Train Loss: 0.02317863702774048  |
Batch: 166  |  Train Loss: 0.014502880163490772  |
Batch: 167  |  Train Loss: 0.03443190082907677  |
Batch: 168  |  Train Loss: 0.01986791379749775  |
Batch: 169  |  Train Loss: 0.027957364916801453  |
Batch: 170  |  Train Loss: 0.03483545035123825  |
Batch: 171  |  Train Loss: 0.008219858631491661  |
Batch: 172  |  Train Loss: 0.00805705040693283  |
Batch: 173  |  Train Loss: 0.02616148814558983  |
Batch: 174  |  Train Loss: 0.028372962027788162  |
Batch: 175  |  Train Loss: 0.020291605964303017  |
Batch: 176  |  Train Loss: 0.012911605648696423  |
Batch: 177  |  Train Loss: 0.026115782558918  |
Batch: 178  |  Train Loss: 0.012689968571066856  |
Batch: 179  |  Train Loss: 0.026611141860485077  |
Batch: 180  |  Train Loss: 0.009930483996868134  |
Batch: 181  |  Train Loss: 0.01952245458960533  |
Batch: 182  |  Train Loss: 0.020169883966445923  |
Batch: 183  |  Train Loss: 0.01749374158680439  |
Batch: 184  |  Train Loss: 0.008538391441106796  |
Epoch: 16  |  Train Loss: 0.024540895681727577
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.78it/s]
Binary results:████████████████████████████▉| 1150/1151 [00:50<00:00, 26.23it/s]
################################################################################

Target prec: 0.639
Target recall: 0.572
Target F1: 0.604

Proportional results:
################################################################################

Target prec: 0.559
Target recall: 0.402
Target F1: 0.468

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.83it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.83it/s]
Binary results:████████████████████████████▉| 1150/1151 [00:50<00:00, 26.02it/s]
################################################################################

Target prec: 0.703
Target recall: 0.522
Target F1: 0.599

Proportional results:
################################################################################

Target prec: 0.568
Target recall: 0.332
Target F1: 0.419

################# END OF PIPELINE's RESULTS #################
 85%|█████████████████████████████████▏     | 17/20 [5:01:27<53:07, 1062.54s/it]Batch: 0  |  Train Loss: 0.017025936394929886  |
Batch: 1  |  Train Loss: 0.029069319367408752  |
Batch: 2  |  Train Loss: 0.012355928309261799  |
Batch: 3  |  Train Loss: 0.037449732422828674  |
Batch: 4  |  Train Loss: 0.013491887599229813  |
Batch: 5  |  Train Loss: 0.029911907389760017  |
Batch: 6  |  Train Loss: 0.03114078938961029  |
Batch: 7  |  Train Loss: 0.026584453880786896  |
Batch: 8  |  Train Loss: 0.01993800699710846  |
Batch: 9  |  Train Loss: 0.014276986941695213  |
Batch: 10  |  Train Loss: 0.01149524562060833  |
Batch: 11  |  Train Loss: 0.025706041604280472  |
Batch: 12  |  Train Loss: 0.02892616204917431  |
Batch: 13  |  Train Loss: 0.011070351116359234  |
Batch: 14  |  Train Loss: 0.013739028945565224  |
Batch: 15  |  Train Loss: 0.025475429370999336  |
Batch: 16  |  Train Loss: 0.024740006774663925  |
Batch: 17  |  Train Loss: 0.057743627578020096  |
Batch: 18  |  Train Loss: 0.00690830685198307  |
Batch: 19  |  Train Loss: 0.06266085803508759  |
Batch: 20  |  Train Loss: 0.03173753619194031  |
Batch: 21  |  Train Loss: 0.010581857524812222  |
Batch: 22  |  Train Loss: 0.025747667998075485  |
Batch: 23  |  Train Loss: 0.011601722799241543  |
Batch: 24  |  Train Loss: 0.01042685005813837  |
Batch: 25  |  Train Loss: 0.021524576470255852  |
Batch: 26  |  Train Loss: 0.009645126760005951  |
Batch: 27  |  Train Loss: 0.017564846202731133  |
Batch: 28  |  Train Loss: 0.009127743542194366  |
Batch: 29  |  Train Loss: 0.006234263069927692  |
Batch: 30  |  Train Loss: 0.043107591569423676  |
Batch: 31  |  Train Loss: 0.017755072563886642  |
Batch: 32  |  Train Loss: 0.023923173546791077  |
Batch: 33  |  Train Loss: 0.035613905638456345  |
Batch: 34  |  Train Loss: 0.006849248427897692  |
Batch: 35  |  Train Loss: 0.010207481682300568  |
Batch: 36  |  Train Loss: 0.014442452229559422  |
Batch: 37  |  Train Loss: 0.044125381857156754  |
Batch: 38  |  Train Loss: 0.02381202206015587  |
Batch: 39  |  Train Loss: 0.02856327034533024  |
Batch: 40  |  Train Loss: 0.011109796352684498  |
Batch: 41  |  Train Loss: 0.026463421061635017  |
Batch: 42  |  Train Loss: 0.006134653929620981  |
Batch: 43  |  Train Loss: 0.01008594036102295  |
Batch: 44  |  Train Loss: 0.019095323979854584  |
Batch: 45  |  Train Loss: 0.01688847318291664  |
Batch: 46  |  Train Loss: 0.017637105658650398  |
Batch: 47  |  Train Loss: 0.006337136961519718  |
Batch: 48  |  Train Loss: 0.043228838592767715  |
Batch: 49  |  Train Loss: 0.0181600209325552  |
Batch: 50  |  Train Loss: 0.021645614877343178  |
Batch: 51  |  Train Loss: 0.03173106163740158  |
Batch: 52  |  Train Loss: 0.014595680870115757  |
Batch: 53  |  Train Loss: 0.04028084874153137  |
Batch: 54  |  Train Loss: 0.008026232942938805  |
Batch: 55  |  Train Loss: 0.004935567267239094  |
Batch: 56  |  Train Loss: 0.01944156177341938  |
Batch: 57  |  Train Loss: 0.034100111573934555  |
Batch: 58  |  Train Loss: 0.04010986536741257  |
Batch: 59  |  Train Loss: 0.012558353133499622  |
Batch: 60  |  Train Loss: 0.021643146872520447  |
Batch: 61  |  Train Loss: 0.006209312938153744  |
Batch: 62  |  Train Loss: 0.012051891535520554  |
Batch: 63  |  Train Loss: 0.0283874049782753  |
Batch: 64  |  Train Loss: 0.03749435767531395  |
Batch: 65  |  Train Loss: 0.0336528979241848  |
Batch: 66  |  Train Loss: 0.032364312559366226  |
Batch: 67  |  Train Loss: 0.0695866048336029  |
Batch: 68  |  Train Loss: 0.038701094686985016  |
Batch: 69  |  Train Loss: 0.01958424411714077  |
Batch: 70  |  Train Loss: 0.025164183229207993  |
Batch: 71  |  Train Loss: 0.02382460981607437  |
Batch: 72  |  Train Loss: 0.019926488399505615  |
Batch: 73  |  Train Loss: 0.003915287088602781  |
Batch: 74  |  Train Loss: 0.004014967475086451  |
Batch: 75  |  Train Loss: 0.037054434418678284  |
Batch: 76  |  Train Loss: 0.02428389899432659  |
Batch: 77  |  Train Loss: 0.014491072855889797  |
Batch: 78  |  Train Loss: 0.009171292185783386  |
Batch: 79  |  Train Loss: 0.04061182588338852  |
Batch: 80  |  Train Loss: 0.06901480257511139  |
Batch: 81  |  Train Loss: 0.011434574611485004  |
Batch: 82  |  Train Loss: 0.045988794416189194  |
Batch: 83  |  Train Loss: 0.014323102310299873  |
Batch: 84  |  Train Loss: 0.02242201939225197  |
Batch: 85  |  Train Loss: 0.012886088341474533  |
Batch: 86  |  Train Loss: 0.004385270643979311  |
Batch: 87  |  Train Loss: 0.009839034639298916  |
Batch: 88  |  Train Loss: 0.016605406999588013  |
Batch: 89  |  Train Loss: 0.023988712579011917  |
Batch: 90  |  Train Loss: 0.07107172906398773  |
Batch: 91  |  Train Loss: 0.022553659975528717  |
Batch: 92  |  Train Loss: 0.006036598235368729  |
Batch: 93  |  Train Loss: 0.019112804904580116  |
Batch: 94  |  Train Loss: 0.006762687582522631  |
Batch: 95  |  Train Loss: 0.01416410505771637  |
Batch: 96  |  Train Loss: 0.0387902706861496  |
Batch: 97  |  Train Loss: 0.02452998049557209  |
Batch: 98  |  Train Loss: 0.018356291577219963  |
Batch: 99  |  Train Loss: 0.025023411959409714  |
Batch: 100  |  Train Loss: 0.03099469654262066  |
Batch: 101  |  Train Loss: 0.019846132025122643  |
Batch: 102  |  Train Loss: 0.01729082502424717  |
Batch: 103  |  Train Loss: 0.025281716138124466  |
Batch: 104  |  Train Loss: 0.03175526112318039  |
Batch: 105  |  Train Loss: 0.02007238380610943  |
Batch: 106  |  Train Loss: 0.03418271616101265  |
Batch: 107  |  Train Loss: 0.02591833472251892  |
Batch: 108  |  Train Loss: 0.008538943715393543  |
Batch: 109  |  Train Loss: 0.015942992642521858  |
Batch: 110  |  Train Loss: 0.006333075929433107  |
Batch: 111  |  Train Loss: 0.02423175983130932  |
Batch: 112  |  Train Loss: 0.0224072877317667  |
Batch: 113  |  Train Loss: 0.027774153277277946  |
Batch: 114  |  Train Loss: 0.0577714741230011  |
Batch: 115  |  Train Loss: 0.014200837351381779  |
Batch: 116  |  Train Loss: 0.025406932458281517  |
Batch: 117  |  Train Loss: 0.008023519068956375  |
Batch: 118  |  Train Loss: 0.002466680249199271  |
Batch: 119  |  Train Loss: 0.042372748255729675  |
Batch: 120  |  Train Loss: 0.013723533600568771  |
Batch: 121  |  Train Loss: 0.015701275318861008  |
Batch: 122  |  Train Loss: 0.029146194458007812  |
Batch: 123  |  Train Loss: 0.03749904781579971  |
Batch: 124  |  Train Loss: 0.03821803256869316  |
Batch: 125  |  Train Loss: 0.03748725354671478  |
Batch: 126  |  Train Loss: 0.05770879611372948  |
Batch: 127  |  Train Loss: 0.037033967673778534  |
Batch: 128  |  Train Loss: 0.033354755491018295  |
Batch: 129  |  Train Loss: 0.012484929524362087  |
Batch: 130  |  Train Loss: 0.012352063320577145  |
Batch: 131  |  Train Loss: 0.01886277087032795  |
Batch: 132  |  Train Loss: 0.01600388064980507  |
Batch: 133  |  Train Loss: 0.0072965775616467  |
Batch: 134  |  Train Loss: 0.013762230053544044  |
Batch: 135  |  Train Loss: 0.026772474870085716  |
Batch: 136  |  Train Loss: 0.03200288489460945  |
Batch: 137  |  Train Loss: 0.011953617446124554  |
Batch: 138  |  Train Loss: 0.02432464435696602  |
Batch: 139  |  Train Loss: 0.022504787892103195  |
Batch: 140  |  Train Loss: 0.03167993947863579  |
Batch: 141  |  Train Loss: 0.026619546115398407  |
Batch: 142  |  Train Loss: 0.018419215455651283  |
Batch: 143  |  Train Loss: 0.03468691185116768  |
Batch: 144  |  Train Loss: 0.029023269191384315  |
Batch: 145  |  Train Loss: 0.01819174736738205  |
Batch: 146  |  Train Loss: 0.03278866410255432  |
Batch: 147  |  Train Loss: 0.01987801305949688  |
Batch: 148  |  Train Loss: 0.012374904938042164  |
Batch: 149  |  Train Loss: 0.018608206883072853  |
Batch: 150  |  Train Loss: 0.006139480508863926  |
Batch: 151  |  Train Loss: 0.019016750156879425  |
Batch: 152  |  Train Loss: 0.012578092515468597  |
Batch: 153  |  Train Loss: 0.022844670340418816  |
Batch: 154  |  Train Loss: 0.0278407521545887  |
Batch: 155  |  Train Loss: 0.03758062794804573  |
Batch: 156  |  Train Loss: 0.045796528458595276  |
Batch: 157  |  Train Loss: 0.045409299433231354  |
Batch: 158  |  Train Loss: 0.004694627597928047  |
Batch: 159  |  Train Loss: 0.034989163279533386  |
Batch: 160  |  Train Loss: 0.004928391892462969  |
Batch: 161  |  Train Loss: 0.03203399479389191  |
Batch: 162  |  Train Loss: 0.00959767121821642  |
Batch: 163  |  Train Loss: 0.021801883354783058  |
Batch: 164  |  Train Loss: 0.02310408093035221  |
Batch: 165  |  Train Loss: 0.03791356459259987  |
Batch: 166  |  Train Loss: 0.020277205854654312  |
Batch: 167  |  Train Loss: 0.01703925058245659  |
Batch: 168  |  Train Loss: 0.012626699171960354  |
Batch: 169  |  Train Loss: 0.023185502737760544  |
Batch: 170  |  Train Loss: 0.006662239786237478  |
Batch: 171  |  Train Loss: 0.012555282562971115  |
Batch: 172  |  Train Loss: 0.03566347435116768  |
Batch: 173  |  Train Loss: 0.004562993533909321  |
Batch: 174  |  Train Loss: 0.009032810106873512  |
Batch: 175  |  Train Loss: 0.01299289334565401  |
Batch: 176  |  Train Loss: 0.024214856326580048  |
Batch: 177  |  Train Loss: 0.017469283193349838  |
Batch: 178  |  Train Loss: 0.015186479315161705  |
Batch: 179  |  Train Loss: 0.014020965434610844  |
Batch: 180  |  Train Loss: 0.02809949591755867  |
Batch: 181  |  Train Loss: 0.031969569623470306  |
Batch: 182  |  Train Loss: 0.031150449067354202  |
Batch: 183  |  Train Loss: 0.006095603108406067  |
Batch: 184  |  Train Loss: 0.01016012392938137  |
Epoch: 17  |  Train Loss: 0.022728656457636404
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.85it/s]
Binary results:████████████████████████████▉| 1149/1151 [00:50<00:00, 22.17it/s]
################################################################################

Target prec: 0.646
Target recall: 0.590
Target F1: 0.617

Proportional results:
################################################################################

Target prec: 0.549
Target recall: 0.415
Target F1: 0.473

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.76it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.76it/s]
Binary results:████████████████████████████▉| 1149/1151 [00:50<00:00, 23.89it/s]
################################################################################

Target prec: 0.698
Target recall: 0.537
Target F1: 0.607

Proportional results:
################################################################################

Target prec: 0.555
Target recall: 0.342
Target F1: 0.423

################# END OF PIPELINE's RESULTS #################
 90%|███████████████████████████████████    | 18/20 [5:19:12<35:26, 1063.27s/it]Batch: 0  |  Train Loss: 0.0032716935966163874  |
Batch: 1  |  Train Loss: 0.010454735718667507  |
Batch: 2  |  Train Loss: 0.017310980707406998  |
Batch: 3  |  Train Loss: 0.010876930318772793  |
Batch: 4  |  Train Loss: 0.020946387201547623  |
Batch: 5  |  Train Loss: 0.01133554894477129  |
Batch: 6  |  Train Loss: 0.023558637127280235  |
Batch: 7  |  Train Loss: 0.011418079026043415  |
Batch: 8  |  Train Loss: 0.02137746661901474  |
Batch: 9  |  Train Loss: 0.0032590150367468596  |
Batch: 10  |  Train Loss: 0.00344726606272161  |
Batch: 11  |  Train Loss: 0.009254954755306244  |
Batch: 12  |  Train Loss: 0.05256930738687515  |
Batch: 13  |  Train Loss: 0.03583288565278053  |
Batch: 14  |  Train Loss: 0.03344359248876572  |
Batch: 15  |  Train Loss: 0.008028777316212654  |
Batch: 16  |  Train Loss: 0.012697937898337841  |
Batch: 17  |  Train Loss: 0.04227738827466965  |
Batch: 18  |  Train Loss: 0.01597682572901249  |
Batch: 19  |  Train Loss: 0.020391795784235  |
Batch: 20  |  Train Loss: 0.012905598618090153  |
Batch: 21  |  Train Loss: 0.024660920724272728  |
Batch: 22  |  Train Loss: 0.024027453735470772  |
Batch: 23  |  Train Loss: 0.0039549460634589195  |
Batch: 24  |  Train Loss: 0.012477393262088299  |
Batch: 25  |  Train Loss: 0.0067896912805736065  |
Batch: 26  |  Train Loss: 0.005330524407327175  |
Batch: 27  |  Train Loss: 0.017296936362981796  |
Batch: 28  |  Train Loss: 0.007807725574821234  |
Batch: 29  |  Train Loss: 0.034547269344329834  |
Batch: 30  |  Train Loss: 0.02139904908835888  |
Batch: 31  |  Train Loss: 0.05531181022524834  |
Batch: 32  |  Train Loss: 0.003003698540851474  |
Batch: 33  |  Train Loss: 0.022830963134765625  |
Batch: 34  |  Train Loss: 0.03250742703676224  |
Batch: 35  |  Train Loss: 0.007518674246966839  |
Batch: 36  |  Train Loss: 0.012544777244329453  |
Batch: 37  |  Train Loss: 0.03071896731853485  |
Batch: 38  |  Train Loss: 0.01527092233300209  |
Batch: 39  |  Train Loss: 0.01970115303993225  |
Batch: 40  |  Train Loss: 0.009355859830975533  |
Batch: 41  |  Train Loss: 0.025488395243883133  |
Batch: 42  |  Train Loss: 0.029500693082809448  |
Batch: 43  |  Train Loss: 0.009821431711316109  |
Batch: 44  |  Train Loss: 0.02219422534108162  |
Batch: 45  |  Train Loss: 0.01990821212530136  |
Batch: 46  |  Train Loss: 0.017877673730254173  |
Batch: 47  |  Train Loss: 0.02739805355668068  |
Batch: 48  |  Train Loss: 0.014015855267643929  |
Batch: 49  |  Train Loss: 0.010862934403121471  |
Batch: 50  |  Train Loss: 0.037676360458135605  |
Batch: 51  |  Train Loss: 0.02781417779624462  |
Batch: 52  |  Train Loss: 0.023168014362454414  |
Batch: 53  |  Train Loss: 0.022057941183447838  |
Batch: 54  |  Train Loss: 0.0075726802460849285  |
Batch: 55  |  Train Loss: 0.022497406229376793  |
Batch: 56  |  Train Loss: 0.020000632852315903  |
Batch: 57  |  Train Loss: 0.016086721792817116  |
Batch: 58  |  Train Loss: 0.02925458736717701  |
Batch: 59  |  Train Loss: 0.021617881953716278  |
Batch: 60  |  Train Loss: 0.017290176823735237  |
Batch: 61  |  Train Loss: 0.0635804533958435  |
Batch: 62  |  Train Loss: 0.03707156702876091  |
Batch: 63  |  Train Loss: 0.013723406940698624  |
Batch: 64  |  Train Loss: 0.048025984317064285  |
Batch: 65  |  Train Loss: 0.020616700872778893  |
Batch: 66  |  Train Loss: 0.027983734384179115  |
Batch: 67  |  Train Loss: 0.040598392486572266  |
Batch: 68  |  Train Loss: 0.014325044117867947  |
Batch: 69  |  Train Loss: 0.023166734725236893  |
Batch: 70  |  Train Loss: 0.006790934130549431  |
Batch: 71  |  Train Loss: 0.014916902408003807  |
Batch: 72  |  Train Loss: 0.011931176297366619  |
Batch: 73  |  Train Loss: 0.03425285592675209  |
Batch: 74  |  Train Loss: 0.03618767857551575  |
Batch: 75  |  Train Loss: 0.07201854884624481  |
Batch: 76  |  Train Loss: 0.023513738065958023  |
Batch: 77  |  Train Loss: 0.013171598315238953  |
Batch: 78  |  Train Loss: 0.008593264035880566  |
Batch: 79  |  Train Loss: 0.010082447901368141  |
Batch: 80  |  Train Loss: 0.011620013043284416  |
Batch: 81  |  Train Loss: 0.04887798801064491  |
Batch: 82  |  Train Loss: 0.010644612833857536  |
Batch: 83  |  Train Loss: 0.015212568454444408  |
Batch: 84  |  Train Loss: 0.019435051828622818  |
Batch: 85  |  Train Loss: 0.006603360176086426  |
Batch: 86  |  Train Loss: 0.04256730154156685  |
Batch: 87  |  Train Loss: 0.009664513170719147  |
Batch: 88  |  Train Loss: 0.01144636794924736  |
Batch: 89  |  Train Loss: 0.01463171187788248  |
Batch: 90  |  Train Loss: 0.024103574454784393  |
Batch: 91  |  Train Loss: 0.028737159445881844  |
Batch: 92  |  Train Loss: 0.010244027711451054  |
Batch: 93  |  Train Loss: 0.019134124740958214  |
Batch: 94  |  Train Loss: 0.015611873008310795  |
Batch: 95  |  Train Loss: 0.015543987974524498  |
Batch: 96  |  Train Loss: 0.03484922647476196  |
Batch: 97  |  Train Loss: 0.0216218288987875  |
Batch: 98  |  Train Loss: 0.010575595311820507  |
Batch: 99  |  Train Loss: 0.017547205090522766  |
Batch: 100  |  Train Loss: 0.015416130423545837  |
Batch: 101  |  Train Loss: 0.008113806135952473  |
Batch: 102  |  Train Loss: 0.01322710420936346  |
Batch: 103  |  Train Loss: 0.01077515259385109  |
Batch: 104  |  Train Loss: 0.020744238048791885  |
Batch: 105  |  Train Loss: 0.025035858154296875  |
Batch: 106  |  Train Loss: 0.010423577390611172  |
Batch: 107  |  Train Loss: 0.029699623584747314  |
Batch: 108  |  Train Loss: 0.012265578843653202  |
Batch: 109  |  Train Loss: 0.00643891328945756  |
Batch: 110  |  Train Loss: 0.015620755963027477  |
Batch: 111  |  Train Loss: 0.0264753345400095  |
Batch: 112  |  Train Loss: 0.02039170265197754  |
Batch: 113  |  Train Loss: 0.023827867582440376  |
Batch: 114  |  Train Loss: 0.021347369998693466  |
Batch: 115  |  Train Loss: 0.04082290828227997  |
Batch: 116  |  Train Loss: 0.07198531180620193  |
Batch: 117  |  Train Loss: 0.013552323915064335  |
Batch: 118  |  Train Loss: 0.007921788841485977  |
Batch: 119  |  Train Loss: 0.034638021141290665  |
Batch: 120  |  Train Loss: 0.02146671898663044  |
Batch: 121  |  Train Loss: 0.002050688723102212  |
Batch: 122  |  Train Loss: 0.019156107679009438  |
Batch: 123  |  Train Loss: 0.016163431107997894  |
Batch: 124  |  Train Loss: 0.04295020550489426  |
Batch: 125  |  Train Loss: 0.024396691471338272  |
Batch: 126  |  Train Loss: 0.006138097494840622  |
Batch: 127  |  Train Loss: 0.03804157301783562  |
Batch: 128  |  Train Loss: 0.018254369497299194  |
Batch: 129  |  Train Loss: 0.02439144067466259  |
Batch: 130  |  Train Loss: 0.029163559898734093  |
Batch: 131  |  Train Loss: 0.019597124308347702  |
Batch: 132  |  Train Loss: 0.0560128316283226  |
Batch: 133  |  Train Loss: 0.03344042971730232  |
Batch: 134  |  Train Loss: 0.05077533423900604  |
Batch: 135  |  Train Loss: 0.019840240478515625  |
Batch: 136  |  Train Loss: 0.017498688772320747  |
Batch: 137  |  Train Loss: 0.018817882984876633  |
Batch: 138  |  Train Loss: 0.008311278186738491  |
Batch: 139  |  Train Loss: 0.0322563536465168  |
Batch: 140  |  Train Loss: 0.029920723289251328  |
Batch: 141  |  Train Loss: 0.022438839077949524  |
Batch: 142  |  Train Loss: 0.016418226063251495  |
Batch: 143  |  Train Loss: 0.023203199729323387  |
Batch: 144  |  Train Loss: 0.025488577783107758  |
Batch: 145  |  Train Loss: 0.04906323924660683  |
Batch: 146  |  Train Loss: 0.008022584021091461  |
Batch: 147  |  Train Loss: 0.01736227236688137  |
Batch: 148  |  Train Loss: 0.027446221560239792  |
Batch: 149  |  Train Loss: 0.010665638372302055  |
Batch: 150  |  Train Loss: 0.0155295729637146  |
Batch: 151  |  Train Loss: 0.045396361500024796  |
Batch: 152  |  Train Loss: 0.020150931552052498  |
Batch: 153  |  Train Loss: 0.012656117789447308  |
Batch: 154  |  Train Loss: 0.040271420031785965  |
Batch: 155  |  Train Loss: 0.02920890972018242  |
Batch: 156  |  Train Loss: 0.01394673716276884  |
Batch: 157  |  Train Loss: 0.011515740305185318  |
Batch: 158  |  Train Loss: 0.006048823706805706  |
Batch: 159  |  Train Loss: 0.02078852616250515  |
Batch: 160  |  Train Loss: 0.03518958017230034  |
Batch: 161  |  Train Loss: 0.029386896640062332  |
Batch: 162  |  Train Loss: 0.007166131865233183  |
Batch: 163  |  Train Loss: 0.013875075615942478  |
Batch: 164  |  Train Loss: 0.030206793919205666  |
Batch: 165  |  Train Loss: 0.019479945302009583  |
Batch: 166  |  Train Loss: 0.04363667964935303  |
Batch: 167  |  Train Loss: 0.010415011085569859  |
Batch: 168  |  Train Loss: 0.04152835160493851  |
Batch: 169  |  Train Loss: 0.015582472085952759  |
Batch: 170  |  Train Loss: 0.03870474547147751  |
Batch: 171  |  Train Loss: 0.01688138023018837  |
Batch: 172  |  Train Loss: 0.028175625950098038  |
Batch: 173  |  Train Loss: 0.012157067656517029  |
Batch: 174  |  Train Loss: 0.012817608192563057  |
Batch: 175  |  Train Loss: 0.002325322013348341  |
Batch: 176  |  Train Loss: 0.016948053613305092  |
Batch: 177  |  Train Loss: 0.02461419440805912  |
Batch: 178  |  Train Loss: 0.021824078634381294  |
Batch: 179  |  Train Loss: 0.018670683726668358  |
Batch: 180  |  Train Loss: 0.015616868622601032  |
Batch: 181  |  Train Loss: 0.020777270197868347  |
Batch: 182  |  Train Loss: 0.022928155958652496  |
Batch: 183  |  Train Loss: 0.027943534776568413  |
Batch: 184  |  Train Loss: 0.011291282251477242  |
Epoch: 18  |  Train Loss: 0.02156838467470496
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.79it/s]
Binary results:█████████████████████████████| 1151/1151 [00:50<00:00, 21.16it/s]
################################################################################

Target prec: 0.612
Target recall: 0.632
Target F1: 0.622

Proportional results:
################################################################################

Target prec: 0.514
Target recall: 0.451
Target F1: 0.480

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.89it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.91it/s]
Binary results:████████████████████████████▉| 1149/1151 [00:50<00:00, 23.38it/s]
################################################################################

Target prec: 0.676
Target recall: 0.564
Target F1: 0.615

Proportional results:
################################################################################

Target prec: 0.532
Target recall: 0.360
Target F1: 0.429

################# END OF PIPELINE's RESULTS #################
 95%|█████████████████████████████████████  | 19/20 [5:36:45<17:40, 1060.20s/it]Batch: 0  |  Train Loss: 0.007315891794860363  |
Batch: 1  |  Train Loss: 0.015809034928679466  |
Batch: 2  |  Train Loss: 0.030565433204174042  |
Batch: 3  |  Train Loss: 0.011970852501690388  |
Batch: 4  |  Train Loss: 0.01365718338638544  |
Batch: 5  |  Train Loss: 0.034804146736860275  |
Batch: 6  |  Train Loss: 0.04672772064805031  |
Batch: 7  |  Train Loss: 0.01724911853671074  |
Batch: 8  |  Train Loss: 0.020145662128925323  |
Batch: 9  |  Train Loss: 0.01413736492395401  |
Batch: 10  |  Train Loss: 0.0069917719811201096  |
Batch: 11  |  Train Loss: 0.010865421034395695  |
Batch: 12  |  Train Loss: 0.01587154157459736  |
Batch: 13  |  Train Loss: 0.02494261972606182  |
Batch: 14  |  Train Loss: 0.007161264773458242  |
Batch: 15  |  Train Loss: 0.005485525820404291  |
Batch: 16  |  Train Loss: 0.00707046315073967  |
Batch: 17  |  Train Loss: 0.01371657196432352  |
Batch: 18  |  Train Loss: 0.019120272248983383  |
Batch: 19  |  Train Loss: 0.013038191944360733  |
Batch: 20  |  Train Loss: 0.013454045169055462  |
Batch: 21  |  Train Loss: 0.011417885310947895  |
Batch: 22  |  Train Loss: 0.028525561094284058  |
Batch: 23  |  Train Loss: 0.026601411402225494  |
Batch: 24  |  Train Loss: 0.02223152667284012  |
Batch: 25  |  Train Loss: 0.0059437998570501804  |
Batch: 26  |  Train Loss: 0.037989769130945206  |
Batch: 27  |  Train Loss: 0.019520001485943794  |
Batch: 28  |  Train Loss: 0.012433409690856934  |
Batch: 29  |  Train Loss: 0.014506196603178978  |
Batch: 30  |  Train Loss: 0.003554937429726124  |
Batch: 31  |  Train Loss: 0.009562659077346325  |
Batch: 32  |  Train Loss: 0.006480914540588856  |
Batch: 33  |  Train Loss: 0.004606890492141247  |
Batch: 34  |  Train Loss: 0.027185527607798576  |
Batch: 35  |  Train Loss: 0.012651230208575726  |
Batch: 36  |  Train Loss: 0.026140399277210236  |
Batch: 37  |  Train Loss: 0.004957652650773525  |
Batch: 38  |  Train Loss: 0.00712983775883913  |
Batch: 39  |  Train Loss: 0.006796573754400015  |
Batch: 40  |  Train Loss: 0.01558032725006342  |
Batch: 41  |  Train Loss: 0.006533128209412098  |
Batch: 42  |  Train Loss: 0.03361162543296814  |
Batch: 43  |  Train Loss: 0.031459301710128784  |
Batch: 44  |  Train Loss: 0.03157103806734085  |
Batch: 45  |  Train Loss: 0.008212335407733917  |
Batch: 46  |  Train Loss: 0.04078371077775955  |
Batch: 47  |  Train Loss: 0.025181259959936142  |
Batch: 48  |  Train Loss: 0.027749134227633476  |
Batch: 49  |  Train Loss: 0.019185323268175125  |
Batch: 50  |  Train Loss: 0.014495126903057098  |
Batch: 51  |  Train Loss: 0.04397227242588997  |
Batch: 52  |  Train Loss: 0.09706158936023712  |
Batch: 53  |  Train Loss: 0.016633516177535057  |
Batch: 54  |  Train Loss: 0.014173462055623531  |
Batch: 55  |  Train Loss: 0.005324187222868204  |
Batch: 56  |  Train Loss: 0.03629731386899948  |
Batch: 57  |  Train Loss: 0.01983153447508812  |
Batch: 58  |  Train Loss: 0.008519018068909645  |
Batch: 59  |  Train Loss: 0.020987294614315033  |
Batch: 60  |  Train Loss: 0.018568644300103188  |
Batch: 61  |  Train Loss: 0.0374172180891037  |
Batch: 62  |  Train Loss: 0.06206629052758217  |
Batch: 63  |  Train Loss: 0.022463463246822357  |
Batch: 64  |  Train Loss: 0.017671609297394753  |
Batch: 65  |  Train Loss: 0.013202983886003494  |
Batch: 66  |  Train Loss: 0.004918733146041632  |
Batch: 67  |  Train Loss: 0.0316598154604435  |
Batch: 68  |  Train Loss: 0.02802496775984764  |
Batch: 69  |  Train Loss: 0.028150619938969612  |
Batch: 70  |  Train Loss: 0.01743849366903305  |
Batch: 71  |  Train Loss: 0.010034318082034588  |
Batch: 72  |  Train Loss: 0.01687796413898468  |
Batch: 73  |  Train Loss: 0.025443071499466896  |
Batch: 74  |  Train Loss: 0.01767565682530403  |
Batch: 75  |  Train Loss: 0.016822218894958496  |
Batch: 76  |  Train Loss: 0.02153136022388935  |
Batch: 77  |  Train Loss: 0.019145796075463295  |
Batch: 78  |  Train Loss: 0.00710698775947094  |
Batch: 79  |  Train Loss: 0.02363189123570919  |
Batch: 80  |  Train Loss: 0.03705959767103195  |
Batch: 81  |  Train Loss: 0.01237697247415781  |
Batch: 82  |  Train Loss: 0.04186403006315231  |
Batch: 83  |  Train Loss: 0.0159197635948658  |
Batch: 84  |  Train Loss: 0.012989386916160583  |
Batch: 85  |  Train Loss: 0.039665888994932175  |
Batch: 86  |  Train Loss: 0.018748266622424126  |
Batch: 87  |  Train Loss: 0.019934875890612602  |
Batch: 88  |  Train Loss: 0.007351880427449942  |
Batch: 89  |  Train Loss: 0.009421180002391338  |
Batch: 90  |  Train Loss: 0.022918928414583206  |
Batch: 91  |  Train Loss: 0.010926964692771435  |
Batch: 92  |  Train Loss: 0.02210267446935177  |
Batch: 93  |  Train Loss: 0.008976992219686508  |
Batch: 94  |  Train Loss: 0.035091888159513474  |
Batch: 95  |  Train Loss: 0.014736022800207138  |
Batch: 96  |  Train Loss: 0.013269850984215736  |
Batch: 97  |  Train Loss: 0.026313193142414093  |
Batch: 98  |  Train Loss: 0.013253893703222275  |
Batch: 99  |  Train Loss: 0.036024436354637146  |
Batch: 100  |  Train Loss: 0.014800158329308033  |
Batch: 101  |  Train Loss: 0.003707430325448513  |
Batch: 102  |  Train Loss: 0.04017702490091324  |
Batch: 103  |  Train Loss: 0.006593760102987289  |
Batch: 104  |  Train Loss: 0.008061304688453674  |
Batch: 105  |  Train Loss: 0.03797721490263939  |
Batch: 106  |  Train Loss: 0.0037985581438988447  |
Batch: 107  |  Train Loss: 0.01506736222654581  |
Batch: 108  |  Train Loss: 0.015069134533405304  |
Batch: 109  |  Train Loss: 0.01644900068640709  |
Batch: 110  |  Train Loss: 0.005507342051714659  |
Batch: 111  |  Train Loss: 0.01477972324937582  |
Batch: 112  |  Train Loss: 0.015255077742040157  |
Batch: 113  |  Train Loss: 0.017463447526097298  |
Batch: 114  |  Train Loss: 0.02422385662794113  |
Batch: 115  |  Train Loss: 0.014560489915311337  |
Batch: 116  |  Train Loss: 0.014522654935717583  |
Batch: 117  |  Train Loss: 0.02438179962337017  |
Batch: 118  |  Train Loss: 0.014111727476119995  |
Batch: 119  |  Train Loss: 0.015627315267920494  |
Batch: 120  |  Train Loss: 0.02800695411860943  |
Batch: 121  |  Train Loss: 0.006903409026563168  |
Batch: 122  |  Train Loss: 0.0031560934148728848  |
Batch: 123  |  Train Loss: 0.005860125180333853  |
Batch: 124  |  Train Loss: 0.021526826545596123  |
Batch: 125  |  Train Loss: 0.02190556190907955  |
Batch: 126  |  Train Loss: 0.009850294329226017  |
Batch: 127  |  Train Loss: 0.007673952262848616  |
Batch: 128  |  Train Loss: 0.02056291699409485  |
Batch: 129  |  Train Loss: 0.030209802091121674  |
Batch: 130  |  Train Loss: 0.016434308141469955  |
Batch: 131  |  Train Loss: 0.013153771869838238  |
Batch: 132  |  Train Loss: 0.018623581156134605  |
Batch: 133  |  Train Loss: 0.03835510089993477  |
Batch: 134  |  Train Loss: 0.0233612023293972  |
Batch: 135  |  Train Loss: 0.011975561268627644  |
Batch: 136  |  Train Loss: 0.011845110915601254  |
Batch: 137  |  Train Loss: 0.04241149127483368  |
Batch: 138  |  Train Loss: 0.009196335449814796  |
Batch: 139  |  Train Loss: 0.025534195825457573  |
Batch: 140  |  Train Loss: 0.013355161063373089  |
Batch: 141  |  Train Loss: 0.016430964693427086  |
Batch: 142  |  Train Loss: 0.02693963423371315  |
Batch: 143  |  Train Loss: 0.03847179934382439  |
Batch: 144  |  Train Loss: 0.0129170473664999  |
Batch: 145  |  Train Loss: 0.06788229942321777  |
Batch: 146  |  Train Loss: 0.002045069122686982  |
Batch: 147  |  Train Loss: 0.03329722583293915  |
Batch: 148  |  Train Loss: 0.020684024319052696  |
Batch: 149  |  Train Loss: 0.02264089696109295  |
Batch: 150  |  Train Loss: 0.009963702410459518  |
Batch: 151  |  Train Loss: 0.01859806291759014  |
Batch: 152  |  Train Loss: 0.02778802253305912  |
Batch: 153  |  Train Loss: 0.08546236157417297  |
Batch: 154  |  Train Loss: 0.01047105249017477  |
Batch: 155  |  Train Loss: 0.017411161214113235  |
Batch: 156  |  Train Loss: 0.014131083153188229  |
Batch: 157  |  Train Loss: 0.059445519000291824  |
Batch: 158  |  Train Loss: 0.011718088760972023  |
Batch: 159  |  Train Loss: 0.0016987744020298123  |
Batch: 160  |  Train Loss: 0.0038893851451575756  |
Batch: 161  |  Train Loss: 0.01775176450610161  |
Batch: 162  |  Train Loss: 0.039197418838739395  |
Batch: 163  |  Train Loss: 0.061392851173877716  |
Batch: 164  |  Train Loss: 0.02877473272383213  |
Batch: 165  |  Train Loss: 0.012930654920637608  |
Batch: 166  |  Train Loss: 0.018269388005137444  |
Batch: 167  |  Train Loss: 0.018588073551654816  |
Batch: 168  |  Train Loss: 0.046978939324617386  |
Batch: 169  |  Train Loss: 0.015465076081454754  |
Batch: 170  |  Train Loss: 0.03367173671722412  |
Batch: 171  |  Train Loss: 0.022249789908528328  |
Batch: 172  |  Train Loss: 0.009599030017852783  |
Batch: 173  |  Train Loss: 0.01595481112599373  |
Batch: 174  |  Train Loss: 0.025672459974884987  |
Batch: 175  |  Train Loss: 0.0365879088640213  |
Batch: 176  |  Train Loss: 0.016509532928466797  |
Batch: 177  |  Train Loss: 0.009777996689081192  |
Batch: 178  |  Train Loss: 0.008710975758731365  |
Batch: 179  |  Train Loss: 0.025920134037733078  |
Batch: 180  |  Train Loss: 0.006176892202347517  |
Batch: 181  |  Train Loss: 0.029915422201156616  |
Batch: 182  |  Train Loss: 0.030687959864735603  |
Batch: 183  |  Train Loss: 0.006724168546497822  |
Batch: 184  |  Train Loss: 0.03085273504257202  |
Epoch: 19  |  Train Loss: 0.020468001841013696
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.90it/s]
Binary results:████████████████████████████▉| 1149/1151 [00:50<00:00, 21.31it/s]
################################################################################

Target prec: 0.626
Target recall: 0.624
Target F1: 0.625

Proportional results:
################################################################################

Target prec: 0.522
Target recall: 0.442
Target F1: 0.479

################### PIPELINE's RESULTS ###################
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.80it/s]
100%|███████████████████████████████████████| 1151/1151 [00:50<00:00, 22.76it/s]
Binary results:████████████████████████████▉| 1150/1151 [00:50<00:00, 21.04it/s]
################################################################################

Target prec: 0.678
Target recall: 0.541
Target F1: 0.602

Proportional results:
################################################################################

Target prec: 0.539
Target recall: 0.343
Target F1: 0.419

################# END OF PIPELINE's RESULTS #################
100%|███████████████████████████████████████| 20/20 [5:54:23<00:00, 1063.18s/it]
100%|█████████████████████████████████████████| 895/895 [00:39<00:00, 22.69it/s]
Binary results:
################################################################################

Target prec: 0.611
Target recall: 0.596
Target F1: 0.604

Proportional results:
################################################################################

Target prec: 0.536
Target recall: 0.451
Target F1: 0.490
